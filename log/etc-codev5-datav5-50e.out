[2024-02-05 09:50:54,196] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-05 09:50:55,120] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-02-05 09:50:55,120] [INFO] [runner.py:555:main] cmd = /mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNSwgNl19 --master_addr=127.0.0.1 --master_port=9907 --enable_each_rank_log=None src/train_bash.py --deepspeed ds_config.json --stage sft --model_name_or_path /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat --output_dir /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0 --do_train --dataset etc-v5-700-total-output --split train --val_size 0.1 --template baichuan2 --finetuning_type lora --lora_rank 8 --lora_target W_pack --overwrite_cache --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 2 --preprocessing_num_workers 16 --lr_scheduler_type cosine --logging_steps 5 --save_steps 100 --learning_rate 5e-5 --max_grad_norm 0.5 --num_train_epochs 50 --evaluation_strategy steps --load_best_model_at_end --plot_loss --fp16 --overwrite_output_dir True
[2024-02-05 09:50:57,083] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-05 09:50:58,567] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [5, 6]}
[2024-02-05 09:50:58,567] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2024-02-05 09:50:58,567] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2024-02-05 09:50:58,567] [INFO] [launch.py:163:main] dist_world_size=2
[2024-02-05 09:50:58,567] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=5,6
[2024-02-05 09:51:03,447] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-05 09:51:03,447] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-05 09:51:05,758] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-02-05 09:51:05,758] [INFO] [comm.py:616:init_distributed] cdb=None
[2024-02-05 09:51:05,758] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-02-05 09:51:05,759] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-02-05 09:51:05,759] [INFO] [comm.py:616:init_distributed] cdb=None
02/05/2024 09:51:05 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
[INFO|training_args.py:1828] 2024-02-05 09:51:05,775 >> PyTorch: setting up devices
02/05/2024 09:51:05 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/transformers/training_args.py:1741: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.
  warnings.warn(
02/05/2024 09:51:05 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1
  distributed training: True, compute dtype: torch.float16
02/05/2024 09:51:05 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=5,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/runs/Feb05_09-51-05_user,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=5,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=0.5,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=50.0,
optim=adamw_torch,
optim_args=None,
output_dir=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=4,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=100,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/transformers/training_args.py:1741: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.
  warnings.warn(
02/05/2024 09:51:05 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1
  distributed training: True, compute dtype: torch.float16
02/05/2024 09:51:05 - INFO - llmtuner.hparams.parser - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=ds_config.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=5,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/runs/Feb05_09-51-05_user,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=5,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=0.5,
max_steps=-1,
metric_for_best_model=loss,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=50.0,
optim=adamw_torch,
optim_args=None,
output_dir=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=4,
per_device_train_batch_size=4,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=100,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|tokenization_utils_base.py:2025] 2024-02-05 09:51:05,801 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2025] 2024-02-05 09:51:05,801 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2025] 2024-02-05 09:51:05,802 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2025] 2024-02-05 09:51:05,802 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2025] 2024-02-05 09:51:05,802 >> loading file tokenizer.json
[INFO|configuration_utils.py:727] 2024-02-05 09:51:06,035 >> loading configuration file /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat/config.json
[INFO|configuration_utils.py:727] 2024-02-05 09:51:06,040 >> loading configuration file /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat/config.json
[INFO|configuration_utils.py:792] 2024-02-05 09:51:06,041 >> Model config BaichuanConfig {
  "_from_model_config": true,
  "_name_or_path": "/mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat",
  "architectures": [
    "BaichuanForCausalLM"
  ],
  "auto_map": {
    "AutoConfig": "configuration_baichuan.BaichuanConfig",
    "AutoModelForCausalLM": "modeling_baichuan.BaichuanForCausalLM"
  },
  "bos_token_id": 1,
  "eos_token_id": 2,
  "gradient_checkpointing": [
    false
  ],
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13696,
  "model_max_length": 4096,
  "model_type": "baichuan",
  "num_attention_heads": 40,
  "num_hidden_layers": 40,
  "pad_token_id": 0,
  "rms_norm_eps": 1e-06,
  "tie_word_embeddings": false,
  "tokenizer_class": "BaichuanTokenizer",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.37.2",
  "use_cache": true,
  "vocab_size": 125696,
  "z_loss_weight": 0
}

Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
[INFO|modeling_utils.py:3473] 2024-02-05 09:51:06,139 >> loading weights file /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat/pytorch_model.bin.index.json
[INFO|modeling_utils.py:1426] 2024-02-05 09:51:06,140 >> Instantiating BaichuanForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:826] 2024-02-05 09:51:06,141 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
[WARNING|modeling_utils.py:2132] 2024-02-05 09:51:06,201 >> You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  33%|███▎      | 1/3 [01:28<02:57, 88.68s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [01:28<02:57, 88.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [03:08<01:35, 95.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [03:08<01:35, 95.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [04:25<00:00, 86.98s/it]Loading checkpoint shards: 100%|██████████| 3/3 [04:25<00:00, 88.55s/it]
You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
02/05/2024 09:55:31 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
02/05/2024 09:55:31 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
Loading checkpoint shards: 100%|██████████| 3/3 [04:25<00:00, 87.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [04:25<00:00, 88.58s/it]
[INFO|modeling_utils.py:4350] 2024-02-05 09:55:31,974 >> All model checkpoint weights were used when initializing BaichuanForCausalLM.

[INFO|modeling_utils.py:4358] 2024-02-05 09:55:31,974 >> All the weights of BaichuanForCausalLM were initialized from the model checkpoint at /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BaichuanForCausalLM for predictions without further training.
[INFO|configuration_utils.py:779] 2024-02-05 09:55:31,979 >> loading configuration file /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat/generation_config.json
[INFO|configuration_utils.py:826] 2024-02-05 09:55:31,979 >> Generate config GenerationConfig {
  "assistant_token_id": 196,
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_new_tokens": 2048,
  "pad_token_id": 0,
  "repetition_penalty": 1.05,
  "temperature": 0.3,
  "top_k": 5,
  "top_p": 0.85,
  "user_token_id": 195
}

[WARNING|modeling_utils.py:2132] 2024-02-05 09:55:31,981 >> You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
02/05/2024 09:55:31 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
02/05/2024 09:55:31 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
02/05/2024 09:55:32 - INFO - llmtuner.model.loader - trainable params: 6553600 || all params: 13903221760 || trainable%: 0.0471
02/05/2024 09:55:32 - INFO - llmtuner.model.loader - trainable params: 6553600 || all params: 13903221760 || trainable%: 0.0471
02/05/2024 09:55:32 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Using custom data configuration default-2f70bfcf3d4f393c
Loading Dataset Infos from /mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/packaged_modules/json
Generating dataset json (/home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
Downloading and preparing dataset json/default to /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]
Downloading took 0.0 min
Checksum Computation took 0.0 min
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 104.56it/s]
Generating train split
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 699 examples [00:00, 15454.37 examples/s]
Unable to verify splits sizes.
Dataset json downloaded and prepared to /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.
Process #0 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00000_of_00016.arrow
Process #1 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00001_of_00016.arrow
Process #2 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00002_of_00016.arrow
Process #3 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00003_of_00016.arrow
Process #4 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00004_of_00016.arrow
Process #5 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00005_of_00016.arrow
Process #6 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00006_of_00016.arrow
Process #7 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00007_of_00016.arrow
Process #8 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00008_of_00016.arrow
Process #9 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00009_of_00016.arrow
Process #10 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00010_of_00016.arrow
Process #11 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00011_of_00016.arrow
Process #12 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00012_of_00016.arrow
Process #13 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00013_of_00016.arrow
Process #14 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00014_of_00016.arrow
Process #15 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00015_of_00016.arrow
Spawning 16 processes
Converting format of dataset (num_proc=16):   0%|          | 0/699 [00:00<?, ? examples/s]Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00000_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00001_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00004_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00002_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00011_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00003_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00005_of_00016.arrow
Converting format of dataset (num_proc=16):   6%|▋         | 44/699 [00:00<00:04, 150.18 examples/s]Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00007_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00008_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00006_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00012_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00014_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00010_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00015_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00009_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1893306d56e595c_00013_of_00016.arrow
Converting format of dataset (num_proc=16): 100%|██████████| 699/699 [00:00<00:00, 904.42 examples/s]
Concatenating 16 shards
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.
  table = cls._concat_blocks(blocks, axis=0)
02/05/2024 09:55:42 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
Process #0 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00000_of_00016.arrow
Process #1 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00001_of_00016.arrow
Process #2 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00002_of_00016.arrow
Process #3 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00003_of_00016.arrow
Process #4 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00004_of_00016.arrow
Process #5 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00005_of_00016.arrow
Process #6 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00006_of_00016.arrow
Process #7 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00007_of_00016.arrow
Process #8 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00008_of_00016.arrow
Process #9 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00009_of_00016.arrow
Process #10 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00010_of_00016.arrow
Process #11 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00011_of_00016.arrow
Process #12 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00012_of_00016.arrow
Process #13 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00013_of_00016.arrow
Process #14 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00014_of_00016.arrow
Process #15 will write at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00015_of_00016.arrow
Spawning 16 processes
Running tokenizer on dataset (num_proc=16):   0%|          | 0/699 [00:00<?, ? examples/s]/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00002_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00004_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00003_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00005_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00006_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00009_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00007_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00008_of_00016.arrow
Running tokenizer on dataset (num_proc=16):   6%|▋         | 44/699 [00:00<00:05, 113.01 examples/s]Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00011_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00010_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00013_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00012_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00014_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00015_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00001_of_00016.arrow
Caching processed dataset at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-c942e6f4e78f9e40_00000_of_00016.arrow
Running tokenizer on dataset (num_proc=16): 100%|██████████| 699/699 [00:00<00:00, 741.50 examples/s]
Concatenating 16 shards
input_ids:
[195, 5, 1411, 28413, 100392, 92415, 43621, 12478, 74723, 3854, 6004, 65, 17032, 92360, 92525, 93057, 92361, 65, 92360, 93057, 93654, 92361, 65, 92360, 2185, 92361, 12340, 1839, 65, 29090, 57172, 92489, 20995, 6104, 65, 92594, 12785, 26712, 6004, 28837, 2502, 66, 5, 1411, 57172, 47812, 92626, 9092, 62, 26387, 92660, 47927, 6295, 17577, 9633, 92323, 92311, 93266, 4276, 92376, 11721, 65, 92948, 3779, 19823, 39549, 4276, 65, 51383, 3550, 13172, 20995, 1833, 65, 92948, 57172, 12785, 66480, 92360, 92525, 92361, 89, 5, 1411, 20995, 6104, 47812, 92360, 93475, 69, 92960, 69, 92960, 93242, 69, 93242, 92361, 2410, 3352, 65, 93266, 6104, 9633, 7277, 6177, 8416, 65, 92948, 12785, 20995, 36217, 33431, 2699, 92360, 92525, 92361, 92311, 5, 1411, 4847, 92311, 12478, 1833, 70, 92676, 92955, 65, 16829, 65, 23003, 24438, 93057, 92525, 39315, 65, 92525, 7056, 1833, 65, 9867, 29724, 92642, 2908, 65, 11393, 65, 11393, 92586, 93400, 14041, 19378, 2503, 65, 23003, 92525, 93057, 5443, 65, 14041, 79356, 92898, 37821, 67, 20995, 3413, 68, 93225, 92438, 92370, 92468, 92356, 92336, 92358, 65, 93475, 93103, 5, 196, 30338, 92612, 92440, 5338, 1664, 92525, 93057, 2925, 1664, 57172, 5338, 1664, 93225, 92438, 92370, 92468, 92356, 92336, 92358, 2925, 1664, 20995, 6104, 5338, 1664, 92525, 2925, 1664, 28837, 2502, 5338, 1664, 5215, 92478, 10747, 92525, 93057, 5443, 65, 2895, 18138, 93057, 92612, 92440, 66, 52639, 2]
inputs:
 <reserved_106>
    ### 请对前端请求信息进行理解分类，划分“无卡”，“卡坏”，“其他”三种情况，抽取车牌号与车牌颜色，并输出详细的分类推理过程。
    车牌号应为省简称+序列号两部分组成的标准描述, 若数字为中文，则统一转为阿拉伯数字，若无符合要求的车牌信息，则车牌号输出结果为“无”；
    车牌颜色应为“蓝、黄、黄绿、绿”其中一种，若颜色描述不在上述范围内，则输出车牌颜色的默认结果“无” 
    ## 请求信息：请讲，你好，这边ETC卡无牌照，无入口信息，麻烦帮我查一下，驾驶员，驾驶员口述是从滨海上的，这边无卡确认，是从大丰站过来的！车牌多少？苏J8KP15，蓝牌
<reserved_107>{"特情": "无卡", "车牌号": "苏J8KP15", "车牌颜色": "无", "推理过程": "收费员提到无卡确认，因此是无卡特情。"}</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30338, 92612, 92440, 5338, 1664, 92525, 93057, 2925, 1664, 57172, 5338, 1664, 93225, 92438, 92370, 92468, 92356, 92336, 92358, 2925, 1664, 20995, 6104, 5338, 1664, 92525, 2925, 1664, 28837, 2502, 5338, 1664, 5215, 92478, 10747, 92525, 93057, 5443, 65, 2895, 18138, 93057, 92612, 92440, 66, 52639, 2]
labels:
 {"特情": "无卡", "车牌号": "苏J8KP15", "车牌颜色": "无", "推理过程": "收费员提到无卡确认，因此是无卡特情。"}</s>
Converting format of dataset (num_proc=16):   0%|          | 0/699 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   6%|▋         | 44/699 [00:00<00:04, 144.84 examples/s]Converting format of dataset (num_proc=16):  13%|█▎        | 88/699 [00:00<00:02, 208.71 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 699/699 [00:00<00:00, 733.92 examples/s]
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.
  table = cls._concat_blocks(blocks, axis=0)
[INFO|training_args.py:1828] 2024-02-05 09:55:49,539 >> PyTorch: setting up devices
Caching indices mapping at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-9669db44351ead38.arrow
Caching indices mapping at /home/user/.cache/huggingface/datasets/json/default-2f70bfcf3d4f393c/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-358eb8d308427a40.arrow
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:571] 2024-02-05 09:55:49,558 >> Using auto half precision backend
[2024-02-05 09:55:49,761] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
Running tokenizer on dataset (num_proc=16):   0%|          | 0/699 [00:00<?, ? examples/s]/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.
  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)
Running tokenizer on dataset (num_proc=16):   6%|▋         | 44/699 [00:00<00:06, 106.57 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 699/699 [00:00<00:00, 751.22 examples/s]
[2024-02-05 09:56:12,971] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-02-05 09:56:12,973] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2024-02-05 09:56:12,973] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-02-05 09:56:12,977] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-02-05 09:56:12,977] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-02-05 09:56:12,977] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2024-02-05 09:56:12,977] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500000000
[2024-02-05 09:56:12,977] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500000000
[2024-02-05 09:56:12,978] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2024-02-05 09:56:12,978] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Rank: 1 partition count [2] and sizes[(3276800, False)] 
Rank: 0 partition count [2] and sizes[(3276800, False)] 
[2024-02-05 09:56:15,579] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2024-02-05 09:56:15,579] [INFO] [utils.py:786:see_memory_usage] MA 25.94 GB         Max_MA 25.95 GB         CA 25.96 GB         Max_CA 26 GB 
[2024-02-05 09:56:15,580] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 34.76 GB, percent = 6.9%
[2024-02-05 09:56:15,723] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2024-02-05 09:56:15,723] [INFO] [utils.py:786:see_memory_usage] MA 25.96 GB         Max_MA 26.0 GB         CA 26.03 GB         Max_CA 26 GB 
[2024-02-05 09:56:15,723] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 34.76 GB, percent = 6.9%
[2024-02-05 09:56:15,724] [INFO] [stage_1_and_2.py:493:__init__] optimizer state initialized
[2024-02-05 09:56:15,868] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2024-02-05 09:56:15,868] [INFO] [utils.py:786:see_memory_usage] MA 25.96 GB         Max_MA 25.96 GB         CA 26.03 GB         Max_CA 26 GB 
[2024-02-05 09:56:15,868] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 34.76 GB, percent = 6.9%
[2024-02-05 09:56:15,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-02-05 09:56:15,871] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-02-05 09:56:15,872] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-02-05 09:56:15,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]
[2024-02-05 09:56:15,875] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2024-02-05 09:56:15,876] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-02-05 09:56:15,876] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   amp_enabled .................. False
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   amp_params ................... False
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   bfloat16_enabled ............. False
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2024-02-05 09:56:15,877] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2024-02-05 09:56:15,878] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6c5e7a8970>
[2024-02-05 09:56:15,879] [INFO] [config.py:964:print]   communication_data_type ...... None
[2024-02-05 09:56:15,879] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-02-05 09:56:15,880] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2024-02-05 09:56:15,880] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   disable_allgather ............ False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   dump_state ................... False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2024-02-05 09:56:15,881] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2024-02-05 09:56:15,882] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-02-05 09:56:15,883] [INFO] [config.py:964:print]   fp16_auto_cast ............... False
[2024-02-05 09:56:15,883] [INFO] [config.py:964:print]   fp16_enabled ................. True
[2024-02-05 09:56:15,884] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2024-02-05 09:56:15,884] [INFO] [config.py:964:print]   global_rank .................. 0
[2024-02-05 09:56:15,885] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2024-02-05 09:56:15,885] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 2
[2024-02-05 09:56:15,886] [INFO] [config.py:964:print]   gradient_clipping ............ 0.0
[2024-02-05 09:56:15,887] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2024-02-05 09:56:15,888] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-02-05 09:56:15,888] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 65536
[2024-02-05 09:56:15,888] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2024-02-05 09:56:15,888] [INFO] [config.py:964:print]   loss_scale ................... 0
[2024-02-05 09:56:15,889] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2024-02-05 09:56:15,889] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2024-02-05 09:56:15,889] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2024-02-05 09:56:15,889] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-02-05 09:56:15,891] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-02-05 09:56:15,891] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2024-02-05 09:56:15,891] [INFO] [config.py:964:print]   optimizer_name ............... None
[2024-02-05 09:56:15,891] [INFO] [config.py:964:print]   optimizer_params ............. None
[2024-02-05 09:56:15,891] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-02-05 09:56:15,893] [INFO] [config.py:964:print]   pld_enabled .................. False
[2024-02-05 09:56:15,893] [INFO] [config.py:964:print]   pld_params ................... False
[2024-02-05 09:56:15,893] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2024-02-05 09:56:15,893] [INFO] [config.py:964:print]   scheduler_name ............... None
[2024-02-05 09:56:15,893] [INFO] [config.py:964:print]   scheduler_params ............. None
[2024-02-05 09:56:15,894] [INFO] [config.py:964:print]   sparse_attention ............. None
[2024-02-05 09:56:15,895] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2024-02-05 09:56:15,895] [INFO] [config.py:964:print]   steps_per_print .............. inf
[2024-02-05 09:56:15,895] [INFO] [config.py:964:print]   train_batch_size ............. 16
[2024-02-05 09:56:15,895] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  4
[2024-02-05 09:56:15,897] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2024-02-05 09:56:15,897] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2024-02-05 09:56:15,897] [INFO] [config.py:964:print]   world_size ................... 2
[2024-02-05 09:56:15,899] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2024-02-05 09:56:15,899] [INFO] [config.py:964:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2024-02-05 09:56:15,899] [INFO] [config.py:964:print]   zero_enabled ................. True
[2024-02-05 09:56:15,901] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2024-02-05 09:56:15,901] [INFO] [config.py:964:print]   zero_optimization_stage ...... 2
[2024-02-05 09:56:15,902] [INFO] [config.py:950:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 2, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 16, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 5.000000e+08, 
        "overlap_comm": false, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": false
    }
}
[INFO|trainer.py:1721] 2024-02-05 09:56:15,903 >> ***** Running training *****
[INFO|trainer.py:1722] 2024-02-05 09:56:15,903 >>   Num examples = 629
[INFO|trainer.py:1723] 2024-02-05 09:56:15,904 >>   Num Epochs = 50
[INFO|trainer.py:1724] 2024-02-05 09:56:15,904 >>   Instantaneous batch size per device = 4
[INFO|trainer.py:1727] 2024-02-05 09:56:15,905 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1728] 2024-02-05 09:56:15,905 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1729] 2024-02-05 09:56:15,906 >>   Total optimization steps = 1,950
[INFO|trainer.py:1730] 2024-02-05 09:56:15,909 >>   Number of trainable parameters = 6,553,600
  0%|          | 0/1950 [00:00<?, ?it/s]  0%|          | 1/1950 [00:06<3:17:25,  6.08s/it]  0%|          | 2/1950 [00:08<2:02:31,  3.77s/it]  0%|          | 3/1950 [00:10<1:38:56,  3.05s/it]  0%|          | 4/1950 [00:13<1:33:18,  2.88s/it]  0%|          | 5/1950 [00:15<1:27:21,  2.70s/it]                                                  {'loss': 2.2673, 'learning_rate': 4.99991888929132e-05, 'epoch': 0.13}
  0%|          | 5/1950 [00:15<1:27:21,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 09:56:31,332 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:56:31,332 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:56:31,332 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.98it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.17it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                  
                                             [A{'eval_loss': 2.142578125, 'eval_runtime': 3.8755, 'eval_samples_per_second': 18.062, 'eval_steps_per_second': 2.322, 'epoch': 0.13}
  0%|          | 5/1950 [00:19<1:27:21,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A  0%|          | 6/1950 [00:21<2:05:35,  3.88s/it]  0%|          | 7/1950 [00:24<1:51:07,  3.43s/it]  0%|          | 8/1950 [00:26<1:41:18,  3.13s/it]  0%|          | 9/1950 [00:28<1:31:54,  2.84s/it]  1%|          | 10/1950 [00:31<1:27:20,  2.70s/it]                                                   {'loss': 1.9802, 'learning_rate': 4.999675562428437e-05, 'epoch': 0.25}
  1%|          | 10/1950 [00:31<1:27:20,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 09:56:47,095 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:56:47,096 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:56:47,096 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.12it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                   
                                             [A{'eval_loss': 1.8232421875, 'eval_runtime': 3.1979, 'eval_samples_per_second': 21.889, 'eval_steps_per_second': 2.814, 'epoch': 0.25}
  1%|          | 10/1950 [00:34<1:27:20,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A  1%|          | 11/1950 [00:36<1:57:11,  3.63s/it]  1%|          | 12/1950 [00:39<1:45:19,  3.26s/it]  1%|          | 13/1950 [00:41<1:36:54,  3.00s/it]  1%|          | 14/1950 [00:44<1:29:56,  2.79s/it]  1%|          | 15/1950 [00:46<1:27:50,  2.72s/it]                                                   {'loss': 1.6816, 'learning_rate': 4.999270035200483e-05, 'epoch': 0.38}
  1%|          | 15/1950 [00:46<1:27:50,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 09:57:02,518 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:57:02,518 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:57:02,518 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.94it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                   
                                             [A{'eval_loss': 1.4951171875, 'eval_runtime': 3.21, 'eval_samples_per_second': 21.807, 'eval_steps_per_second': 2.804, 'epoch': 0.38}
  1%|          | 15/1950 [00:49<1:27:50,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A  1%|          | 16/1950 [00:52<1:56:43,  3.62s/it]  1%|          | 17/1950 [00:55<1:48:07,  3.36s/it]  1%|          | 18/1950 [00:57<1:39:15,  3.08s/it]  1%|          | 19/1950 [00:59<1:33:01,  2.89s/it]  1%|          | 20/1950 [01:02<1:29:42,  2.79s/it]                                                   {'loss': 1.381, 'learning_rate': 4.9987023339215374e-05, 'epoch': 0.51}
  1%|          | 20/1950 [01:02<1:29:42,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 09:57:18,403 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:57:18,404 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:57:18,404 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.53it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                   
                                             [A{'eval_loss': 1.2109375, 'eval_runtime': 3.2293, 'eval_samples_per_second': 21.677, 'eval_steps_per_second': 2.787, 'epoch': 0.51}
  1%|          | 20/1950 [01:05<1:29:42,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A  1%|          | 21/1950 [01:08<1:56:05,  3.61s/it]  1%|          | 22/1950 [01:10<1:48:28,  3.38s/it]  1%|          | 23/1950 [01:13<1:38:14,  3.06s/it]  1%|          | 24/1950 [01:15<1:35:56,  2.99s/it]  1%|▏         | 25/1950 [01:18<1:29:24,  2.79s/it]                                                   {'loss': 1.0822, 'learning_rate': 4.9979724954289244e-05, 'epoch': 0.63}
  1%|▏         | 25/1950 [01:18<1:29:24,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 09:57:34,219 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:57:34,219 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:57:34,219 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.87it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                   
                                             [A{'eval_loss': 0.970703125, 'eval_runtime': 3.2417, 'eval_samples_per_second': 21.594, 'eval_steps_per_second': 2.776, 'epoch': 0.63}
  1%|▏         | 25/1950 [01:21<1:29:24,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A  1%|▏         | 26/1950 [01:24<1:57:52,  3.68s/it]  1%|▏         | 27/1950 [01:26<1:44:41,  3.27s/it]  1%|▏         | 28/1950 [01:28<1:35:13,  2.97s/it]  1%|▏         | 29/1950 [01:31<1:29:59,  2.81s/it]  2%|▏         | 30/1950 [01:33<1:26:11,  2.69s/it]                                                   {'loss': 0.8688, 'learning_rate': 4.997080567080817e-05, 'epoch': 0.76}
  2%|▏         | 30/1950 [01:33<1:26:11,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 09:57:49,420 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:57:49,420 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:57:49,420 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                   
                                             [A{'eval_loss': 0.7138671875, 'eval_runtime': 3.2585, 'eval_samples_per_second': 21.482, 'eval_steps_per_second': 2.762, 'epoch': 0.76}
  2%|▏         | 30/1950 [01:36<1:26:11,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A  2%|▏         | 31/1950 [01:39<1:53:36,  3.55s/it]  2%|▏         | 32/1950 [01:41<1:42:59,  3.22s/it]  2%|▏         | 33/1950 [01:44<1:36:50,  3.03s/it]  2%|▏         | 34/1950 [01:46<1:30:11,  2.82s/it]  2%|▏         | 35/1950 [01:48<1:25:31,  2.68s/it]                                                   {'loss': 0.6028, 'learning_rate': 4.996026606753167e-05, 'epoch': 0.89}
  2%|▏         | 35/1950 [01:48<1:25:31,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 09:58:04,697 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:58:04,698 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:58:04,698 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                   
                                             [A{'eval_loss': 0.48876953125, 'eval_runtime': 3.2706, 'eval_samples_per_second': 21.403, 'eval_steps_per_second': 2.752, 'epoch': 0.89}
  2%|▏         | 35/1950 [01:52<1:25:31,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A  2%|▏         | 36/1950 [01:54<1:54:06,  3.58s/it]  2%|▏         | 37/1950 [01:56<1:42:19,  3.21s/it]  2%|▏         | 38/1950 [01:59<1:34:38,  2.97s/it]  2%|▏         | 39/1950 [02:01<1:29:43,  2.82s/it]  2%|▏         | 40/1950 [02:03<1:24:41,  2.66s/it]                                                   {'loss': 0.3983, 'learning_rate': 4.994810682835951e-05, 'epoch': 1.01}
  2%|▏         | 40/1950 [02:03<1:24:41,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 09:58:19,886 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:58:19,886 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:58:19,886 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                   
                                             [A{'eval_loss': 0.356689453125, 'eval_runtime': 3.2825, 'eval_samples_per_second': 21.325, 'eval_steps_per_second': 2.742, 'epoch': 1.01}
  2%|▏         | 40/1950 [02:07<1:24:41,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A  2%|▏         | 41/1950 [02:09<1:51:38,  3.51s/it]  2%|▏         | 42/1950 [02:11<1:39:46,  3.14s/it]  2%|▏         | 43/1950 [02:14<1:32:55,  2.92s/it]  2%|▏         | 44/1950 [02:16<1:28:25,  2.78s/it]  2%|▏         | 45/1950 [02:18<1:24:12,  2.65s/it]                                                   {'loss': 0.2932, 'learning_rate': 4.9934328742287285e-05, 'epoch': 1.14}
  2%|▏         | 45/1950 [02:18<1:24:12,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 09:58:34,874 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:58:34,874 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:58:34,874 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.28955078125, 'eval_runtime': 3.2887, 'eval_samples_per_second': 21.285, 'eval_steps_per_second': 2.737, 'epoch': 1.14}
  2%|▏         | 45/1950 [02:22<1:24:12,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  2%|▏         | 46/1950 [02:24<1:54:30,  3.61s/it]  2%|▏         | 47/1950 [02:27<1:45:47,  3.34s/it]  2%|▏         | 48/1950 [02:29<1:36:10,  3.03s/it]  3%|▎         | 49/1950 [02:32<1:29:29,  2.82s/it]  3%|▎         | 50/1950 [02:34<1:25:09,  2.69s/it]                                                   {'loss': 0.2768, 'learning_rate': 4.9918932703355256e-05, 'epoch': 1.27}
  3%|▎         | 50/1950 [02:34<1:25:09,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 09:58:50,452 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:58:50,452 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:58:50,452 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.24658203125, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 1.27}
  3%|▎         | 50/1950 [02:37<1:25:09,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  3%|▎         | 51/1950 [02:40<1:54:54,  3.63s/it]  3%|▎         | 52/1950 [02:42<1:44:37,  3.31s/it]  3%|▎         | 53/1950 [02:45<1:36:25,  3.05s/it]  3%|▎         | 54/1950 [02:47<1:31:18,  2.89s/it]  3%|▎         | 55/1950 [02:50<1:27:44,  2.78s/it]                                                   {'loss': 0.2253, 'learning_rate': 4.990191971059033e-05, 'epoch': 1.39}
  3%|▎         | 55/1950 [02:50<1:27:44,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 09:59:06,314 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:59:06,314 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:59:06,314 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.223876953125, 'eval_runtime': 3.2971, 'eval_samples_per_second': 21.231, 'eval_steps_per_second': 2.73, 'epoch': 1.39}
  3%|▎         | 55/1950 [02:53<1:27:44,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  3%|▎         | 56/1950 [02:56<1:57:58,  3.74s/it]  3%|▎         | 57/1950 [02:59<1:48:40,  3.44s/it]  3%|▎         | 58/1950 [03:01<1:37:56,  3.11s/it]  3%|▎         | 59/1950 [03:04<1:35:10,  3.02s/it]  3%|▎         | 60/1950 [03:06<1:29:28,  2.84s/it]                                                   {'loss': 0.2238, 'learning_rate': 4.988329086794122e-05, 'epoch': 1.52}
  3%|▎         | 60/1950 [03:06<1:29:28,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 09:59:22,611 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:59:22,611 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:59:22,611 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.2080078125, 'eval_runtime': 3.2964, 'eval_samples_per_second': 21.235, 'eval_steps_per_second': 2.73, 'epoch': 1.52}
  3%|▎         | 60/1950 [03:09<1:29:28,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  3%|▎         | 61/1950 [03:12<2:01:40,  3.86s/it]  3%|▎         | 62/1950 [03:15<1:47:19,  3.41s/it]  3%|▎         | 63/1950 [03:18<1:40:52,  3.21s/it]  3%|▎         | 64/1950 [03:20<1:34:19,  3.00s/it]  3%|▎         | 65/1950 [03:23<1:30:46,  2.89s/it]                                                   {'loss': 0.1688, 'learning_rate': 4.9863047384206835e-05, 'epoch': 1.65}
  3%|▎         | 65/1950 [03:23<1:30:46,  2.89s/it][INFO|trainer.py:3242] 2024-02-05 09:59:39,097 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:59:39,097 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:59:39,097 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1961669921875, 'eval_runtime': 3.2943, 'eval_samples_per_second': 21.249, 'eval_steps_per_second': 2.732, 'epoch': 1.65}
  3%|▎         | 65/1950 [03:26<1:30:46,  2.89s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  3%|▎         | 66/1950 [03:28<1:55:56,  3.69s/it]  3%|▎         | 67/1950 [03:31<1:44:33,  3.33s/it]  3%|▎         | 68/1950 [03:33<1:35:28,  3.04s/it]  4%|▎         | 69/1950 [03:35<1:29:17,  2.85s/it]  4%|▎         | 70/1950 [03:38<1:24:41,  2.70s/it]                                                   {'loss': 0.1871, 'learning_rate': 4.984119057295783e-05, 'epoch': 1.77}
  4%|▎         | 70/1950 [03:38<1:24:41,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 09:59:54,280 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 09:59:54,280 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 09:59:54,280 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1884765625, 'eval_runtime': 3.2978, 'eval_samples_per_second': 21.227, 'eval_steps_per_second': 2.729, 'epoch': 1.77}
  4%|▎         | 70/1950 [03:41<1:24:41,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  4%|▎         | 71/1950 [03:44<1:53:21,  3.62s/it]  4%|▎         | 72/1950 [03:46<1:45:34,  3.37s/it]  4%|▎         | 73/1950 [03:49<1:35:26,  3.05s/it]  4%|▍         | 74/1950 [03:51<1:27:41,  2.80s/it]  4%|▍         | 75/1950 [03:53<1:23:05,  2.66s/it]                                                   {'loss': 0.1758, 'learning_rate': 4.981772185245135e-05, 'epoch': 1.9}
  4%|▍         | 75/1950 [03:53<1:23:05,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 10:00:09,685 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:00:09,685 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:00:09,685 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1798095703125, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.244, 'eval_steps_per_second': 2.731, 'epoch': 1.9}
  4%|▍         | 75/1950 [03:57<1:23:05,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  4%|▍         | 76/1950 [03:59<1:52:46,  3.61s/it]  4%|▍         | 77/1950 [04:01<1:40:47,  3.23s/it]  4%|▍         | 78/1950 [04:04<1:32:36,  2.97s/it]  4%|▍         | 79/1950 [04:06<1:27:11,  2.80s/it]  4%|▍         | 80/1950 [04:08<1:22:23,  2.64s/it]                                                   {'loss': 0.1537, 'learning_rate': 4.979264274553905e-05, 'epoch': 2.03}
  4%|▍         | 80/1950 [04:08<1:22:23,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 10:00:24,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:00:24,896 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:00:24,896 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1724853515625, 'eval_runtime': 3.2962, 'eval_samples_per_second': 21.236, 'eval_steps_per_second': 2.73, 'epoch': 2.03}
  4%|▍         | 80/1950 [04:12<1:22:23,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  4%|▍         | 81/1950 [04:14<1:49:28,  3.51s/it]  4%|▍         | 82/1950 [04:16<1:37:35,  3.13s/it]  4%|▍         | 83/1950 [04:19<1:32:20,  2.97s/it]  4%|▍         | 84/1950 [04:21<1:27:11,  2.80s/it]  4%|▍         | 85/1950 [04:24<1:22:27,  2.65s/it]                                                   {'loss': 0.1335, 'learning_rate': 4.976595487956823e-05, 'epoch': 2.15}
  4%|▍         | 85/1950 [04:24<1:22:27,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 10:00:39,990 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:00:39,991 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:00:39,991 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1658935546875, 'eval_runtime': 3.2964, 'eval_samples_per_second': 21.236, 'eval_steps_per_second': 2.73, 'epoch': 2.15}
  4%|▍         | 85/1950 [04:27<1:22:27,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  4%|▍         | 86/1950 [04:29<1:51:08,  3.58s/it]  4%|▍         | 87/1950 [04:32<1:41:12,  3.26s/it]  5%|▍         | 88/1950 [04:34<1:31:51,  2.96s/it]  5%|▍         | 89/1950 [04:36<1:26:26,  2.79s/it]  5%|▍         | 90/1950 [04:39<1:23:34,  2.70s/it]                                                   {'loss': 0.1676, 'learning_rate': 4.973765998627628e-05, 'epoch': 2.28}
  5%|▍         | 90/1950 [04:39<1:23:34,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:00:55,371 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:00:55,371 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:00:55,371 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.16015625, 'eval_runtime': 3.2906, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 2.28}
  5%|▍         | 90/1950 [04:42<1:23:34,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  5%|▍         | 91/1950 [04:45<1:52:25,  3.63s/it]  5%|▍         | 92/1950 [04:47<1:42:05,  3.30s/it]  5%|▍         | 93/1950 [04:50<1:32:08,  2.98s/it]  5%|▍         | 94/1950 [04:52<1:27:24,  2.83s/it]  5%|▍         | 95/1950 [04:54<1:23:20,  2.70s/it]                                                   {'loss': 0.1455, 'learning_rate': 4.970775990167826e-05, 'epoch': 2.41}
  5%|▍         | 95/1950 [04:54<1:23:20,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:01:10,795 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:01:10,795 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:01:10,795 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                   
                                             [A{'eval_loss': 0.1544189453125, 'eval_runtime': 3.2955, 'eval_samples_per_second': 21.241, 'eval_steps_per_second': 2.731, 'epoch': 2.41}
  5%|▍         | 95/1950 [04:58<1:23:20,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  5%|▍         | 96/1950 [05:00<1:54:40,  3.71s/it]  5%|▍         | 97/1950 [05:03<1:42:45,  3.33s/it]  5%|▌         | 98/1950 [05:05<1:34:36,  3.07s/it]  5%|▌         | 99/1950 [05:08<1:30:55,  2.95s/it]  5%|▌         | 100/1950 [05:10<1:26:16,  2.80s/it]                                                    {'loss': 0.1545, 'learning_rate': 4.967625656594782e-05, 'epoch': 2.53}
  5%|▌         | 100/1950 [05:10<1:26:16,  2.80s/it][INFO|trainer.py:3242] 2024-02-05 10:01:26,886 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:01:26,886 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:01:26,886 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.15234375, 'eval_runtime': 3.2923, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 2.53}
  5%|▌         | 100/1950 [05:14<1:26:16,  2.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 10:01:43,917 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 10:01:44,063 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 10:01:44,064 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/special_tokens_map.json
[2024-02-05 10:01:45,124] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 10:01:58,973] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/mp_rank_00_model_states.pt
[2024-02-05 10:01:58,973] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/mp_rank_00_model_states.pt...
[2024-02-05 10:09:54,729] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/mp_rank_00_model_states.pt.
[2024-02-05 10:09:55,695] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 10:09:56,375] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 10:09:56,379] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-100/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 10:09:56,379] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!
  5%|▌         | 101/1950 [13:43<79:57:44, 155.69s/it]  5%|▌         | 102/1950 [13:45<56:17:28, 109.66s/it]  5%|▌         | 103/1950 [13:48<39:47:53, 77.57s/it]   5%|▌         | 104/1950 [13:50<28:11:27, 54.98s/it]  5%|▌         | 105/1950 [13:53<20:06:14, 39.23s/it]                                                     {'loss': 0.1271, 'learning_rate': 4.964315202329127e-05, 'epoch': 2.66}
  5%|▌         | 105/1950 [13:53<20:06:14, 39.23s/it][INFO|trainer.py:3242] 2024-02-05 10:10:09,016 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:10:09,016 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:10:09,016 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.00it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                     
                                             [A{'eval_loss': 0.15185546875, 'eval_runtime': 3.1861, 'eval_samples_per_second': 21.971, 'eval_steps_per_second': 2.825, 'epoch': 2.66}
  5%|▌         | 105/1950 [13:56<20:06:14, 39.23s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A  5%|▌         | 106/1950 [13:58<14:55:53, 29.15s/it][2024-02-05 10:10:16,953] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
  5%|▌         | 107/1950 [14:01<10:48:12, 21.10s/it]  6%|▌         | 108/1950 [14:03<7:56:08, 15.51s/it]   6%|▌         | 109/1950 [14:05<5:55:29, 11.59s/it]  6%|▌         | 110/1950 [14:08<4:30:16,  8.81s/it]                                                    {'loss': 0.1303, 'learning_rate': 4.961551696021918e-05, 'epoch': 2.78}
  6%|▌         | 110/1950 [14:08<4:30:16,  8.81s/it][INFO|trainer.py:3242] 2024-02-05 10:10:24,201 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:10:24,201 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:10:24,201 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                    
                                             [A{'eval_loss': 0.1500244140625, 'eval_runtime': 3.2057, 'eval_samples_per_second': 21.836, 'eval_steps_per_second': 2.807, 'epoch': 2.78}
  6%|▌         | 110/1950 [14:11<4:30:16,  8.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A  6%|▌         | 111/1950 [14:13<4:01:19,  7.87s/it]  6%|▌         | 112/1950 [14:16<3:12:23,  6.28s/it]  6%|▌         | 113/1950 [14:18<2:35:14,  5.07s/it]  6%|▌         | 114/1950 [14:21<2:10:06,  4.25s/it]  6%|▌         | 115/1950 [14:23<1:51:53,  3.66s/it]                                                    {'loss': 0.1235, 'learning_rate': 4.957953572805558e-05, 'epoch': 2.91}
  6%|▌         | 115/1950 [14:23<1:51:53,  3.66s/it][INFO|trainer.py:3242] 2024-02-05 10:10:39,308 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:10:39,308 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:10:39,308 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.09it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                    
                                             [A{'eval_loss': 0.14501953125, 'eval_runtime': 3.2225, 'eval_samples_per_second': 21.722, 'eval_steps_per_second': 2.793, 'epoch': 2.91}
  6%|▌         | 115/1950 [14:26<1:51:53,  3.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A  6%|▌         | 116/1950 [14:28<2:08:51,  4.22s/it]  6%|▌         | 117/1950 [14:31<1:51:49,  3.66s/it]  6%|▌         | 118/1950 [14:33<1:40:55,  3.31s/it]  6%|▌         | 119/1950 [14:35<1:31:07,  2.99s/it]  6%|▌         | 120/1950 [14:38<1:23:34,  2.74s/it]                                                    {'loss': 0.127, 'learning_rate': 4.954195956504245e-05, 'epoch': 3.04}
  6%|▌         | 120/1950 [14:38<1:23:34,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 10:10:54,073 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:10:54,073 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:10:54,073 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                    
                                             [A{'eval_loss': 0.142822265625, 'eval_runtime': 3.2373, 'eval_samples_per_second': 21.623, 'eval_steps_per_second': 2.78, 'epoch': 3.04}
  6%|▌         | 120/1950 [14:41<1:23:34,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A  6%|▌         | 121/1950 [14:43<1:48:16,  3.55s/it]  6%|▋         | 122/1950 [14:45<1:36:54,  3.18s/it]  6%|▋         | 123/1950 [14:48<1:30:03,  2.96s/it]  6%|▋         | 124/1950 [14:50<1:24:47,  2.79s/it]  6%|▋         | 125/1950 [14:53<1:21:11,  2.67s/it]                                                    {'loss': 0.0991, 'learning_rate': 4.950279090944313e-05, 'epoch': 3.16}
  6%|▋         | 125/1950 [14:53<1:21:11,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:11:09,050 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:11:09,051 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:11:09,051 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.1407470703125, 'eval_runtime': 3.2462, 'eval_samples_per_second': 21.564, 'eval_steps_per_second': 2.772, 'epoch': 3.16}
  6%|▋         | 125/1950 [14:56<1:21:11,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A  6%|▋         | 126/1950 [14:59<1:50:32,  3.64s/it]  7%|▋         | 127/1950 [15:01<1:37:45,  3.22s/it]  7%|▋         | 128/1950 [15:03<1:29:18,  2.94s/it]  7%|▋         | 129/1950 [15:05<1:23:54,  2.76s/it]  7%|▋         | 130/1950 [15:08<1:21:31,  2.69s/it]                                                    {'loss': 0.1347, 'learning_rate': 4.9462032302855576e-05, 'epoch': 3.29}
  7%|▋         | 130/1950 [15:08<1:21:31,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 10:11:24,342 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:11:24,342 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:11:24,342 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.13916015625, 'eval_runtime': 3.2655, 'eval_samples_per_second': 21.436, 'eval_steps_per_second': 2.756, 'epoch': 3.29}
  7%|▋         | 130/1950 [15:11<1:21:31,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A  7%|▋         | 131/1950 [15:14<1:48:36,  3.58s/it]  7%|▋         | 132/1950 [15:16<1:37:00,  3.20s/it]  7%|▋         | 133/1950 [15:18<1:30:01,  2.97s/it]  7%|▋         | 134/1950 [15:21<1:26:42,  2.86s/it]  7%|▋         | 135/1950 [15:24<1:24:03,  2.78s/it]                                                    {'loss': 0.1161, 'learning_rate': 4.9419686390047334e-05, 'epoch': 3.42}
  7%|▋         | 135/1950 [15:24<1:24:03,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 10:11:39,955 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:11:39,955 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:11:39,955 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.1368408203125, 'eval_runtime': 3.2788, 'eval_samples_per_second': 21.349, 'eval_steps_per_second': 2.745, 'epoch': 3.42}
  7%|▋         | 135/1950 [15:27<1:24:03,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A  7%|▋         | 136/1950 [15:29<1:51:29,  3.69s/it]  7%|▋         | 137/1950 [15:32<1:38:51,  3.27s/it]  7%|▋         | 138/1950 [15:35<1:35:15,  3.15s/it]  7%|▋         | 139/1950 [15:37<1:27:24,  2.90s/it]  7%|▋         | 140/1950 [15:40<1:27:19,  2.89s/it]                                                    {'loss': 0.122, 'learning_rate': 4.937575591878403e-05, 'epoch': 3.54}
  7%|▋         | 140/1950 [15:40<1:27:19,  2.89s/it][INFO|trainer.py:3242] 2024-02-05 10:11:56,130 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:11:56,131 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:11:56,131 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.137451171875, 'eval_runtime': 3.286, 'eval_samples_per_second': 21.303, 'eval_steps_per_second': 2.739, 'epoch': 3.54}
  7%|▋         | 140/1950 [15:43<1:27:19,  2.89s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A  7%|▋         | 141/1950 [15:45<1:52:05,  3.72s/it]  7%|▋         | 142/1950 [15:48<1:43:03,  3.42s/it]  7%|▋         | 143/1950 [15:50<1:33:36,  3.11s/it]  7%|▋         | 144/1950 [15:53<1:28:15,  2.93s/it]  7%|▋         | 145/1950 [15:55<1:22:47,  2.75s/it]                                                    {'loss': 0.1026, 'learning_rate': 4.9330243739650964e-05, 'epoch': 3.67}
  7%|▋         | 145/1950 [15:55<1:22:47,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:12:11,727 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:12:11,727 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:12:11,727 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.137939453125, 'eval_runtime': 3.2933, 'eval_samples_per_second': 21.256, 'eval_steps_per_second': 2.733, 'epoch': 3.67}
  7%|▋         | 145/1950 [15:59<1:22:47,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  7%|▋         | 146/1950 [16:01<1:50:01,  3.66s/it]  8%|▊         | 147/1950 [16:04<1:39:23,  3.31s/it]  8%|▊         | 148/1950 [16:06<1:31:51,  3.06s/it]  8%|▊         | 149/1950 [16:09<1:26:21,  2.88s/it]  8%|▊         | 150/1950 [16:11<1:21:28,  2.72s/it]                                                    {'loss': 0.1062, 'learning_rate': 4.9283152805868235e-05, 'epoch': 3.8}
  8%|▊         | 150/1950 [16:11<1:21:28,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 10:12:27,261 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:12:27,262 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:12:27,262 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1337890625, 'eval_runtime': 3.2923, 'eval_samples_per_second': 21.262, 'eval_steps_per_second': 2.734, 'epoch': 3.8}
  8%|▊         | 150/1950 [16:14<1:21:28,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  8%|▊         | 151/1950 [16:17<1:51:16,  3.71s/it]  8%|▊         | 152/1950 [16:19<1:38:34,  3.29s/it]  8%|▊         | 153/1950 [16:21<1:28:59,  2.97s/it]  8%|▊         | 154/1950 [16:24<1:23:16,  2.78s/it]  8%|▊         | 155/1950 [16:26<1:19:53,  2.67s/it]                                                    {'loss': 0.1112, 'learning_rate': 4.923448617309905e-05, 'epoch': 3.92}
  8%|▊         | 155/1950 [16:26<1:19:53,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:12:42,581 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:12:42,582 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:12:42,582 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1314697265625, 'eval_runtime': 3.2924, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 3.92}
  8%|▊         | 155/1950 [16:29<1:19:53,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  8%|▊         | 156/1950 [16:32<1:47:08,  3.58s/it]  8%|▊         | 157/1950 [16:34<1:36:21,  3.22s/it]  8%|▊         | 158/1950 [16:37<1:28:08,  2.95s/it]  8%|▊         | 159/1950 [16:39<1:22:06,  2.75s/it]  8%|▊         | 160/1950 [16:41<1:18:23,  2.63s/it]                                                    {'loss': 0.0866, 'learning_rate': 4.918424699925145e-05, 'epoch': 4.05}
  8%|▊         | 160/1950 [16:41<1:18:23,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 10:12:57,617 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:12:57,617 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:12:57,617 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1331787109375, 'eval_runtime': 3.2908, 'eval_samples_per_second': 21.271, 'eval_steps_per_second': 2.735, 'epoch': 4.05}
  8%|▊         | 160/1950 [16:44<1:18:23,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  8%|▊         | 161/1950 [16:47<1:45:12,  3.53s/it]  8%|▊         | 162/1950 [16:49<1:36:32,  3.24s/it]  8%|▊         | 163/1950 [16:52<1:29:09,  2.99s/it]  8%|▊         | 164/1950 [16:54<1:22:57,  2.79s/it]  8%|▊         | 165/1950 [16:57<1:20:38,  2.71s/it]                                                    {'loss': 0.0928, 'learning_rate': 4.913243854427346e-05, 'epoch': 4.18}
  8%|▊         | 165/1950 [16:57<1:20:38,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 10:13:13,071 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:13:13,072 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:13:13,072 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.12939453125, 'eval_runtime': 3.2889, 'eval_samples_per_second': 21.284, 'eval_steps_per_second': 2.736, 'epoch': 4.18}
  8%|▊         | 165/1950 [17:00<1:20:38,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  9%|▊         | 166/1950 [17:02<1:47:45,  3.62s/it]  9%|▊         | 167/1950 [17:05<1:36:20,  3.24s/it]  9%|▊         | 168/1950 [17:07<1:28:32,  2.98s/it]  9%|▊         | 169/1950 [17:10<1:23:42,  2.82s/it]  9%|▊         | 170/1950 [17:12<1:20:04,  2.70s/it]                                                    {'loss': 0.0999, 'learning_rate': 4.907906416994146e-05, 'epoch': 4.3}
  9%|▊         | 170/1950 [17:12<1:20:04,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:13:28,412 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:13:28,412 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:13:28,412 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.130859375, 'eval_runtime': 3.2933, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 4.3}
  9%|▊         | 170/1950 [17:15<1:20:04,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  9%|▉         | 171/1950 [17:18<1:47:32,  3.63s/it]  9%|▉         | 172/1950 [17:20<1:35:16,  3.22s/it]  9%|▉         | 173/1950 [17:23<1:29:36,  3.03s/it]  9%|▉         | 174/1950 [17:25<1:24:39,  2.86s/it]  9%|▉         | 175/1950 [17:28<1:22:22,  2.78s/it]                                                    {'loss': 0.1028, 'learning_rate': 4.902412733964211e-05, 'epoch': 4.43}
  9%|▉         | 175/1950 [17:28<1:22:22,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 10:13:44,124 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:13:44,124 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:13:44,124 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.129150390625, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 4.43}
  9%|▉         | 175/1950 [17:31<1:22:22,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  9%|▉         | 176/1950 [17:33<1:48:17,  3.66s/it]  9%|▉         | 177/1950 [17:36<1:38:17,  3.33s/it]  9%|▉         | 178/1950 [17:39<1:31:55,  3.11s/it]  9%|▉         | 179/1950 [17:41<1:24:50,  2.87s/it]  9%|▉         | 180/1950 [17:44<1:24:07,  2.85s/it]                                                    {'loss': 0.099, 'learning_rate': 4.896763161814761e-05, 'epoch': 4.56}
  9%|▉         | 180/1950 [17:44<1:24:07,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 10:14:00,107 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:14:00,107 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:14:00,107 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.13427734375, 'eval_runtime': 3.2917, 'eval_samples_per_second': 21.266, 'eval_steps_per_second': 2.734, 'epoch': 4.56}
  9%|▉         | 180/1950 [17:47<1:24:07,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A  9%|▉         | 181/1950 [17:49<1:49:34,  3.72s/it]  9%|▉         | 182/1950 [17:52<1:41:42,  3.45s/it]  9%|▉         | 183/1950 [17:55<1:31:42,  3.11s/it]  9%|▉         | 184/1950 [17:57<1:25:40,  2.91s/it]  9%|▉         | 185/1950 [17:59<1:21:15,  2.76s/it]                                                    {'loss': 0.0993, 'learning_rate': 4.890958067138436e-05, 'epoch': 4.68}
  9%|▉         | 185/1950 [17:59<1:21:15,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 10:14:15,854 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:14:15,854 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:14:15,854 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.131591796875, 'eval_runtime': 3.2905, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 4.68}
  9%|▉         | 185/1950 [18:03<1:21:15,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 10%|▉         | 186/1950 [18:05<1:46:05,  3.61s/it] 10%|▉         | 187/1950 [18:08<1:36:10,  3.27s/it] 10%|▉         | 188/1950 [18:10<1:29:07,  3.04s/it] 10%|▉         | 189/1950 [18:12<1:23:41,  2.85s/it] 10%|▉         | 190/1950 [18:15<1:20:41,  2.75s/it]                                                    {'loss': 0.081, 'learning_rate': 4.8849978266195114e-05, 'epoch': 4.81}
 10%|▉         | 190/1950 [18:15<1:20:41,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:14:31,349 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:14:31,349 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:14:31,349 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.1292724609375, 'eval_runtime': 3.282, 'eval_samples_per_second': 21.328, 'eval_steps_per_second': 2.742, 'epoch': 4.81}
 10%|▉         | 190/1950 [18:18<1:20:41,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 10%|▉         | 191/1950 [18:21<1:47:45,  3.68s/it] 10%|▉         | 192/1950 [18:23<1:35:46,  3.27s/it] 10%|▉         | 193/1950 [18:25<1:27:54,  3.00s/it] 10%|▉         | 194/1950 [18:28<1:21:47,  2.79s/it] 10%|█         | 195/1950 [18:30<1:17:25,  2.65s/it]                                                    {'loss': 0.0919, 'learning_rate': 4.878882827009452e-05, 'epoch': 4.94}
 10%|█         | 195/1950 [18:30<1:17:25,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 10:14:46,492 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:14:46,492 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:14:46,492 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.12646484375, 'eval_runtime': 3.2853, 'eval_samples_per_second': 21.307, 'eval_steps_per_second': 2.739, 'epoch': 4.94}
 10%|█         | 195/1950 [18:33<1:17:25,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 10%|█         | 196/1950 [18:36<1:43:31,  3.54s/it] 10%|█         | 197/1950 [18:38<1:34:16,  3.23s/it] 10%|█         | 198/1950 [18:40<1:25:54,  2.94s/it] 10%|█         | 199/1950 [18:43<1:19:20,  2.72s/it] 10%|█         | 200/1950 [18:45<1:16:11,  2.61s/it]                                                    {'loss': 0.0695, 'learning_rate': 4.8726134651018194e-05, 'epoch': 5.06}
 10%|█         | 200/1950 [18:45<1:16:11,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 10:15:01,451 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:15:01,452 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:15:01,452 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.127685546875, 'eval_runtime': 3.2898, 'eval_samples_per_second': 21.278, 'eval_steps_per_second': 2.736, 'epoch': 5.06}
 10%|█         | 200/1950 [18:48<1:16:11,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 10:15:19,853 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 10:15:20,005 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 10:15:20,005 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/special_tokens_map.json
[2024-02-05 10:15:21,064] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 10:15:35,690] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt
[2024-02-05 10:15:35,690] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt...
[2024-02-05 10:23:37,746] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/mp_rank_00_model_states.pt.
[2024-02-05 10:23:38,714] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 10:23:39,395] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 10:23:39,415] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 10:23:39,415] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step200 is ready now!
 10%|█         | 201/1950 [27:25<76:44:33, 157.96s/it] 10%|█         | 202/1950 [27:28<54:02:32, 111.30s/it] 10%|█         | 203/1950 [27:30<38:08:42, 78.60s/it]  10%|█         | 204/1950 [27:33<27:01:24, 55.72s/it] 11%|█         | 205/1950 [27:35<19:17:22, 39.80s/it]                                                     {'loss': 0.0893, 'learning_rate': 4.8661901477065244e-05, 'epoch': 5.19}
 11%|█         | 205/1950 [27:35<19:17:22, 39.80s/it][INFO|trainer.py:3242] 2024-02-05 10:23:51,593 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:23:51,593 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:23:51,593 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.02it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.19it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                     
                                             [A{'eval_loss': 0.12841796875, 'eval_runtime': 3.1836, 'eval_samples_per_second': 21.987, 'eval_steps_per_second': 2.827, 'epoch': 5.19}
 11%|█         | 205/1950 [27:38<19:17:22, 39.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 11%|█         | 206/1950 [27:41<14:16:37, 29.47s/it] 11%|█         | 207/1950 [27:43<10:18:46, 21.30s/it] 11%|█         | 208/1950 [27:45<7:33:13, 15.61s/it]  11%|█         | 209/1950 [27:48<5:39:44, 11.71s/it] 11%|█         | 210/1950 [27:50<4:17:49,  8.89s/it]                                                    {'loss': 0.0783, 'learning_rate': 4.859613291623428e-05, 'epoch': 5.32}
 11%|█         | 210/1950 [27:50<4:17:49,  8.89s/it][INFO|trainer.py:3242] 2024-02-05 10:24:06,462 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:24:06,463 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:24:06,463 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.94it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                    
                                             [A{'eval_loss': 0.1273193359375, 'eval_runtime': 3.1996, 'eval_samples_per_second': 21.878, 'eval_steps_per_second': 2.813, 'epoch': 5.32}
 11%|█         | 210/1950 [27:53<4:17:49,  8.89s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 11%|█         | 211/1950 [27:56<3:49:13,  7.91s/it] 11%|█         | 212/1950 [27:58<3:01:35,  6.27s/it] 11%|█         | 213/1950 [28:01<2:28:21,  5.12s/it] 11%|█         | 214/1950 [28:03<2:05:43,  4.35s/it] 11%|█         | 215/1950 [28:06<1:49:58,  3.80s/it]                                                    {'loss': 0.081, 'learning_rate': 4.852883323615295e-05, 'epoch': 5.44}
 11%|█         | 215/1950 [28:06<1:49:58,  3.80s/it][INFO|trainer.py:3242] 2024-02-05 10:24:22,042 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:24:22,042 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:24:22,042 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.93it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                    
                                             [A{'eval_loss': 0.1273193359375, 'eval_runtime': 3.2156, 'eval_samples_per_second': 21.769, 'eval_steps_per_second': 2.799, 'epoch': 5.44}
 11%|█         | 215/1950 [28:09<1:49:58,  3.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 11%|█         | 216/1950 [28:11<2:03:51,  4.29s/it] 11%|█         | 217/1950 [28:14<1:50:44,  3.83s/it] 11%|█         | 218/1950 [28:16<1:37:17,  3.37s/it] 11%|█         | 219/1950 [28:19<1:33:06,  3.23s/it] 11%|█▏        | 220/1950 [28:21<1:25:36,  2.97s/it]                                                    {'loss': 0.0881, 'learning_rate': 4.846000680380105e-05, 'epoch': 5.57}
 11%|█▏        | 220/1950 [28:21<1:25:36,  2.97s/it][INFO|trainer.py:3242] 2024-02-05 10:24:37,782 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:24:37,782 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:24:37,782 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                    
                                             [A{'eval_loss': 0.13525390625, 'eval_runtime': 3.2364, 'eval_samples_per_second': 21.629, 'eval_steps_per_second': 2.781, 'epoch': 5.57}
 11%|█▏        | 220/1950 [28:25<1:25:36,  2.97s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 11%|█▏        | 221/1950 [28:27<1:52:32,  3.91s/it] 11%|█▏        | 222/1950 [28:30<1:39:11,  3.44s/it] 11%|█▏        | 223/1950 [28:32<1:31:52,  3.19s/it] 11%|█▏        | 224/1950 [28:35<1:22:57,  2.88s/it] 12%|█▏        | 225/1950 [28:37<1:18:33,  2.73s/it]                                                    {'loss': 0.0768, 'learning_rate': 4.838965808522716e-05, 'epoch': 5.7}
 12%|█▏        | 225/1950 [28:37<1:18:33,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 10:24:53,387 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:24:53,388 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:24:53,388 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.1317138671875, 'eval_runtime': 3.2495, 'eval_samples_per_second': 21.541, 'eval_steps_per_second': 2.77, 'epoch': 5.7}
 12%|█▏        | 225/1950 [28:40<1:18:33,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 12%|█▏        | 226/1950 [28:43<1:44:24,  3.63s/it] 12%|█▏        | 227/1950 [28:45<1:34:42,  3.30s/it] 12%|█▏        | 228/1950 [28:48<1:27:39,  3.05s/it] 12%|█▏        | 229/1950 [28:50<1:20:59,  2.82s/it] 12%|█▏        | 230/1950 [28:53<1:20:15,  2.80s/it]                                                    {'loss': 0.061, 'learning_rate': 4.831779164525881e-05, 'epoch': 5.82}
 12%|█▏        | 230/1950 [28:53<1:20:15,  2.80s/it][INFO|trainer.py:3242] 2024-02-05 10:25:09,154 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:25:09,154 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:25:09,154 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.1307373046875, 'eval_runtime': 3.2633, 'eval_samples_per_second': 21.45, 'eval_steps_per_second': 2.758, 'epoch': 5.82}
 12%|█▏        | 230/1950 [28:56<1:20:15,  2.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 12%|█▏        | 231/1950 [28:58<1:45:11,  3.67s/it] 12%|█▏        | 232/1950 [29:01<1:33:29,  3.26s/it] 12%|█▏        | 233/1950 [29:03<1:26:07,  3.01s/it] 12%|█▏        | 234/1950 [29:06<1:21:27,  2.85s/it] 12%|█▏        | 235/1950 [29:08<1:17:04,  2.70s/it]                                                    {'loss': 0.0825, 'learning_rate': 4.8244412147206284e-05, 'epoch': 5.95}
 12%|█▏        | 235/1950 [29:08<1:17:04,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:25:24,404 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:25:24,404 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:25:24,404 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.1282958984375, 'eval_runtime': 3.2786, 'eval_samples_per_second': 21.351, 'eval_steps_per_second': 2.745, 'epoch': 5.95}
 12%|█▏        | 235/1950 [29:11<1:17:04,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 12%|█▏        | 236/1950 [29:14<1:41:52,  3.57s/it] 12%|█▏        | 237/1950 [29:16<1:30:59,  3.19s/it] 12%|█▏        | 238/1950 [29:18<1:23:44,  2.94s/it] 12%|█▏        | 239/1950 [29:21<1:18:13,  2.74s/it] 12%|█▏        | 240/1950 [29:23<1:14:23,  2.61s/it]                                                    {'loss': 0.0551, 'learning_rate': 4.8169524352560076e-05, 'epoch': 6.08}
 12%|█▏        | 240/1950 [29:23<1:14:23,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 10:25:39,244 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:25:39,244 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:25:39,244 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.128662109375, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 6.08}
 12%|█▏        | 240/1950 [29:26<1:14:23,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 12%|█▏        | 241/1950 [29:29<1:42:03,  3.58s/it] 12%|█▏        | 242/1950 [29:31<1:32:02,  3.23s/it] 12%|█▏        | 243/1950 [29:33<1:23:23,  2.93s/it] 13%|█▎        | 244/1950 [29:36<1:19:46,  2.81s/it] 13%|█▎        | 245/1950 [29:38<1:17:54,  2.74s/it]                                                    {'loss': 0.0691, 'learning_rate': 4.809313312068185e-05, 'epoch': 6.2}
 13%|█▎        | 245/1950 [29:38<1:17:54,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 10:25:54,846 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:25:54,846 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:25:54,846 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.135009765625, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 6.2}
 13%|█▎        | 245/1950 [29:42<1:17:54,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 13%|█▎        | 246/1950 [29:44<1:42:03,  3.59s/it] 13%|█▎        | 247/1950 [29:46<1:32:17,  3.25s/it] 13%|█▎        | 248/1950 [29:49<1:26:08,  3.04s/it] 13%|█▎        | 249/1950 [29:52<1:22:15,  2.90s/it] 13%|█▎        | 250/1950 [29:54<1:19:02,  2.79s/it]                                                    {'loss': 0.0656, 'learning_rate': 4.801524340848917e-05, 'epoch': 6.33}
 13%|█▎        | 250/1950 [29:54<1:19:02,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 10:26:10,530 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:26:10,530 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:26:10,530 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1297607421875, 'eval_runtime': 3.2984, 'eval_samples_per_second': 21.223, 'eval_steps_per_second': 2.729, 'epoch': 6.33}
 13%|█▎        | 250/1950 [29:57<1:19:02,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 13%|█▎        | 251/1950 [30:00<1:42:44,  3.63s/it] 13%|█▎        | 252/1950 [30:02<1:33:10,  3.29s/it] 13%|█▎        | 253/1950 [30:05<1:25:29,  3.02s/it] 13%|█▎        | 254/1950 [30:07<1:22:14,  2.91s/it] 13%|█▎        | 255/1950 [30:10<1:17:44,  2.75s/it]                                                    {'loss': 0.0742, 'learning_rate': 4.7935860270133844e-05, 'epoch': 6.46}
 13%|█▎        | 255/1950 [30:10<1:17:44,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:26:26,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:26:26,047 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:26:26,048 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.128173828125, 'eval_runtime': 3.3006, 'eval_samples_per_second': 21.208, 'eval_steps_per_second': 2.727, 'epoch': 6.46}
 13%|█▎        | 255/1950 [30:13<1:17:44,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 13%|█▎        | 256/1950 [30:15<1:43:41,  3.67s/it] 13%|█▎        | 257/1950 [30:18<1:35:12,  3.37s/it] 13%|█▎        | 258/1950 [30:21<1:27:06,  3.09s/it] 13%|█▎        | 259/1950 [30:23<1:25:52,  3.05s/it] 13%|█▎        | 260/1950 [30:26<1:19:55,  2.84s/it]                                                    {'loss': 0.0642, 'learning_rate': 4.785498885667395e-05, 'epoch': 6.58}
 13%|█▎        | 260/1950 [30:26<1:19:55,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 10:26:42,268 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:26:42,268 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:26:42,268 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1400146484375, 'eval_runtime': 3.2939, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 6.58}
 13%|█▎        | 260/1950 [30:29<1:19:55,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 13%|█▎        | 261/1950 [30:32<1:47:53,  3.83s/it] 13%|█▎        | 262/1950 [30:34<1:36:19,  3.42s/it] 13%|█▎        | 263/1950 [30:37<1:28:32,  3.15s/it] 14%|█▎        | 264/1950 [30:39<1:21:46,  2.91s/it] 14%|█▎        | 265/1950 [30:42<1:17:15,  2.75s/it]                                                    {'loss': 0.0632, 'learning_rate': 4.7772634415739624e-05, 'epoch': 6.71}
 14%|█▎        | 265/1950 [30:42<1:17:15,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:26:58,131 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:26:58,132 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:26:58,132 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.135986328125, 'eval_runtime': 3.2916, 'eval_samples_per_second': 21.267, 'eval_steps_per_second': 2.734, 'epoch': 6.71}
 14%|█▎        | 265/1950 [30:45<1:17:15,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 14%|█▎        | 266/1950 [30:48<1:43:02,  3.67s/it] 14%|█▎        | 267/1950 [30:50<1:32:03,  3.28s/it] 14%|█▎        | 268/1950 [30:52<1:23:45,  2.99s/it] 14%|█▍        | 269/1950 [30:55<1:19:08,  2.82s/it] 14%|█▍        | 270/1950 [30:57<1:16:17,  2.72s/it]                                                    {'loss': 0.0479, 'learning_rate': 4.768880229119253e-05, 'epoch': 6.84}
 14%|█▍        | 270/1950 [30:57<1:16:17,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 10:27:13,562 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:27:13,562 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:27:13,562 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1324462890625, 'eval_runtime': 3.296, 'eval_samples_per_second': 21.238, 'eval_steps_per_second': 2.731, 'epoch': 6.84}
 14%|█▍        | 270/1950 [31:00<1:16:17,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 14%|█▍        | 271/1950 [31:03<1:40:17,  3.58s/it] 14%|█▍        | 272/1950 [31:05<1:29:47,  3.21s/it] 14%|█▍        | 273/1950 [31:07<1:21:59,  2.93s/it] 14%|█▍        | 274/1950 [31:10<1:16:46,  2.75s/it] 14%|█▍        | 275/1950 [31:12<1:13:18,  2.63s/it]                                                    {'loss': 0.067, 'learning_rate': 4.760349792277906e-05, 'epoch': 6.96}
 14%|█▍        | 275/1950 [31:12<1:13:18,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 10:27:28,433 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:27:28,433 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:27:28,433 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.135498046875, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.244, 'eval_steps_per_second': 2.731, 'epoch': 6.96}
 14%|█▍        | 275/1950 [31:15<1:13:18,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 14%|█▍        | 276/1950 [31:18<1:39:10,  3.55s/it] 14%|█▍        | 277/1950 [31:20<1:28:27,  3.17s/it] 14%|█▍        | 278/1950 [31:22<1:20:17,  2.88s/it] 14%|█▍        | 279/1950 [31:25<1:15:51,  2.72s/it] 14%|█▍        | 280/1950 [31:27<1:13:26,  2.64s/it]                                                    {'loss': 0.0407, 'learning_rate': 4.751672684577747e-05, 'epoch': 7.09}
 14%|█▍        | 280/1950 [31:27<1:13:26,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 10:27:43,433 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:27:43,433 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:27:43,433 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1324462890625, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 7.09}
 14%|█▍        | 280/1950 [31:30<1:13:26,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 14%|█▍        | 281/1950 [31:33<1:38:57,  3.56s/it] 14%|█▍        | 282/1950 [31:35<1:29:33,  3.22s/it] 15%|█▍        | 283/1950 [31:38<1:22:52,  2.98s/it] 15%|█▍        | 284/1950 [31:40<1:20:02,  2.88s/it] 15%|█▍        | 285/1950 [31:43<1:14:59,  2.70s/it]                                                    {'loss': 0.055, 'learning_rate': 4.742849469063858e-05, 'epoch': 7.22}
 15%|█▍        | 285/1950 [31:43<1:14:59,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:27:58,931 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:27:58,931 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:27:58,931 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.1495361328125, 'eval_runtime': 3.2864, 'eval_samples_per_second': 21.3, 'eval_steps_per_second': 2.739, 'epoch': 7.22}
 15%|█▍        | 285/1950 [31:46<1:14:59,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 15%|█▍        | 286/1950 [31:48<1:38:32,  3.55s/it] 15%|█▍        | 287/1950 [31:50<1:28:41,  3.20s/it] 15%|█▍        | 288/1950 [31:53<1:23:11,  3.00s/it] 15%|█▍        | 289/1950 [31:55<1:18:47,  2.85s/it] 15%|█▍        | 290/1950 [31:58<1:14:59,  2.71s/it]                                                    {'loss': 0.0501, 'learning_rate': 4.73388071826205e-05, 'epoch': 7.34}
 15%|█▍        | 290/1950 [31:58<1:14:59,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 10:28:14,262 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:28:14,262 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:28:14,262 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1412353515625, 'eval_runtime': 3.2959, 'eval_samples_per_second': 21.239, 'eval_steps_per_second': 2.731, 'epoch': 7.34}
 15%|█▍        | 290/1950 [32:01<1:14:59,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 15%|█▍        | 291/1950 [32:04<1:40:16,  3.63s/it] 15%|█▍        | 292/1950 [32:06<1:31:12,  3.30s/it] 15%|█▌        | 293/1950 [32:09<1:25:01,  3.08s/it] 15%|█▌        | 294/1950 [32:11<1:20:41,  2.92s/it] 15%|█▌        | 295/1950 [32:14<1:15:01,  2.72s/it]                                                    {'loss': 0.0608, 'learning_rate': 4.72476701414171e-05, 'epoch': 7.47}
 15%|█▌        | 295/1950 [32:14<1:15:01,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 10:28:29,935 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:28:29,935 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:28:29,935 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1348876953125, 'eval_runtime': 3.2936, 'eval_samples_per_second': 21.253, 'eval_steps_per_second': 2.733, 'epoch': 7.47}
 15%|█▌        | 295/1950 [32:17<1:15:01,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 15%|█▌        | 296/1950 [32:20<1:43:05,  3.74s/it] 15%|█▌        | 297/1950 [32:22<1:30:58,  3.30s/it] 15%|█▌        | 298/1950 [32:25<1:27:33,  3.18s/it] 15%|█▌        | 299/1950 [32:27<1:21:25,  2.96s/it] 15%|█▌        | 300/1950 [32:30<1:20:02,  2.91s/it]                                                    {'loss': 0.0505, 'learning_rate': 4.715508948078037e-05, 'epoch': 7.59}
 15%|█▌        | 300/1950 [32:30<1:20:02,  2.91s/it][INFO|trainer.py:3242] 2024-02-05 10:28:46,471 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:28:46,472 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:28:46,472 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.152099609375, 'eval_runtime': 3.288, 'eval_samples_per_second': 21.29, 'eval_steps_per_second': 2.737, 'epoch': 7.59}
 15%|█▌        | 300/1950 [32:33<1:20:02,  2.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 10:29:04,752 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 10:29:04,897 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 10:29:04,898 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/special_tokens_map.json
[2024-02-05 10:29:05,953] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step300 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 10:29:20,490] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/mp_rank_00_model_states.pt
[2024-02-05 10:29:20,490] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/mp_rank_00_model_states.pt...
[2024-02-05 10:37:19,757] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/mp_rank_00_model_states.pt.
[2024-02-05 10:37:20,713] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 10:37:21,331] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 10:37:21,395] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-300/global_step300/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 10:37:21,395] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step300 is ready now!
 15%|█▌        | 301/1950 [41:07<72:02:00, 157.26s/it] 15%|█▌        | 302/1950 [41:10<50:44:44, 110.85s/it] 16%|█▌        | 303/1950 [41:12<35:47:36, 78.24s/it]  16%|█▌        | 304/1950 [41:15<25:21:52, 55.48s/it] 16%|█▌        | 305/1950 [41:17<18:03:46, 39.53s/it]                                                     {'loss': 0.052, 'learning_rate': 4.706107120813671e-05, 'epoch': 7.72}
 16%|█▌        | 305/1950 [41:17<18:03:46, 39.53s/it][INFO|trainer.py:3242] 2024-02-05 10:37:33,280 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:37:33,280 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:37:33,280 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.01it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.21it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                     
                                             [A{'eval_loss': 0.1488037109375, 'eval_runtime': 3.1805, 'eval_samples_per_second': 22.009, 'eval_steps_per_second': 2.83, 'epoch': 7.72}
 16%|█▌        | 305/1950 [41:20<18:03:46, 39.53s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 16%|█▌        | 306/1950 [41:22<13:23:39, 29.33s/it] 16%|█▌        | 307/1950 [41:25<9:41:03, 21.22s/it]  16%|█▌        | 308/1950 [41:27<7:05:15, 15.54s/it] 16%|█▌        | 309/1950 [41:30<5:19:49, 11.69s/it] 16%|█▌        | 310/1950 [41:32<4:01:59,  8.85s/it]                                                    {'loss': 0.0392, 'learning_rate': 4.6965621424197116e-05, 'epoch': 7.85}
 16%|█▌        | 310/1950 [41:32<4:01:59,  8.85s/it][INFO|trainer.py:3242] 2024-02-05 10:37:48,327 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:37:48,328 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:37:48,328 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                    
                                             [A{'eval_loss': 0.1431884765625, 'eval_runtime': 3.2052, 'eval_samples_per_second': 21.839, 'eval_steps_per_second': 2.808, 'epoch': 7.85}
 16%|█▌        | 310/1950 [41:35<4:01:59,  8.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 16%|█▌        | 311/1950 [41:37<3:33:41,  7.82s/it] 16%|█▌        | 312/1950 [41:40<2:48:29,  6.17s/it] 16%|█▌        | 313/1950 [41:42<2:17:51,  5.05s/it] 16%|█▌        | 314/1950 [41:44<1:55:42,  4.24s/it] 16%|█▌        | 315/1950 [41:47<1:40:03,  3.67s/it]                                                    {'loss': 0.0557, 'learning_rate': 4.686874632256125e-05, 'epoch': 7.97}
 16%|█▌        | 315/1950 [41:47<1:40:03,  3.67s/it][INFO|trainer.py:3242] 2024-02-05 10:38:03,200 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:38:03,200 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:38:03,200 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                    
                                             [A{'eval_loss': 0.14404296875, 'eval_runtime': 3.2157, 'eval_samples_per_second': 21.768, 'eval_steps_per_second': 2.799, 'epoch': 7.97}
 16%|█▌        | 315/1950 [41:50<1:40:03,  3.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A[2024-02-05 10:38:08,701] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
 16%|█▌        | 316/1950 [41:52<1:55:02,  4.22s/it] 16%|█▋        | 317/1950 [41:55<1:38:54,  3.63s/it] 16%|█▋        | 318/1950 [41:57<1:27:41,  3.22s/it] 16%|█▋        | 319/1950 [41:59<1:19:50,  2.94s/it] 16%|█▋        | 320/1950 [42:02<1:17:06,  2.84s/it]                                                    {'loss': 0.0295, 'learning_rate': 4.679022423366424e-05, 'epoch': 8.1}
 16%|█▋        | 320/1950 [42:02<1:17:06,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 10:38:18,112 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:38:18,112 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:38:18,113 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  3.46it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.19it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.05it/s][A
 67%|██████▋   | 6/9 [00:01<00:01,  2.96it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.90it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.1429443359375, 'eval_runtime': 3.3475, 'eval_samples_per_second': 20.911, 'eval_steps_per_second': 2.689, 'epoch': 8.1}
 16%|█▋        | 320/1950 [42:05<1:17:06,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 16%|█▋        | 321/1950 [42:07<1:40:50,  3.71s/it] 17%|█▋        | 322/1950 [42:10<1:28:59,  3.28s/it] 17%|█▋        | 323/1950 [42:12<1:22:03,  3.03s/it] 17%|█▋        | 324/1950 [42:15<1:16:46,  2.83s/it] 17%|█▋        | 325/1950 [42:17<1:11:03,  2.62s/it]                                                    {'loss': 0.042, 'learning_rate': 4.669079946300404e-05, 'epoch': 8.23}
 17%|█▋        | 325/1950 [42:17<1:11:03,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 10:38:33,088 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:38:33,088 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:38:33,088 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.87it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.1617431640625, 'eval_runtime': 3.2484, 'eval_samples_per_second': 21.549, 'eval_steps_per_second': 2.771, 'epoch': 8.23}
 17%|█▋        | 325/1950 [42:20<1:11:03,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 17%|█▋        | 326/1950 [42:22<1:35:04,  3.51s/it] 17%|█▋        | 327/1950 [42:25<1:26:01,  3.18s/it] 17%|█▋        | 328/1950 [42:27<1:19:40,  2.95s/it] 17%|█▋        | 329/1950 [42:30<1:16:19,  2.83s/it] 17%|█▋        | 330/1950 [42:32<1:11:58,  2.67s/it]                                                    {'loss': 0.0387, 'learning_rate': 4.658996720745081e-05, 'epoch': 8.35}
 17%|█▋        | 330/1950 [42:32<1:11:58,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:38:48,317 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:38:48,317 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:38:48,317 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.1566162109375, 'eval_runtime': 3.2629, 'eval_samples_per_second': 21.453, 'eval_steps_per_second': 2.758, 'epoch': 8.35}
 17%|█▋        | 330/1950 [42:35<1:11:58,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 17%|█▋        | 331/1950 [42:38<1:37:52,  3.63s/it] 17%|█▋        | 332/1950 [42:40<1:28:16,  3.27s/it] 17%|█▋        | 333/1950 [42:43<1:22:29,  3.06s/it] 17%|█▋        | 334/1950 [42:45<1:16:47,  2.85s/it] 17%|█▋        | 335/1950 [42:48<1:14:01,  2.75s/it]                                                    {'loss': 0.0537, 'learning_rate': 4.6487734009865134e-05, 'epoch': 8.48}
 17%|█▋        | 335/1950 [42:48<1:14:01,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:39:04,077 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:39:04,077 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:39:04,077 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.142578125, 'eval_runtime': 3.274, 'eval_samples_per_second': 21.381, 'eval_steps_per_second': 2.749, 'epoch': 8.48}
 17%|█▋        | 335/1950 [42:51<1:14:01,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 17%|█▋        | 336/1950 [42:54<1:39:16,  3.69s/it] 17%|█▋        | 337/1950 [42:56<1:28:30,  3.29s/it] 17%|█▋        | 338/1950 [42:59<1:25:07,  3.17s/it] 17%|█▋        | 339/1950 [43:01<1:18:16,  2.92s/it] 17%|█▋        | 340/1950 [43:04<1:17:55,  2.90s/it]                                                    {'loss': 0.0395, 'learning_rate': 4.638410650401267e-05, 'epoch': 8.61}
 17%|█▋        | 340/1950 [43:04<1:17:55,  2.90s/it][INFO|trainer.py:3242] 2024-02-05 10:39:20,407 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:39:20,407 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:39:20,407 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1571044921875, 'eval_runtime': 3.2885, 'eval_samples_per_second': 21.286, 'eval_steps_per_second': 2.737, 'epoch': 8.61}
 17%|█▋        | 340/1950 [43:07<1:17:55,  2.90s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 17%|█▋        | 341/1950 [43:10<1:39:44,  3.72s/it] 18%|█▊        | 342/1950 [43:12<1:29:33,  3.34s/it] 18%|█▊        | 343/1950 [43:14<1:21:50,  3.06s/it] 18%|█▊        | 344/1950 [43:17<1:16:30,  2.86s/it] 18%|█▊        | 345/1950 [43:19<1:13:04,  2.73s/it]                                                    {'loss': 0.0432, 'learning_rate': 4.627909141413378e-05, 'epoch': 8.73}
 18%|█▊        | 345/1950 [43:19<1:13:04,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 10:39:35,712 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:39:35,712 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:39:35,712 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.163330078125, 'eval_runtime': 3.288, 'eval_samples_per_second': 21.289, 'eval_steps_per_second': 2.737, 'epoch': 8.73}
 18%|█▊        | 345/1950 [43:23<1:13:04,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 18%|█▊        | 346/1950 [43:25<1:36:36,  3.61s/it] 18%|█▊        | 347/1950 [43:27<1:27:15,  3.27s/it] 18%|█▊        | 348/1950 [43:30<1:20:42,  3.02s/it] 18%|█▊        | 349/1950 [43:32<1:16:53,  2.88s/it] 18%|█▊        | 350/1950 [43:35<1:12:11,  2.71s/it]                                                    {'loss': 0.0322, 'learning_rate': 4.617269555450715e-05, 'epoch': 8.86}
 18%|█▊        | 350/1950 [43:35<1:12:11,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 10:39:51,146 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:39:51,146 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:39:51,146 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.150390625, 'eval_runtime': 3.2927, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 8.86}
 18%|█▊        | 350/1950 [43:38<1:12:11,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 18%|█▊        | 351/1950 [43:40<1:36:01,  3.60s/it] 18%|█▊        | 352/1950 [43:43<1:25:15,  3.20s/it] 18%|█▊        | 353/1950 [43:45<1:18:15,  2.94s/it] 18%|█▊        | 354/1950 [43:47<1:13:40,  2.77s/it] 18%|█▊        | 355/1950 [43:50<1:12:15,  2.72s/it]                                                    {'loss': 0.0517, 'learning_rate': 4.606492582900764e-05, 'epoch': 8.99}
 18%|█▊        | 355/1950 [43:50<1:12:15,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 10:40:06,404 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:40:06,404 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:40:06,404 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1431884765625, 'eval_runtime': 3.2979, 'eval_samples_per_second': 21.226, 'eval_steps_per_second': 2.729, 'epoch': 8.99}
 18%|█▊        | 355/1950 [43:53<1:12:15,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 18%|█▊        | 356/1950 [43:56<1:35:06,  3.58s/it] 18%|█▊        | 357/1950 [43:58<1:24:08,  3.17s/it] 18%|█▊        | 358/1950 [44:00<1:17:57,  2.94s/it] 18%|█▊        | 359/1950 [44:03<1:13:58,  2.79s/it] 18%|█▊        | 360/1950 [44:05<1:11:22,  2.69s/it]                                                    {'loss': 0.0261, 'learning_rate': 4.595578923065831e-05, 'epoch': 9.11}
 18%|█▊        | 360/1950 [44:05<1:11:22,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 10:40:21,517 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:40:21,517 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:40:21,517 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1436767578125, 'eval_runtime': 3.2924, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 9.11}
 18%|█▊        | 360/1950 [44:08<1:11:22,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 19%|█▊        | 361/1950 [44:11<1:34:53,  3.58s/it] 19%|█▊        | 362/1950 [44:13<1:25:08,  3.22s/it] 19%|█▊        | 363/1950 [44:16<1:20:01,  3.03s/it] 19%|█▊        | 364/1950 [44:18<1:14:00,  2.80s/it] 19%|█▊        | 365/1950 [44:20<1:09:59,  2.65s/it]                                                    {'loss': 0.0342, 'learning_rate': 4.584529284117662e-05, 'epoch': 9.24}
 19%|█▊        | 365/1950 [44:20<1:09:59,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 10:40:36,691 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:40:36,691 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:40:36,691 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1622314453125, 'eval_runtime': 3.2934, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 9.24}
 19%|█▊        | 365/1950 [44:24<1:09:59,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 19%|█▉        | 366/1950 [44:26<1:33:55,  3.56s/it] 19%|█▉        | 367/1950 [44:28<1:25:40,  3.25s/it] 19%|█▉        | 368/1950 [44:31<1:19:02,  3.00s/it] 19%|█▉        | 369/1950 [44:33<1:13:53,  2.80s/it] 19%|█▉        | 370/1950 [44:36<1:10:17,  2.67s/it]                                                    {'loss': 0.0342, 'learning_rate': 4.573344383051492e-05, 'epoch': 9.37}
 19%|█▉        | 370/1950 [44:36<1:10:17,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:40:52,012 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:40:52,012 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:40:52,012 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.178955078125, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 9.37}
 19%|█▉        | 370/1950 [44:39<1:10:17,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 19%|█▉        | 371/1950 [44:41<1:35:10,  3.62s/it] 19%|█▉        | 372/1950 [44:44<1:26:39,  3.29s/it] 19%|█▉        | 373/1950 [44:47<1:20:51,  3.08s/it] 19%|█▉        | 374/1950 [44:49<1:14:37,  2.84s/it] 19%|█▉        | 375/1950 [44:52<1:13:51,  2.81s/it]                                                    {'loss': 0.0482, 'learning_rate': 4.562024945639525e-05, 'epoch': 9.49}
 19%|█▉        | 375/1950 [44:52<1:13:51,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 10:41:07,992 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:41:07,992 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:41:07,992 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1580810546875, 'eval_runtime': 3.2898, 'eval_samples_per_second': 21.278, 'eval_steps_per_second': 2.736, 'epoch': 9.49}
 19%|█▉        | 375/1950 [44:55<1:13:51,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 19%|█▉        | 376/1950 [44:57<1:36:36,  3.68s/it] 19%|█▉        | 377/1950 [45:00<1:30:29,  3.45s/it] 19%|█▉        | 378/1950 [45:03<1:21:26,  3.11s/it] 19%|█▉        | 379/1950 [45:05<1:18:27,  3.00s/it] 19%|█▉        | 380/1950 [45:08<1:13:52,  2.82s/it]                                                    {'loss': 0.0269, 'learning_rate': 4.5505717063838326e-05, 'epoch': 9.62}
 19%|█▉        | 380/1950 [45:08<1:13:52,  2.82s/it][INFO|trainer.py:3242] 2024-02-05 10:41:24,076 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:41:24,077 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:41:24,077 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.175537109375, 'eval_runtime': 3.291, 'eval_samples_per_second': 21.27, 'eval_steps_per_second': 2.735, 'epoch': 9.62}
 19%|█▉        | 380/1950 [45:11<1:13:52,  2.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 20%|█▉        | 381/1950 [45:14<1:37:38,  3.73s/it] 20%|█▉        | 382/1950 [45:16<1:25:33,  3.27s/it] 20%|█▉        | 383/1950 [45:18<1:19:24,  3.04s/it] 20%|█▉        | 384/1950 [45:21<1:14:01,  2.84s/it] 20%|█▉        | 385/1950 [45:23<1:10:44,  2.71s/it]                                                    {'loss': 0.0399, 'learning_rate': 4.538985408468697e-05, 'epoch': 9.75}
 20%|█▉        | 385/1950 [45:23<1:10:44,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 10:41:39,413 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:41:39,413 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:41:39,413 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1728515625, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.244, 'eval_steps_per_second': 2.731, 'epoch': 9.75}
 20%|█▉        | 385/1950 [45:26<1:10:44,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 20%|█▉        | 386/1950 [45:29<1:33:27,  3.59s/it] 20%|█▉        | 387/1950 [45:31<1:23:22,  3.20s/it] 20%|█▉        | 388/1950 [45:34<1:21:30,  3.13s/it] 20%|█▉        | 389/1950 [45:36<1:15:52,  2.92s/it] 20%|██        | 390/1950 [45:39<1:10:55,  2.73s/it]                                                    {'loss': 0.035, 'learning_rate': 4.5272668037123845e-05, 'epoch': 9.87}
 20%|██        | 390/1950 [45:39<1:10:55,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 10:41:55,012 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:41:55,012 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:41:55,012 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1563720703125, 'eval_runtime': 3.2997, 'eval_samples_per_second': 21.214, 'eval_steps_per_second': 2.728, 'epoch': 9.87}
 20%|██        | 390/1950 [45:42<1:10:55,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 20%|██        | 391/1950 [45:44<1:33:33,  3.60s/it] 20%|██        | 392/1950 [45:47<1:24:33,  3.26s/it] 20%|██        | 393/1950 [45:49<1:17:59,  3.01s/it] 20%|██        | 394/1950 [45:51<1:13:04,  2.82s/it] 20%|██        | 395/1950 [45:54<1:08:58,  2.66s/it]                                                    {'loss': 0.0395, 'learning_rate': 4.515416652518366e-05, 'epoch': 10.0}
 20%|██        | 395/1950 [45:54<1:08:58,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 10:42:10,200 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:42:10,200 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:42:10,201 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1611328125, 'eval_runtime': 3.2917, 'eval_samples_per_second': 21.266, 'eval_steps_per_second': 2.734, 'epoch': 10.0}
 20%|██        | 395/1950 [45:57<1:08:58,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 20%|██        | 396/1950 [45:59<1:31:38,  3.54s/it] 20%|██        | 397/1950 [46:02<1:21:16,  3.14s/it] 20%|██        | 398/1950 [46:04<1:14:37,  2.89s/it] 20%|██        | 399/1950 [46:06<1:12:27,  2.80s/it] 21%|██        | 400/1950 [46:09<1:09:26,  2.69s/it]                                                    {'loss': 0.0255, 'learning_rate': 4.503435723825971e-05, 'epoch': 10.13}
 21%|██        | 400/1950 [46:09<1:09:26,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 10:42:25,317 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:42:25,317 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:42:25,317 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.150634765625, 'eval_runtime': 3.2844, 'eval_samples_per_second': 21.313, 'eval_steps_per_second': 2.74, 'epoch': 10.13}
 21%|██        | 400/1950 [46:12<1:09:26,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 10:42:43,219 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 10:42:43,365 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 10:42:43,366 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/special_tokens_map.json
[2024-02-05 10:42:44,512] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step400 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 10:42:58,526] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt
[2024-02-05 10:42:58,526] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt...
[2024-02-05 10:50:56,790] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/mp_rank_00_model_states.pt.
[2024-02-05 10:50:57,791] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 10:50:58,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 10:50:58,482] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-400/global_step400/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 10:50:58,482] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step400 is ready now!
 21%|██        | 401/1950 [54:44<67:21:52, 156.56s/it] 21%|██        | 402/1950 [54:47<47:26:20, 110.32s/it] 21%|██        | 403/1950 [54:49<33:29:27, 77.94s/it]  21%|██        | 404/1950 [54:51<23:42:08, 55.19s/it] 21%|██        | 405/1950 [54:54<16:52:35, 39.32s/it]                                                     {'loss': 0.0359, 'learning_rate': 4.491324795060491e-05, 'epoch': 10.25}
 21%|██        | 405/1950 [54:54<16:52:35, 39.32s/it][INFO|trainer.py:3242] 2024-02-05 10:51:10,136 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:51:10,137 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:51:10,137 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.99it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.19it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                     
                                             [A{'eval_loss': 0.161865234375, 'eval_runtime': 3.1812, 'eval_samples_per_second': 22.004, 'eval_steps_per_second': 2.829, 'epoch': 10.25}
 21%|██        | 405/1950 [54:57<16:52:35, 39.32s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 21%|██        | 406/1950 [54:59<12:31:39, 29.21s/it] 21%|██        | 407/1950 [55:02<9:04:10, 21.16s/it]  21%|██        | 408/1950 [55:04<6:39:17, 15.54s/it] 21%|██        | 409/1950 [55:06<4:56:01, 11.53s/it] 21%|██        | 410/1950 [55:09<3:46:16,  8.82s/it]                                                    {'loss': 0.032, 'learning_rate': 4.47908465208274e-05, 'epoch': 10.38}
 21%|██        | 410/1950 [55:09<3:46:16,  8.82s/it][INFO|trainer.py:3242] 2024-02-05 10:51:25,200 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:51:25,200 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:51:25,200 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                    
                                             [A{'eval_loss': 0.167724609375, 'eval_runtime': 3.2024, 'eval_samples_per_second': 21.858, 'eval_steps_per_second': 2.81, 'epoch': 10.38}
 21%|██        | 410/1950 [55:12<3:46:16,  8.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 21%|██        | 411/1950 [55:14<3:21:40,  7.86s/it] 21%|██        | 412/1950 [55:17<2:41:15,  6.29s/it] 21%|██        | 413/1950 [55:19<2:11:33,  5.14s/it] 21%|██        | 414/1950 [55:22<1:51:10,  4.34s/it] 21%|██▏       | 415/1950 [55:25<1:37:51,  3.83s/it]                                                    {'loss': 0.029, 'learning_rate': 4.466716089138053e-05, 'epoch': 10.51}
 21%|██▏       | 415/1950 [55:25<1:37:51,  3.83s/it][INFO|trainer.py:3242] 2024-02-05 10:51:41,022 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:51:41,022 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:51:41,022 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.93it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                    
                                             [A{'eval_loss': 0.1737060546875, 'eval_runtime': 3.2158, 'eval_samples_per_second': 21.768, 'eval_steps_per_second': 2.799, 'epoch': 10.51}
 21%|██▏       | 415/1950 [55:28<1:37:51,  3.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 21%|██▏       | 416/1950 [55:30<1:51:17,  4.35s/it] 21%|██▏       | 417/1950 [55:33<1:39:57,  3.91s/it] 21%|██▏       | 418/1950 [55:35<1:26:34,  3.39s/it] 21%|██▏       | 419/1950 [55:38<1:21:17,  3.19s/it] 22%|██▏       | 420/1950 [55:40<1:15:05,  2.94s/it]                                                    {'loss': 0.0213, 'learning_rate': 4.454219908804757e-05, 'epoch': 10.63}
 22%|██▏       | 420/1950 [55:40<1:15:05,  2.94s/it][INFO|trainer.py:3242] 2024-02-05 10:51:56,745 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:51:56,745 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:51:56,745 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.17431640625, 'eval_runtime': 3.2433, 'eval_samples_per_second': 21.583, 'eval_steps_per_second': 2.775, 'epoch': 10.63}
 22%|██▏       | 420/1950 [55:44<1:15:05,  2.94s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 22%|██▏       | 421/1950 [55:46<1:36:15,  3.78s/it] 22%|██▏       | 422/1950 [55:48<1:25:00,  3.34s/it] 22%|██▏       | 423/1950 [55:51<1:17:01,  3.03s/it] 22%|██▏       | 424/1950 [55:53<1:12:53,  2.87s/it] 22%|██▏       | 425/1950 [55:56<1:10:36,  2.78s/it]                                                    {'loss': 0.0261, 'learning_rate': 4.441596921942085e-05, 'epoch': 10.76}
 22%|██▏       | 425/1950 [55:56<1:10:36,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 10:52:12,141 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:52:12,141 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:52:12,141 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.1806640625, 'eval_runtime': 3.2502, 'eval_samples_per_second': 21.537, 'eval_steps_per_second': 2.769, 'epoch': 10.76}
 22%|██▏       | 425/1950 [55:59<1:10:36,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 22%|██▏       | 426/1950 [56:01<1:32:58,  3.66s/it] 22%|██▏       | 427/1950 [56:04<1:24:14,  3.32s/it] 22%|██▏       | 428/1950 [56:07<1:18:20,  3.09s/it] 22%|██▏       | 429/1950 [56:09<1:12:26,  2.86s/it] 22%|██▏       | 430/1950 [56:11<1:09:45,  2.75s/it]                                                    {'loss': 0.0218, 'learning_rate': 4.428847947637563e-05, 'epoch': 10.89}
 22%|██▏       | 430/1950 [56:11<1:09:45,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 10:52:27,763 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:52:27,763 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:52:27,764 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.1812744140625, 'eval_runtime': 3.2645, 'eval_samples_per_second': 21.443, 'eval_steps_per_second': 2.757, 'epoch': 10.89}
 22%|██▏       | 430/1950 [56:15<1:09:45,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 22%|██▏       | 431/1950 [56:17<1:30:47,  3.59s/it] 22%|██▏       | 432/1950 [56:19<1:21:10,  3.21s/it] 22%|██▏       | 433/1950 [56:22<1:14:30,  2.95s/it] 22%|██▏       | 434/1950 [56:24<1:10:27,  2.79s/it] 22%|██▏       | 435/1950 [56:26<1:06:30,  2.63s/it]                                                    {'loss': 0.0265, 'learning_rate': 4.4159738131538674e-05, 'epoch': 11.01}
 22%|██▏       | 435/1950 [56:26<1:06:30,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 10:52:42,648 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:52:42,648 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:52:42,648 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.1685791015625, 'eval_runtime': 3.2716, 'eval_samples_per_second': 21.396, 'eval_steps_per_second': 2.751, 'epoch': 11.01}
 22%|██▏       | 435/1950 [56:30<1:06:30,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 22%|██▏       | 436/1950 [56:32<1:28:27,  3.51s/it] 22%|██▏       | 437/1950 [56:34<1:19:55,  3.17s/it] 22%|██▏       | 438/1950 [56:37<1:14:42,  2.96s/it] 23%|██▎       | 439/1950 [56:39<1:10:47,  2.81s/it] 23%|██▎       | 440/1950 [56:41<1:07:20,  2.68s/it]                                                    {'loss': 0.0184, 'learning_rate': 4.4029753538751336e-05, 'epoch': 11.14}
 23%|██▎       | 440/1950 [56:41<1:07:20,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 10:52:57,872 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:52:57,872 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:52:57,873 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.1668701171875, 'eval_runtime': 3.2872, 'eval_samples_per_second': 21.295, 'eval_steps_per_second': 2.738, 'epoch': 11.14}
 23%|██▎       | 440/1950 [56:45<1:07:20,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 23%|██▎       | 441/1950 [56:47<1:29:50,  3.57s/it] 23%|██▎       | 442/1950 [56:50<1:22:47,  3.29s/it] 23%|██▎       | 443/1950 [56:52<1:15:19,  3.00s/it] 23%|██▎       | 444/1950 [56:54<1:09:48,  2.78s/it] 23%|██▎       | 445/1950 [56:57<1:06:43,  2.66s/it]                                                    {'loss': 0.0278, 'learning_rate': 4.389853413252756e-05, 'epoch': 11.27}
 23%|██▎       | 445/1950 [56:57<1:06:43,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 10:53:13,142 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:53:13,142 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:53:13,142 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.166015625, 'eval_runtime': 3.2948, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.732, 'epoch': 11.27}
 23%|██▎       | 445/1950 [57:00<1:06:43,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 23%|██▎       | 446/1950 [57:03<1:30:37,  3.62s/it] 23%|██▎       | 447/1950 [57:05<1:21:30,  3.25s/it] 23%|██▎       | 448/1950 [57:07<1:15:38,  3.02s/it] 23%|██▎       | 449/1950 [57:10<1:11:17,  2.85s/it] 23%|██▎       | 450/1950 [57:12<1:08:26,  2.74s/it]                                                    {'loss': 0.0246, 'learning_rate': 4.376608842750658e-05, 'epoch': 11.39}
 23%|██▎       | 450/1950 [57:12<1:08:26,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 10:53:28,802 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:53:28,802 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:53:28,802 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1787109375, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.244, 'eval_steps_per_second': 2.731, 'epoch': 11.39}
 23%|██▎       | 450/1950 [57:16<1:08:26,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 23%|██▎       | 451/1950 [57:18<1:32:03,  3.69s/it] 23%|██▎       | 452/1950 [57:21<1:23:25,  3.34s/it] 23%|██▎       | 453/1950 [57:23<1:15:35,  3.03s/it] 23%|██▎       | 454/1950 [57:26<1:13:57,  2.97s/it] 23%|██▎       | 455/1950 [57:28<1:08:54,  2.77s/it]                                                    {'loss': 0.0259, 'learning_rate': 4.36324250179004e-05, 'epoch': 11.52}
 23%|██▎       | 455/1950 [57:28<1:08:54,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 10:53:44,655 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:53:44,655 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:53:44,655 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1707763671875, 'eval_runtime': 3.2927, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 11.52}
 23%|██▎       | 455/1950 [57:32<1:08:54,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 23%|██▎       | 456/1950 [57:34<1:34:43,  3.80s/it] 23%|██▎       | 457/1950 [57:37<1:24:21,  3.39s/it] 23%|██▎       | 458/1950 [57:40<1:19:23,  3.19s/it] 24%|██▎       | 459/1950 [57:42<1:13:23,  2.95s/it] 24%|██▎       | 460/1950 [57:45<1:10:14,  2.83s/it]                                                    {'loss': 0.0163, 'learning_rate': 4.3497552576936106e-05, 'epoch': 11.65}
 24%|██▎       | 460/1950 [57:45<1:10:14,  2.83s/it][INFO|trainer.py:3242] 2024-02-05 10:54:00,972 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:54:00,972 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:54:00,972 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1839599609375, 'eval_runtime': 3.2952, 'eval_samples_per_second': 21.243, 'eval_steps_per_second': 2.731, 'epoch': 11.65}
 24%|██▎       | 460/1950 [57:48<1:10:14,  2.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 24%|██▎       | 461/1950 [57:50<1:29:56,  3.62s/it] 24%|██▎       | 462/1950 [57:52<1:20:52,  3.26s/it] 24%|██▎       | 463/1950 [57:55<1:13:59,  2.99s/it] 24%|██▍       | 464/1950 [57:57<1:09:42,  2.81s/it] 24%|██▍       | 465/1950 [58:00<1:05:50,  2.66s/it]                                                    {'loss': 0.0206, 'learning_rate': 4.336147985629312e-05, 'epoch': 11.77}
 24%|██▍       | 465/1950 [58:00<1:05:50,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 10:54:15,925 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:54:15,925 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:54:15,926 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1912841796875, 'eval_runtime': 3.2936, 'eval_samples_per_second': 21.253, 'eval_steps_per_second': 2.733, 'epoch': 11.77}
 24%|██▍       | 465/1950 [58:03<1:05:50,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 24%|██▍       | 466/1950 [58:05<1:27:43,  3.55s/it] 24%|██▍       | 467/1950 [58:08<1:22:01,  3.32s/it] 24%|██▍       | 468/1950 [58:10<1:14:29,  3.02s/it] 24%|██▍       | 469/1950 [58:13<1:09:06,  2.80s/it] 24%|██▍       | 470/1950 [58:15<1:05:58,  2.67s/it]                                                    {'loss': 0.0184, 'learning_rate': 4.3224215685535294e-05, 'epoch': 11.9}
 24%|██▍       | 470/1950 [58:15<1:05:58,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:54:31,315 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:54:31,316 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:54:31,316 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1905517578125, 'eval_runtime': 3.2922, 'eval_samples_per_second': 21.262, 'eval_steps_per_second': 2.734, 'epoch': 11.9}
 24%|██▍       | 470/1950 [58:18<1:05:58,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 24%|██▍       | 471/1950 [58:21<1:28:56,  3.61s/it] 24%|██▍       | 472/1950 [58:23<1:19:39,  3.23s/it] 24%|██▍       | 473/1950 [58:25<1:13:25,  2.98s/it] 24%|██▍       | 474/1950 [58:28<1:09:02,  2.81s/it] 24%|██▍       | 475/1950 [58:30<1:05:09,  2.65s/it]                                                    {'loss': 0.0223, 'learning_rate': 4.308576897153794e-05, 'epoch': 12.03}
 24%|██▍       | 475/1950 [58:30<1:05:09,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 10:54:46,540 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:54:46,540 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:54:46,540 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.177490234375, 'eval_runtime': 3.2942, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 12.03}
 24%|██▍       | 475/1950 [58:33<1:05:09,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 24%|██▍       | 476/1950 [58:36<1:26:23,  3.52s/it] 24%|██▍       | 477/1950 [58:38<1:16:46,  3.13s/it] 25%|██▍       | 478/1950 [58:40<1:12:24,  2.95s/it] 25%|██▍       | 479/1950 [58:43<1:08:25,  2.79s/it] 25%|██▍       | 480/1950 [58:45<1:05:29,  2.67s/it]                                                    {'loss': 0.013, 'learning_rate': 4.294614869790994e-05, 'epoch': 12.15}
 25%|██▍       | 480/1950 [58:45<1:05:29,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 10:55:01,653 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:55:01,653 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:55:01,653 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1751708984375, 'eval_runtime': 3.29, 'eval_samples_per_second': 21.277, 'eval_steps_per_second': 2.736, 'epoch': 12.15}
 25%|██▍       | 480/1950 [58:49<1:05:29,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 25%|██▍       | 481/1950 [58:51<1:28:33,  3.62s/it] 25%|██▍       | 482/1950 [58:54<1:20:39,  3.30s/it] 25%|██▍       | 483/1950 [58:56<1:12:31,  2.97s/it] 25%|██▍       | 484/1950 [58:58<1:08:49,  2.82s/it] 25%|██▍       | 485/1950 [59:01<1:05:50,  2.70s/it]                                                    {'loss': 0.0237, 'learning_rate': 4.2805363924410776e-05, 'epoch': 12.28}
 25%|██▍       | 485/1950 [59:01<1:05:50,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 10:55:17,100 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:55:17,100 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:55:17,100 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.1666259765625, 'eval_runtime': 3.2919, 'eval_samples_per_second': 21.264, 'eval_steps_per_second': 2.734, 'epoch': 12.28}
 25%|██▍       | 485/1950 [59:04<1:05:50,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 25%|██▍       | 486/1950 [59:06<1:28:24,  3.62s/it] 25%|██▍       | 487/1950 [59:09<1:20:52,  3.32s/it] 25%|██▌       | 488/1950 [59:12<1:17:50,  3.19s/it] 25%|██▌       | 489/1950 [59:15<1:13:07,  3.00s/it] 25%|██▌       | 490/1950 [59:17<1:09:37,  2.86s/it]                                                    {'loss': 0.0164, 'learning_rate': 4.266342378636263e-05, 'epoch': 12.41}
 25%|██▌       | 490/1950 [59:17<1:09:37,  2.86s/it][INFO|trainer.py:3242] 2024-02-05 10:55:33,481 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:55:33,481 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:55:33,482 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.169677734375, 'eval_runtime': 3.2867, 'eval_samples_per_second': 21.298, 'eval_steps_per_second': 2.738, 'epoch': 12.41}
 25%|██▌       | 490/1950 [59:20<1:09:37,  2.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 25%|██▌       | 491/1950 [59:23<1:31:44,  3.77s/it] 25%|██▌       | 492/1950 [59:25<1:21:21,  3.35s/it] 25%|██▌       | 493/1950 [59:28<1:15:18,  3.10s/it] 25%|██▌       | 494/1950 [59:30<1:11:51,  2.96s/it] 25%|██▌       | 495/1950 [59:33<1:07:46,  2.79s/it]                                                    {'loss': 0.0209, 'learning_rate': 4.2520337494057663e-05, 'epoch': 12.53}
 25%|██▌       | 495/1950 [59:33<1:07:46,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 10:55:49,305 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:55:49,305 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:55:49,305 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.173583984375, 'eval_runtime': 3.2942, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 12.53}
 25%|██▌       | 495/1950 [59:36<1:07:46,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 25%|██▌       | 496/1950 [59:39<1:32:53,  3.83s/it] 25%|██▌       | 497/1950 [59:41<1:21:52,  3.38s/it] 26%|██▌       | 498/1950 [59:44<1:18:14,  3.23s/it] 26%|██▌       | 499/1950 [59:47<1:12:02,  2.98s/it] 26%|██▌       | 500/1950 [59:49<1:08:47,  2.85s/it]                                                    {'loss': 0.0153, 'learning_rate': 4.237611433216032e-05, 'epoch': 12.66}
 26%|██▌       | 500/1950 [59:49<1:08:47,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 10:56:05,699 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 10:56:05,700 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 10:56:05,700 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.17236328125, 'eval_runtime': 3.2961, 'eval_samples_per_second': 21.237, 'eval_steps_per_second': 2.731, 'epoch': 12.66}
 26%|██▌       | 500/1950 [59:53<1:08:47,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 10:56:23,474 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 10:56:23,617 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 10:56:23,618 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/special_tokens_map.json
[2024-02-05 10:56:24,827] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 10:56:38,631] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/mp_rank_00_model_states.pt
[2024-02-05 10:56:38,631] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/mp_rank_00_model_states.pt...
[2024-02-05 11:04:35,975] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/mp_rank_00_model_states.pt.
[2024-02-05 11:04:37,015] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 11:04:37,703] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 11:04:37,707] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 11:04:37,708] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 26%|██▌       | 501/1950 [1:08:24<62:55:36, 156.34s/it] 26%|██▌       | 502/1950 [1:08:26<44:17:45, 110.13s/it] 26%|██▌       | 503/1950 [1:08:28<31:16:27, 77.81s/it]  26%|██▌       | 504/1950 [1:08:31<22:11:14, 55.24s/it] 26%|██▌       | 505/1950 [1:08:33<15:48:11, 39.37s/it]                                                       {'loss': 0.013, 'learning_rate': 4.223076365910491e-05, 'epoch': 12.78}
 26%|██▌       | 505/1950 [1:08:33<15:48:11, 39.37s/it][INFO|trainer.py:3242] 2024-02-05 11:04:49,818 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:04:49,819 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:04:49,819 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.00it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                       
                                             [A{'eval_loss': 0.1854248046875, 'eval_runtime': 3.1839, 'eval_samples_per_second': 21.986, 'eval_steps_per_second': 2.827, 'epoch': 12.78}
 26%|██▌       | 505/1950 [1:08:37<15:48:11, 39.37s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 26%|██▌       | 506/1950 [1:08:39<11:45:33, 29.32s/it] 26%|██▌       | 507/1950 [1:08:42<8:32:53, 21.33s/it]  26%|██▌       | 508/1950 [1:08:44<6:16:43, 15.68s/it] 26%|██▌       | 509/1950 [1:08:47<4:42:08, 11.75s/it] 26%|██▌       | 510/1950 [1:08:49<3:34:06,  8.92s/it]                                                      {'loss': 0.0094, 'learning_rate': 4.2084294906488314e-05, 'epoch': 12.91}
 26%|██▌       | 510/1950 [1:08:49<3:34:06,  8.92s/it][INFO|trainer.py:3242] 2024-02-05 11:05:05,745 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:05:05,746 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:05:05,746 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.17it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                      
                                             [A{'eval_loss': 0.1962890625, 'eval_runtime': 3.2089, 'eval_samples_per_second': 21.814, 'eval_steps_per_second': 2.805, 'epoch': 12.91}
 26%|██▌       | 510/1950 [1:08:53<3:34:06,  8.92s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 26%|██▌       | 511/1950 [1:08:55<3:09:34,  7.90s/it] 26%|██▋       | 512/1950 [1:08:57<2:29:07,  6.22s/it] 26%|██▋       | 513/1950 [1:09:00<2:02:16,  5.11s/it] 26%|██▋       | 514/1950 [1:09:02<1:41:38,  4.25s/it] 26%|██▋       | 515/1950 [1:09:04<1:27:03,  3.64s/it]                                                      {'loss': 0.0137, 'learning_rate': 4.193671757845797e-05, 'epoch': 13.04}
 26%|██▋       | 515/1950 [1:09:04<1:27:03,  3.64s/it][INFO|trainer.py:3242] 2024-02-05 11:05:20,542 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:05:20,542 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:05:20,542 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                      
                                             [A{'eval_loss': 0.1934814453125, 'eval_runtime': 3.2204, 'eval_samples_per_second': 21.737, 'eval_steps_per_second': 2.795, 'epoch': 13.04}
 26%|██▋       | 515/1950 [1:09:07<1:27:03,  3.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 26%|██▋       | 516/1950 [1:09:10<1:39:45,  4.17s/it] 27%|██▋       | 517/1950 [1:09:12<1:26:47,  3.63s/it] 27%|██▋       | 518/1950 [1:09:14<1:18:17,  3.28s/it] 27%|██▋       | 519/1950 [1:09:17<1:12:10,  3.03s/it] 27%|██▋       | 520/1950 [1:09:19<1:08:17,  2.87s/it]                                                      {'loss': 0.009, 'learning_rate': 4.178804125109523e-05, 'epoch': 13.16}
 27%|██▋       | 520/1950 [1:09:19<1:08:17,  2.87s/it][INFO|trainer.py:3242] 2024-02-05 11:05:35,713 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:05:35,713 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:05:35,713 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.53it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                      
                                             [A{'eval_loss': 0.1990966796875, 'eval_runtime': 3.2351, 'eval_samples_per_second': 21.638, 'eval_steps_per_second': 2.782, 'epoch': 13.16}
 27%|██▋       | 520/1950 [1:09:23<1:08:17,  2.87s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 27%|██▋       | 521/1950 [1:09:25<1:29:09,  3.74s/it] 27%|██▋       | 522/1950 [1:09:27<1:17:37,  3.26s/it] 27%|██▋       | 523/1950 [1:09:29<1:10:05,  2.95s/it] 27%|██▋       | 524/1950 [1:09:32<1:05:41,  2.76s/it] 27%|██▋       | 525/1950 [1:09:34<1:03:21,  2.67s/it]                                                      {'loss': 0.0162, 'learning_rate': 4.163827557179391e-05, 'epoch': 13.29}
 27%|██▋       | 525/1950 [1:09:34<1:03:21,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 11:05:50,637 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:05:50,637 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:05:50,637 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                      
                                             [A{'eval_loss': 0.19677734375, 'eval_runtime': 3.2545, 'eval_samples_per_second': 21.508, 'eval_steps_per_second': 2.765, 'epoch': 13.29}
 27%|██▋       | 525/1950 [1:09:37<1:03:21,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 27%|██▋       | 526/1950 [1:09:40<1:24:33,  3.56s/it] 27%|██▋       | 527/1950 [1:09:42<1:16:21,  3.22s/it] 27%|██▋       | 528/1950 [1:09:45<1:11:02,  3.00s/it] 27%|██▋       | 529/1950 [1:09:47<1:07:32,  2.85s/it] 27%|██▋       | 530/1950 [1:09:50<1:05:40,  2.78s/it]                                                      {'loss': 0.018, 'learning_rate': 4.1487430258634315e-05, 'epoch': 13.42}
 27%|██▋       | 530/1950 [1:09:50<1:05:40,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 11:06:06,293 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:06:06,294 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:06:06,294 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                      
                                             [A{'eval_loss': 0.1854248046875, 'eval_runtime': 3.263, 'eval_samples_per_second': 21.452, 'eval_steps_per_second': 2.758, 'epoch': 13.42}
 27%|██▋       | 530/1950 [1:09:53<1:05:40,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 27%|██▋       | 531/1950 [1:09:56<1:27:43,  3.71s/it] 27%|██▋       | 532/1950 [1:09:58<1:17:16,  3.27s/it] 27%|██▋       | 533/1950 [1:10:01<1:14:18,  3.15s/it] 27%|██▋       | 534/1950 [1:10:03<1:08:11,  2.89s/it] 27%|██▋       | 535/1950 [1:10:06<1:08:20,  2.90s/it]                                                      {'loss': 0.0189, 'learning_rate': 4.133551509975264e-05, 'epoch': 13.54}
 27%|██▋       | 535/1950 [1:10:06<1:08:20,  2.90s/it][INFO|trainer.py:3242] 2024-02-05 11:06:22,491 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:06:22,491 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:06:22,492 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                      
                                             [A{'eval_loss': 0.1900634765625, 'eval_runtime': 3.2709, 'eval_samples_per_second': 21.401, 'eval_steps_per_second': 2.752, 'epoch': 13.54}
 27%|██▋       | 535/1950 [1:10:09<1:08:20,  2.90s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 27%|██▋       | 536/1950 [1:10:12<1:28:31,  3.76s/it] 28%|██▊       | 537/1950 [1:10:15<1:21:09,  3.45s/it] 28%|██▊       | 538/1950 [1:10:17<1:13:47,  3.14s/it] 28%|██▊       | 539/1950 [1:10:20<1:10:12,  2.99s/it] 28%|██▊       | 540/1950 [1:10:22<1:05:17,  2.78s/it]                                                      {'loss': 0.014, 'learning_rate': 4.1182539952705844e-05, 'epoch': 13.67}
 28%|██▊       | 540/1950 [1:10:22<1:05:17,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 11:06:38,316 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:06:38,316 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:06:38,316 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                      
                                             [A{'eval_loss': 0.1907958984375, 'eval_runtime': 3.2806, 'eval_samples_per_second': 21.338, 'eval_steps_per_second': 2.743, 'epoch': 13.67}
 28%|██▊       | 540/1950 [1:10:25<1:05:17,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 28%|██▊       | 541/1950 [1:10:28<1:26:22,  3.68s/it] 28%|██▊       | 542/1950 [1:10:30<1:17:19,  3.30s/it] 28%|██▊       | 543/1950 [1:10:32<1:11:07,  3.03s/it] 28%|██▊       | 544/1950 [1:10:35<1:07:14,  2.87s/it] 28%|██▊       | 545/1950 [1:10:37<1:03:44,  2.72s/it]                                                      {'loss': 0.0121, 'learning_rate': 4.1028514743832005e-05, 'epoch': 13.8}
 28%|██▊       | 545/1950 [1:10:37<1:03:44,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 11:06:53,782 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:06:53,782 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:06:53,782 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.183837890625, 'eval_runtime': 3.2917, 'eval_samples_per_second': 21.265, 'eval_steps_per_second': 2.734, 'epoch': 13.8}
 28%|██▊       | 545/1950 [1:10:41<1:03:44,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 28%|██▊       | 546/1950 [1:10:43<1:26:56,  3.72s/it] 28%|██▊       | 547/1950 [1:10:46<1:17:36,  3.32s/it] 28%|██▊       | 548/1950 [1:10:48<1:09:59,  3.00s/it] 28%|██▊       | 549/1950 [1:10:50<1:05:22,  2.80s/it] 28%|██▊       | 550/1950 [1:10:53<1:03:51,  2.74s/it]                                                      {'loss': 0.0167, 'learning_rate': 4.087344946760619e-05, 'epoch': 13.92}
 28%|██▊       | 550/1950 [1:10:53<1:03:51,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 11:07:09,382 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:07:09,382 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:07:09,382 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.184326171875, 'eval_runtime': 3.2927, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 13.92}
 28%|██▊       | 550/1950 [1:10:56<1:03:51,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 28%|██▊       | 551/1950 [1:10:59<1:24:33,  3.63s/it] 28%|██▊       | 552/1950 [1:11:01<1:15:35,  3.24s/it] 28%|██▊       | 553/1950 [1:11:03<1:09:04,  2.97s/it] 28%|██▊       | 554/1950 [1:11:06<1:04:15,  2.76s/it] 28%|██▊       | 555/1950 [1:11:08<1:00:34,  2.61s/it]                                                      {'loss': 0.0114, 'learning_rate': 4.071735418599197e-05, 'epoch': 14.05}
 28%|██▊       | 555/1950 [1:11:08<1:00:34,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 11:07:24,282 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:07:24,282 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:07:24,282 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.1800537109375, 'eval_runtime': 3.2944, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 14.05}
 28%|██▊       | 555/1950 [1:11:11<1:00:34,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 29%|██▊       | 556/1950 [1:11:13<1:20:47,  3.48s/it] 29%|██▊       | 557/1950 [1:11:16<1:14:30,  3.21s/it] 29%|██▊       | 558/1950 [1:11:18<1:08:55,  2.97s/it] 29%|██▊       | 559/1950 [1:11:21<1:04:17,  2.77s/it] 29%|██▊       | 560/1950 [1:11:23<1:02:07,  2.68s/it]                                                      {'loss': 0.0091, 'learning_rate': 4.056023902778846e-05, 'epoch': 14.18}
 29%|██▊       | 560/1950 [1:11:23<1:02:07,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 11:07:39,572 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:07:39,572 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:07:39,572 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.181396484375, 'eval_runtime': 3.2886, 'eval_samples_per_second': 21.285, 'eval_steps_per_second': 2.737, 'epoch': 14.18}
 29%|██▊       | 560/1950 [1:11:26<1:02:07,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 29%|██▉       | 561/1950 [1:11:29<1:23:03,  3.59s/it] 29%|██▉       | 562/1950 [1:11:31<1:13:58,  3.20s/it] 29%|██▉       | 563/1950 [1:11:34<1:08:12,  2.95s/it] 29%|██▉       | 564/1950 [1:11:36<1:05:42,  2.84s/it] 29%|██▉       | 565/1950 [1:11:39<1:03:10,  2.74s/it]                                                      {'loss': 0.0091, 'learning_rate': 4.0402114187973134e-05, 'epoch': 14.3}
 29%|██▉       | 565/1950 [1:11:39<1:03:10,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 11:07:55,019 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:07:55,019 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:07:55,019 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.19482421875, 'eval_runtime': 3.2953, 'eval_samples_per_second': 21.243, 'eval_steps_per_second': 2.731, 'epoch': 14.3}
 29%|██▉       | 565/1950 [1:11:42<1:03:10,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 29%|██▉       | 566/1950 [1:11:44<1:23:57,  3.64s/it] 29%|██▉       | 567/1950 [1:11:47<1:14:48,  3.25s/it] 29%|██▉       | 568/1950 [1:11:49<1:10:01,  3.04s/it] 29%|██▉       | 569/1950 [1:11:52<1:05:39,  2.85s/it] 29%|██▉       | 570/1950 [1:11:54<1:04:16,  2.79s/it]                                                      {'loss': 0.0103, 'learning_rate': 4.0242989927040234e-05, 'epoch': 14.43}
 29%|██▉       | 570/1950 [1:11:54<1:04:16,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 11:08:10,727 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:08:10,727 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:08:10,727 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.197998046875, 'eval_runtime': 3.2905, 'eval_samples_per_second': 21.274, 'eval_steps_per_second': 2.735, 'epoch': 14.43}
 29%|██▉       | 570/1950 [1:11:58<1:04:16,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 29%|██▉       | 571/1950 [1:12:00<1:24:06,  3.66s/it] 29%|██▉       | 572/1950 [1:12:02<1:15:43,  3.30s/it] 29%|██▉       | 573/1950 [1:12:05<1:11:41,  3.12s/it] 29%|██▉       | 574/1950 [1:12:08<1:07:56,  2.96s/it] 29%|██▉       | 575/1950 [1:12:11<1:07:50,  2.96s/it]                                                      {'loss': 0.0121, 'learning_rate': 4.008287657033503e-05, 'epoch': 14.56}
 29%|██▉       | 575/1950 [1:12:11<1:07:50,  2.96s/it][INFO|trainer.py:3242] 2024-02-05 11:08:27,118 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:08:27,118 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:08:27,118 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.197998046875, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 14.56}
 29%|██▉       | 575/1950 [1:12:14<1:07:50,  2.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 30%|██▉       | 576/1950 [1:12:16<1:25:18,  3.73s/it] 30%|██▉       | 577/1950 [1:12:19<1:18:30,  3.43s/it] 30%|██▉       | 578/1950 [1:12:21<1:11:26,  3.12s/it] 30%|██▉       | 579/1950 [1:12:24<1:07:26,  2.95s/it] 30%|██▉       | 580/1950 [1:12:26<1:03:29,  2.78s/it]                                                      {'loss': 0.0094, 'learning_rate': 3.992178450738378e-05, 'epoch': 14.68}
 30%|██▉       | 580/1950 [1:12:26<1:03:29,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 11:08:42,710 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:08:42,710 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:08:42,710 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.2093505859375, 'eval_runtime': 3.2903, 'eval_samples_per_second': 21.275, 'eval_steps_per_second': 2.735, 'epoch': 14.68}
 30%|██▉       | 580/1950 [1:12:30<1:03:29,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 30%|██▉       | 581/1950 [1:12:32<1:23:01,  3.64s/it] 30%|██▉       | 582/1950 [1:12:34<1:15:10,  3.30s/it] 30%|██▉       | 583/1950 [1:12:37<1:09:33,  3.05s/it] 30%|██▉       | 584/1950 [1:12:39<1:04:43,  2.84s/it] 30%|███       | 585/1950 [1:12:42<1:01:57,  2.72s/it]                                                      {'loss': 0.0083, 'learning_rate': 3.975972419121958e-05, 'epoch': 14.81}
 30%|███       | 585/1950 [1:12:42<1:01:57,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 11:08:58,131 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:08:58,131 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:08:58,131 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.21630859375, 'eval_runtime': 3.2899, 'eval_samples_per_second': 21.277, 'eval_steps_per_second': 2.736, 'epoch': 14.81}
 30%|███       | 585/1950 [1:12:45<1:01:57,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 30%|███       | 586/1950 [1:12:48<1:22:58,  3.65s/it] 30%|███       | 587/1950 [1:12:50<1:14:13,  3.27s/it] 30%|███       | 588/1950 [1:12:52<1:08:25,  3.01s/it] 30%|███       | 589/1950 [1:12:55<1:03:37,  2.80s/it] 30%|███       | 590/1950 [1:12:57<1:01:03,  2.69s/it]                                                      {'loss': 0.0092, 'learning_rate': 3.959670613770414e-05, 'epoch': 14.94}
 30%|███       | 590/1950 [1:12:57<1:01:03,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 11:09:13,494 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:09:13,494 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:09:13,494 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.2139892578125, 'eval_runtime': 3.2948, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.732, 'epoch': 14.94}
 30%|███       | 590/1950 [1:13:00<1:01:03,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 30%|███       | 591/1950 [1:13:03<1:21:16,  3.59s/it] 30%|███       | 592/1950 [1:13:05<1:13:54,  3.27s/it] 30%|███       | 593/1950 [1:13:08<1:07:08,  2.97s/it] 30%|███       | 594/1950 [1:13:10<1:01:52,  2.74s/it] 31%|███       | 595/1950 [1:13:12<58:41,  2.60s/it]                                                      {'loss': 0.0095, 'learning_rate': 3.943274092484531e-05, 'epoch': 15.06}
 31%|███       | 595/1950 [1:13:12<58:41,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 11:09:28,431 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:09:28,431 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:09:28,432 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2095947265625, 'eval_runtime': 3.2924, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 15.06}
 31%|███       | 595/1950 [1:13:15<58:41,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 31%|███       | 596/1950 [1:13:18<1:19:11,  3.51s/it] 31%|███       | 597/1950 [1:13:20<1:11:50,  3.19s/it] 31%|███       | 598/1950 [1:13:22<1:06:19,  2.94s/it] 31%|███       | 599/1950 [1:13:25<1:02:46,  2.79s/it] 31%|███       | 600/1950 [1:13:28<1:01:46,  2.75s/it]                                                      {'loss': 0.0073, 'learning_rate': 3.92678391921108e-05, 'epoch': 15.19}
 31%|███       | 600/1950 [1:13:28<1:01:46,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 11:09:43,945 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:09:43,945 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:09:43,945 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.2119140625, 'eval_runtime': 3.2913, 'eval_samples_per_second': 21.268, 'eval_steps_per_second': 2.734, 'epoch': 15.19}
 31%|███       | 600/1950 [1:13:31<1:01:46,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 11:10:01,846 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 11:10:01,992 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 11:10:01,993 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/special_tokens_map.json
[2024-02-05 11:10:03,177] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step600 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 11:10:17,227] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/mp_rank_00_model_states.pt
[2024-02-05 11:10:17,227] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/mp_rank_00_model_states.pt...
[2024-02-05 11:18:14,262] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/mp_rank_00_model_states.pt.
[2024-02-05 11:18:15,261] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 11:18:15,944] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 11:18:15,949] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-600/global_step600/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 11:18:15,950] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step600 is ready now!
 31%|███       | 601/1950 [1:22:02<58:31:38, 156.19s/it] 31%|███       | 602/1950 [1:22:04<41:11:55, 110.03s/it] 31%|███       | 603/1950 [1:22:06<29:05:10, 77.74s/it]  31%|███       | 604/1950 [1:22:09<20:37:55, 55.18s/it] 31%|███       | 605/1950 [1:22:12<14:42:45, 39.38s/it]                                                       {'loss': 0.008, 'learning_rate': 3.910201163973771e-05, 'epoch': 15.32}
 31%|███       | 605/1950 [1:22:12<14:42:45, 39.38s/it][INFO|trainer.py:3242] 2024-02-05 11:18:27,958 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:18:27,958 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:18:27,958 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.01it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.21it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.32it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.2115478515625, 'eval_runtime': 3.1765, 'eval_samples_per_second': 22.037, 'eval_steps_per_second': 2.833, 'epoch': 15.32}
 31%|███       | 605/1950 [1:22:15<14:42:45, 39.38s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 31%|███       | 606/1950 [1:22:17<10:54:20, 29.21s/it] 31%|███       | 607/1950 [1:22:19<7:53:24, 21.15s/it]  31%|███       | 608/1950 [1:22:22<5:47:21, 15.53s/it] 31%|███       | 609/1950 [1:22:24<4:19:40, 11.62s/it] 31%|███▏      | 610/1950 [1:22:27<3:18:58,  8.91s/it]                                                      {'loss': 0.0088, 'learning_rate': 3.8935269028038297e-05, 'epoch': 15.44}
 31%|███▏      | 610/1950 [1:22:27<3:18:58,  8.91s/it][INFO|trainer.py:3242] 2024-02-05 11:18:43,261 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:18:43,262 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:18:43,262 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                      
                                             [A{'eval_loss': 0.213134765625, 'eval_runtime': 3.1969, 'eval_samples_per_second': 21.896, 'eval_steps_per_second': 2.815, 'epoch': 15.44}
 31%|███▏      | 610/1950 [1:22:30<3:18:58,  8.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 31%|███▏      | 611/1950 [1:22:32<2:55:10,  7.85s/it] 31%|███▏      | 612/1950 [1:22:35<2:21:33,  6.35s/it] 31%|███▏      | 613/1950 [1:22:37<1:55:04,  5.16s/it] 31%|███▏      | 614/1950 [1:22:40<1:39:59,  4.49s/it] 32%|███▏      | 615/1950 [1:22:43<1:25:07,  3.83s/it]                                                      {'loss': 0.0079, 'learning_rate': 3.876762217670167e-05, 'epoch': 15.57}
 32%|███▏      | 615/1950 [1:22:43<1:25:07,  3.83s/it][INFO|trainer.py:3242] 2024-02-05 11:18:59,077 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:18:59,077 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:18:59,077 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                      
                                             [A{'eval_loss': 0.202392578125, 'eval_runtime': 3.2137, 'eval_samples_per_second': 21.782, 'eval_steps_per_second': 2.801, 'epoch': 15.57}
 32%|███▏      | 615/1950 [1:22:46<1:25:07,  3.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 32%|███▏      | 616/1950 [1:22:49<1:38:54,  4.45s/it] 32%|███▏      | 617/1950 [1:22:51<1:24:54,  3.82s/it] 32%|███▏      | 618/1950 [1:22:53<1:16:15,  3.43s/it] 32%|███▏      | 619/1950 [1:22:56<1:08:28,  3.09s/it] 32%|███▏      | 620/1950 [1:22:58<1:04:27,  2.91s/it]                                                      {'loss': 0.0082, 'learning_rate': 3.8599081964091765e-05, 'epoch': 15.7}
 32%|███▏      | 620/1950 [1:22:58<1:04:27,  2.91s/it][INFO|trainer.py:3242] 2024-02-05 11:19:14,636 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:19:14,636 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:19:14,636 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.26it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                      
                                             [A{'eval_loss': 0.2037353515625, 'eval_runtime': 3.2292, 'eval_samples_per_second': 21.677, 'eval_steps_per_second': 2.787, 'epoch': 15.7}
 32%|███▏      | 620/1950 [1:23:01<1:04:27,  2.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 32%|███▏      | 621/1950 [1:23:04<1:23:12,  3.76s/it] 32%|███▏      | 622/1950 [1:23:06<1:14:15,  3.36s/it] 32%|███▏      | 623/1950 [1:23:09<1:07:20,  3.04s/it] 32%|███▏      | 624/1950 [1:23:11<1:02:18,  2.82s/it] 32%|███▏      | 625/1950 [1:23:14<1:01:45,  2.80s/it]                                                      {'loss': 0.0044, 'learning_rate': 3.8429659326541464e-05, 'epoch': 15.82}
 32%|███▏      | 625/1950 [1:23:14<1:01:45,  2.80s/it][INFO|trainer.py:3242] 2024-02-05 11:19:30,149 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:19:30,150 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:19:30,150 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                      
                                             [A{'eval_loss': 0.21044921875, 'eval_runtime': 3.2435, 'eval_samples_per_second': 21.582, 'eval_steps_per_second': 2.775, 'epoch': 15.82}
 32%|███▏      | 625/1950 [1:23:17<1:01:45,  2.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 32%|███▏      | 626/1950 [1:23:19<1:21:01,  3.67s/it] 32%|███▏      | 627/1950 [1:23:22<1:12:14,  3.28s/it] 32%|███▏      | 628/1950 [1:23:24<1:06:12,  3.00s/it] 32%|███▏      | 629/1950 [1:23:27<1:02:47,  2.85s/it] 32%|███▏      | 630/1950 [1:23:29<59:21,  2.70s/it]                                                      {'loss': 0.0067, 'learning_rate': 3.8259365257642905e-05, 'epoch': 15.95}
 32%|███▏      | 630/1950 [1:23:29<59:21,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 11:19:45,421 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:19:45,421 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:19:45,422 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.2164306640625, 'eval_runtime': 3.2588, 'eval_samples_per_second': 21.481, 'eval_steps_per_second': 2.762, 'epoch': 15.95}
 32%|███▏      | 630/1950 [1:23:32<59:21,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 32%|███▏      | 631/1950 [1:23:35<1:18:37,  3.58s/it] 32%|███▏      | 632/1950 [1:23:37<1:10:34,  3.21s/it] 32%|███▏      | 633/1950 [1:23:39<1:04:20,  2.93s/it] 33%|███▎      | 634/1950 [1:23:42<1:00:04,  2.74s/it] 33%|███▎      | 635/1950 [1:23:44<57:06,  2.61s/it]                                                      {'loss': 0.0059, 'learning_rate': 3.808821080753419e-05, 'epoch': 16.08}
 33%|███▎      | 635/1950 [1:23:44<57:06,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 11:20:00,270 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:20:00,270 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:20:00,270 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.20947265625, 'eval_runtime': 3.2662, 'eval_samples_per_second': 21.432, 'eval_steps_per_second': 2.756, 'epoch': 16.08}
 33%|███▎      | 635/1950 [1:23:47<57:06,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 33%|███▎      | 636/1950 [1:23:50<1:17:55,  3.56s/it] 33%|███▎      | 637/1950 [1:23:52<1:10:16,  3.21s/it] 33%|███▎      | 638/1950 [1:23:54<1:04:29,  2.95s/it] 33%|███▎      | 639/1950 [1:23:57<1:01:39,  2.82s/it] 33%|███▎      | 640/1950 [1:23:59<59:30,  2.73s/it]                                                      {'loss': 0.0089, 'learning_rate': 3.791620708218231e-05, 'epoch': 16.2}
 33%|███▎      | 640/1950 [1:23:59<59:30,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 11:20:15,818 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:20:15,818 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:20:15,818 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.21240234375, 'eval_runtime': 3.2731, 'eval_samples_per_second': 21.387, 'eval_steps_per_second': 2.75, 'epoch': 16.2}
 33%|███▎      | 640/1950 [1:24:03<59:30,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 33%|███▎      | 641/1950 [1:24:05<1:17:55,  3.57s/it] 33%|███▎      | 642/1950 [1:24:07<1:10:14,  3.22s/it] 33%|███▎      | 643/1950 [1:24:10<1:04:52,  2.98s/it] 33%|███▎      | 644/1950 [1:24:12<1:01:11,  2.81s/it] 33%|███▎      | 645/1950 [1:24:15<58:46,  2.70s/it]                                                      {'loss': 0.0098, 'learning_rate': 3.774336524266252e-05, 'epoch': 16.33}
 33%|███▎      | 645/1950 [1:24:15<58:46,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 11:20:31,049 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:20:31,050 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:20:31,050 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.2178955078125, 'eval_runtime': 3.2829, 'eval_samples_per_second': 21.323, 'eval_steps_per_second': 2.741, 'epoch': 16.33}
 33%|███▎      | 645/1950 [1:24:18<58:46,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 33%|███▎      | 646/1950 [1:24:20<1:17:40,  3.57s/it] 33%|███▎      | 647/1950 [1:24:23<1:11:00,  3.27s/it] 33%|███▎      | 648/1950 [1:24:25<1:06:07,  3.05s/it] 33%|███▎      | 649/1950 [1:24:28<1:03:58,  2.95s/it] 33%|███▎      | 650/1950 [1:24:30<1:00:19,  2.78s/it]                                                      {'loss': 0.0076, 'learning_rate': 3.756969650443408e-05, 'epoch': 16.46}
 33%|███▎      | 650/1950 [1:24:30<1:00:19,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 11:20:46,864 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:20:46,864 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:20:46,864 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.21435546875, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 16.46}
 33%|███▎      | 650/1950 [1:24:34<1:00:19,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 33%|███▎      | 651/1950 [1:24:36<1:19:44,  3.68s/it] 33%|███▎      | 652/1950 [1:24:39<1:12:24,  3.35s/it] 33%|███▎      | 653/1950 [1:24:41<1:06:26,  3.07s/it] 34%|███▎      | 654/1950 [1:24:44<1:04:33,  2.99s/it] 34%|███▎      | 655/1950 [1:24:46<59:35,  2.76s/it]                                                      {'loss': 0.0065, 'learning_rate': 3.739521213661255e-05, 'epoch': 16.58}
 34%|███▎      | 655/1950 [1:24:46<59:35,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 11:21:02,665 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:21:02,665 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:21:02,665 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2015380859375, 'eval_runtime': 3.2977, 'eval_samples_per_second': 21.227, 'eval_steps_per_second': 2.729, 'epoch': 16.58}
 34%|███▎      | 655/1950 [1:24:50<59:35,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 34%|███▎      | 656/1950 [1:24:52<1:20:58,  3.75s/it] 34%|███▎      | 657/1950 [1:24:55<1:11:49,  3.33s/it] 34%|███▎      | 658/1950 [1:24:57<1:06:13,  3.08s/it] 34%|███▍      | 659/1950 [1:25:00<1:01:47,  2.87s/it] 34%|███▍      | 660/1950 [1:25:02<58:22,  2.72s/it]                                                      {'loss': 0.0067, 'learning_rate': 3.7219923461238505e-05, 'epoch': 16.71}
 34%|███▍      | 660/1950 [1:25:02<58:22,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 11:21:18,309 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:21:18,309 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:21:18,309 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2005615234375, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 16.71}
 34%|███▍      | 660/1950 [1:25:05<58:22,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 34%|███▍      | 661/1950 [1:25:08<1:18:15,  3.64s/it] 34%|███▍      | 662/1950 [1:25:10<1:11:25,  3.33s/it] 34%|███▍      | 663/1950 [1:25:13<1:05:29,  3.05s/it] 34%|███▍      | 664/1950 [1:25:15<1:02:00,  2.89s/it] 34%|███▍      | 665/1950 [1:25:18<1:00:05,  2.81s/it]                                                      {'loss': 0.0041, 'learning_rate': 3.704384185254288e-05, 'epoch': 16.84}
 34%|███▍      | 665/1950 [1:25:18<1:00:05,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 11:21:34,243 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:21:34,243 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:21:34,243 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                      
                                             [A{'eval_loss': 0.2152099609375, 'eval_runtime': 3.2949, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 16.84}
 34%|███▍      | 665/1950 [1:25:21<1:00:05,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 34%|███▍      | 666/1950 [1:25:23<1:17:52,  3.64s/it] 34%|███▍      | 667/1950 [1:25:26<1:09:42,  3.26s/it] 34%|███▍      | 668/1950 [1:25:28<1:03:15,  2.96s/it] 34%|███▍      | 669/1950 [1:25:30<59:32,  2.79s/it]   34%|███▍      | 670/1950 [1:25:33<56:45,  2.66s/it]                                                    {'loss': 0.0066, 'learning_rate': 3.6866978736208957e-05, 'epoch': 16.96}
 34%|███▍      | 670/1950 [1:25:33<56:45,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 11:21:49,213 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:21:49,213 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:21:49,214 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2252197265625, 'eval_runtime': 3.2958, 'eval_samples_per_second': 21.239, 'eval_steps_per_second': 2.731, 'epoch': 16.96}
 34%|███▍      | 670/1950 [1:25:36<56:45,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 34%|███▍      | 671/1950 [1:25:39<1:16:27,  3.59s/it] 34%|███▍      | 672/1950 [1:25:41<1:08:15,  3.20s/it] 35%|███▍      | 673/1950 [1:25:43<1:02:13,  2.92s/it] 35%|███▍      | 674/1950 [1:25:45<58:30,  2.75s/it]   35%|███▍      | 675/1950 [1:25:48<56:20,  2.65s/it]                                                    {'loss': 0.0039, 'learning_rate': 3.668934558863088e-05, 'epoch': 17.09}
 35%|███▍      | 675/1950 [1:25:48<56:20,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 11:22:04,310 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:22:04,310 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:22:04,310 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.217529296875, 'eval_runtime': 3.2961, 'eval_samples_per_second': 21.237, 'eval_steps_per_second': 2.73, 'epoch': 17.09}
 35%|███▍      | 675/1950 [1:25:51<56:20,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 35%|███▍      | 676/1950 [1:25:54<1:15:53,  3.57s/it] 35%|███▍      | 677/1950 [1:25:56<1:08:19,  3.22s/it] 35%|███▍      | 678/1950 [1:25:58<1:03:14,  2.98s/it] 35%|███▍      | 679/1950 [1:26:01<1:01:09,  2.89s/it] 35%|███▍      | 680/1950 [1:26:03<57:51,  2.73s/it]                                                      {'loss': 0.0058, 'learning_rate': 3.651095393616904e-05, 'epoch': 17.22}
 35%|███▍      | 680/1950 [1:26:03<57:51,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 11:22:19,898 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:22:19,898 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:22:19,898 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A                                                    
                                             [A{'eval_loss': 0.217529296875, 'eval_runtime': 3.2969, 'eval_samples_per_second': 21.232, 'eval_steps_per_second': 2.73, 'epoch': 17.22}
 35%|███▍      | 680/1950 [1:26:07<57:51,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A
                                             [A 35%|███▍      | 681/1950 [1:26:09<1:16:42,  3.63s/it] 35%|███▍      | 682/1950 [1:26:12<1:08:43,  3.25s/it] 35%|███▌      | 683/1950 [1:26:14<1:04:11,  3.04s/it] 35%|███▌      | 684/1950 [1:26:17<1:00:56,  2.89s/it] 35%|███▌      | 685/1950 [1:26:19<57:42,  2.74s/it]                                                      {'loss': 0.0097, 'learning_rate': 3.633181535440212e-05, 'epoch': 17.34}
 35%|███▌      | 685/1950 [1:26:19<57:42,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 11:22:35,451 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:22:35,452 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:22:35,452 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2235107421875, 'eval_runtime': 3.2963, 'eval_samples_per_second': 21.236, 'eval_steps_per_second': 2.73, 'epoch': 17.34}
 35%|███▌      | 685/1950 [1:26:22<57:42,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 35%|███▌      | 686/1950 [1:26:25<1:16:38,  3.64s/it] 35%|███▌      | 687/1950 [1:26:27<1:08:58,  3.28s/it] 35%|███▌      | 688/1950 [1:26:30<1:04:20,  3.06s/it] 35%|███▌      | 689/1950 [1:26:32<1:00:50,  2.90s/it] 35%|███▌      | 690/1950 [1:26:35<57:02,  2.72s/it]                                                      {'loss': 0.0057, 'learning_rate': 3.615194146737598e-05, 'epoch': 17.47}
 35%|███▌      | 690/1950 [1:26:35<57:02,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 11:22:50,988 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:22:50,988 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:22:50,988 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.231689453125, 'eval_runtime': 3.2894, 'eval_samples_per_second': 21.281, 'eval_steps_per_second': 2.736, 'epoch': 17.47}
 35%|███▌      | 690/1950 [1:26:38<57:02,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 35%|███▌      | 691/1950 [1:26:41<1:18:03,  3.72s/it] 35%|███▌      | 692/1950 [1:26:43<1:09:05,  3.30s/it] 36%|███▌      | 693/1950 [1:26:46<1:06:11,  3.16s/it] 36%|███▌      | 694/1950 [1:26:48<1:00:50,  2.91s/it] 36%|███▌      | 695/1950 [1:26:51<59:39,  2.85s/it]                                                      {'loss': 0.0083, 'learning_rate': 3.597134394684937e-05, 'epoch': 17.59}
 36%|███▌      | 695/1950 [1:26:51<59:39,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 11:23:07,239 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:23:07,239 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:23:07,239 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.213134765625, 'eval_runtime': 3.2899, 'eval_samples_per_second': 21.277, 'eval_steps_per_second': 2.736, 'epoch': 17.59}
 36%|███▌      | 695/1950 [1:26:54<59:39,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 36%|███▌      | 696/1950 [1:26:57<1:17:36,  3.71s/it] 36%|███▌      | 697/1950 [1:26:59<1:10:00,  3.35s/it] 36%|███▌      | 698/1950 [1:27:01<1:02:39,  3.00s/it] 36%|███▌      | 699/1950 [1:27:04<59:04,  2.83s/it]   36%|███▌      | 700/1950 [1:27:06<56:18,  2.70s/it]                                                    {'loss': 0.0054, 'learning_rate': 3.579003451153661e-05, 'epoch': 17.72}
 36%|███▌      | 700/1950 [1:27:06<56:18,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 11:23:22,494 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:23:22,495 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:23:22,495 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.21142578125, 'eval_runtime': 3.2907, 'eval_samples_per_second': 21.272, 'eval_steps_per_second': 2.735, 'epoch': 17.72}
 36%|███▌      | 700/1950 [1:27:09<56:18,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 11:23:40,540 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 11:23:40,685 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 11:23:40,686 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/special_tokens_map.json
[2024-02-05 11:23:41,786] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step700 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 11:23:55,792] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/mp_rank_00_model_states.pt
[2024-02-05 11:23:55,792] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/mp_rank_00_model_states.pt...
[2024-02-05 11:31:52,171] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/mp_rank_00_model_states.pt.
[2024-02-05 11:31:53,173] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 11:31:53,855] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 11:31:53,859] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-700/global_step700/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 11:31:53,859] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step700 is ready now!
 36%|███▌      | 701/1950 [1:35:40<54:07:52, 156.02s/it] 36%|███▌      | 702/1950 [1:35:42<38:06:39, 109.94s/it] 36%|███▌      | 703/1950 [1:35:45<26:53:30, 77.63s/it]  36%|███▌      | 704/1950 [1:35:47<19:05:38, 55.17s/it] 36%|███▌      | 705/1950 [1:35:50<13:36:22, 39.34s/it]                                                       {'loss': 0.0076, 'learning_rate': 3.5608024926347114e-05, 'epoch': 17.85}
 36%|███▌      | 705/1950 [1:35:50<13:36:22, 39.34s/it][INFO|trainer.py:3242] 2024-02-05 11:32:06,105 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:32:06,105 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:32:06,105 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.01it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.60it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.2098388671875, 'eval_runtime': 3.1774, 'eval_samples_per_second': 22.031, 'eval_steps_per_second': 2.833, 'epoch': 17.85}
 36%|███▌      | 705/1950 [1:35:53<13:36:22, 39.34s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 36%|███▌      | 706/1950 [1:35:55<10:04:45, 29.17s/it] 36%|███▋      | 707/1950 [1:35:57<7:16:58, 21.09s/it]  36%|███▋      | 708/1950 [1:36:00<5:20:31, 15.48s/it] 36%|███▋      | 709/1950 [1:36:02<3:58:32, 11.53s/it] 36%|███▋      | 710/1950 [1:36:04<3:01:01,  8.76s/it]                                                      {'loss': 0.0042, 'learning_rate': 3.5425327001622036e-05, 'epoch': 17.97}
 36%|███▋      | 710/1950 [1:36:04<3:01:01,  8.76s/it][INFO|trainer.py:3242] 2024-02-05 11:32:20,768 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:32:20,768 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:32:20,769 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.12it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                      
                                             [A{'eval_loss': 0.2239990234375, 'eval_runtime': 3.1974, 'eval_samples_per_second': 21.893, 'eval_steps_per_second': 2.815, 'epoch': 17.97}
 36%|███▋      | 710/1950 [1:36:08<3:01:01,  8.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 36%|███▋      | 711/1950 [1:36:10<2:40:28,  7.77s/it] 37%|███▋      | 712/1950 [1:36:12<2:06:04,  6.11s/it] 37%|███▋      | 713/1950 [1:36:14<1:41:45,  4.94s/it] 37%|███▋      | 714/1950 [1:36:16<1:24:59,  4.13s/it] 37%|███▋      | 715/1950 [1:36:19<1:14:19,  3.61s/it]                                                      {'loss': 0.0061, 'learning_rate': 3.524195259236789e-05, 'epoch': 18.1}
 37%|███▋      | 715/1950 [1:36:19<1:14:19,  3.61s/it][INFO|trainer.py:3242] 2024-02-05 11:32:35,312 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:32:35,312 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:32:35,312 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.09it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                      
                                             [A{'eval_loss': 0.216552734375, 'eval_runtime': 3.2203, 'eval_samples_per_second': 21.737, 'eval_steps_per_second': 2.795, 'epoch': 18.1}
 37%|███▋      | 715/1950 [1:36:22<1:14:19,  3.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 37%|███▋      | 716/1950 [1:36:25<1:26:36,  4.21s/it] 37%|███▋      | 717/1950 [1:36:27<1:14:29,  3.62s/it] 37%|███▋      | 718/1950 [1:36:29<1:07:41,  3.30s/it] 37%|███▋      | 719/1950 [1:36:32<1:03:17,  3.08s/it] 37%|███▋      | 720/1950 [1:36:34<58:19,  2.84s/it]                                                      {'loss': 0.0039, 'learning_rate': 3.505791359748733e-05, 'epoch': 18.23}
 37%|███▋      | 720/1950 [1:36:34<58:19,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 11:32:50,586 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:32:50,587 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:32:50,587 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                    
                                             [A{'eval_loss': 0.2099609375, 'eval_runtime': 3.235, 'eval_samples_per_second': 21.639, 'eval_steps_per_second': 2.782, 'epoch': 18.23}
 37%|███▋      | 720/1950 [1:36:37<58:19,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 37%|███▋      | 721/1950 [1:36:40<1:15:03,  3.66s/it] 37%|███▋      | 722/1950 [1:36:42<1:07:24,  3.29s/it] 37%|███▋      | 723/1950 [1:36:45<1:02:38,  3.06s/it] 37%|███▋      | 724/1950 [1:36:47<58:25,  2.86s/it]   37%|███▋      | 725/1950 [1:36:49<55:09,  2.70s/it]                                                    {'loss': 0.0032, 'learning_rate': 3.487322195900698e-05, 'epoch': 18.35}
 37%|███▋      | 725/1950 [1:36:49<55:09,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 11:33:05,834 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:33:05,835 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:33:05,835 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.87it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.2125244140625, 'eval_runtime': 3.246, 'eval_samples_per_second': 21.565, 'eval_steps_per_second': 2.773, 'epoch': 18.35}
 37%|███▋      | 725/1950 [1:36:53<55:09,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 37%|███▋      | 726/1950 [1:36:55<1:14:11,  3.64s/it] 37%|███▋      | 727/1950 [1:36:58<1:06:18,  3.25s/it] 37%|███▋      | 728/1950 [1:37:00<1:02:27,  3.07s/it] 37%|███▋      | 729/1950 [1:37:03<58:17,  2.86s/it]   37%|███▋      | 730/1950 [1:37:05<55:40,  2.74s/it]                                                    {'loss': 0.0059, 'learning_rate': 3.4687889661302576e-05, 'epoch': 18.48}
 37%|███▋      | 730/1950 [1:37:05<55:40,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 11:33:21,479 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:33:21,479 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:33:21,479 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.2169189453125, 'eval_runtime': 3.2601, 'eval_samples_per_second': 21.472, 'eval_steps_per_second': 2.761, 'epoch': 18.48}
 37%|███▋      | 730/1950 [1:37:08<55:40,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 37%|███▋      | 731/1950 [1:37:11<1:14:22,  3.66s/it] 38%|███▊      | 732/1950 [1:37:13<1:06:19,  3.27s/it] 38%|███▊      | 733/1950 [1:37:16<1:03:17,  3.12s/it] 38%|███▊      | 734/1950 [1:37:18<57:36,  2.84s/it]   38%|███▊      | 735/1950 [1:37:21<56:52,  2.81s/it]                                                    {'loss': 0.0048, 'learning_rate': 3.450192873032134e-05, 'epoch': 18.61}
 38%|███▊      | 735/1950 [1:37:21<56:52,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 11:33:37,344 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:33:37,344 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:33:37,344 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.232421875, 'eval_runtime': 3.2741, 'eval_samples_per_second': 21.38, 'eval_steps_per_second': 2.749, 'epoch': 18.61}
 38%|███▊      | 735/1950 [1:37:24<56:52,  2.81s/it]
100%|██████████| 9/9 [00:03<00:00,  2.76it/s][A
                                             [A 38%|███▊      | 736/1950 [1:37:27<1:15:02,  3.71s/it] 38%|███▊      | 737/1950 [1:37:29<1:07:21,  3.33s/it] 38%|███▊      | 738/1950 [1:37:32<1:01:09,  3.03s/it] 38%|███▊      | 739/1950 [1:37:34<57:06,  2.83s/it]   38%|███▊      | 740/1950 [1:37:36<54:43,  2.71s/it]                                                    {'loss': 0.0055, 'learning_rate': 3.43153512328016e-05, 'epoch': 18.73}
 38%|███▊      | 740/1950 [1:37:36<54:43,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 11:33:52,734 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:33:52,734 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:33:52,734 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.22119140625, 'eval_runtime': 3.2803, 'eval_samples_per_second': 21.34, 'eval_steps_per_second': 2.744, 'epoch': 18.73}
 38%|███▊      | 740/1950 [1:37:40<54:43,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 38%|███▊      | 741/1950 [1:37:42<1:13:01,  3.62s/it] 38%|███▊      | 742/1950 [1:37:44<1:05:06,  3.23s/it] 38%|███▊      | 743/1950 [1:37:47<1:00:15,  3.00s/it] 38%|███▊      | 744/1950 [1:37:49<57:27,  2.86s/it]   38%|███▊      | 745/1950 [1:37:52<54:09,  2.70s/it]                                                    {'loss': 0.0025, 'learning_rate': 3.4128169275489766e-05, 'epoch': 18.86}
 38%|███▊      | 745/1950 [1:37:52<54:09,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 11:34:08,105 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:34:08,105 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:34:08,105 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.22412109375, 'eval_runtime': 3.2882, 'eval_samples_per_second': 21.288, 'eval_steps_per_second': 2.737, 'epoch': 18.86}
 38%|███▊      | 745/1950 [1:37:55<54:09,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 38%|███▊      | 746/1950 [1:37:57<1:11:39,  3.57s/it] 38%|███▊      | 747/1950 [1:38:00<1:03:32,  3.17s/it] 38%|███▊      | 748/1950 [1:38:02<58:32,  2.92s/it]   38%|███▊      | 749/1950 [1:38:04<55:07,  2.75s/it] 38%|███▊      | 750/1950 [1:38:07<53:08,  2.66s/it]                                                    {'loss': 0.0042, 'learning_rate': 3.394039500435483e-05, 'epoch': 18.99}
 38%|███▊      | 750/1950 [1:38:07<53:08,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 11:34:23,085 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:34:23,085 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:34:23,085 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2265625, 'eval_runtime': 3.2937, 'eval_samples_per_second': 21.253, 'eval_steps_per_second': 2.733, 'epoch': 18.99}
 38%|███▊      | 750/1950 [1:38:10<53:08,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 39%|███▊      | 751/1950 [1:38:12<1:10:38,  3.54s/it] 39%|███▊      | 752/1950 [1:38:14<1:02:37,  3.14s/it] 39%|███▊      | 753/1950 [1:38:17<57:12,  2.87s/it]   39%|███▊      | 754/1950 [1:38:19<54:27,  2.73s/it] 39%|███▊      | 755/1950 [1:38:22<52:29,  2.64s/it]                                                    {'loss': 0.002, 'learning_rate': 3.3752040603800146e-05, 'epoch': 19.11}
 39%|███▊      | 755/1950 [1:38:22<52:29,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 11:34:37,940 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:34:37,940 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:34:37,940 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2354736328125, 'eval_runtime': 3.2924, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 19.11}
 39%|███▊      | 755/1950 [1:38:25<52:29,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 39%|███▉      | 756/1950 [1:38:27<1:11:00,  3.57s/it] 39%|███▉      | 757/1950 [1:38:30<1:04:04,  3.22s/it] 39%|███▉      | 758/1950 [1:38:32<1:00:11,  3.03s/it] 39%|███▉      | 759/1950 [1:38:34<55:04,  2.77s/it]   39%|███▉      | 760/1950 [1:38:37<52:16,  2.64s/it]                                                    {'loss': 0.0038, 'learning_rate': 3.3563118295872843e-05, 'epoch': 19.24}
 39%|███▉      | 760/1950 [1:38:37<52:16,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 11:34:53,172 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:34:53,172 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:34:53,172 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2222900390625, 'eval_runtime': 3.2901, 'eval_samples_per_second': 21.276, 'eval_steps_per_second': 2.736, 'epoch': 19.24}
 39%|███▉      | 760/1950 [1:38:40<52:16,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 39%|███▉      | 761/1950 [1:38:42<1:10:18,  3.55s/it] 39%|███▉      | 762/1950 [1:38:45<1:04:03,  3.24s/it] 39%|███▉      | 763/1950 [1:38:47<59:15,  3.00s/it]   39%|███▉      | 764/1950 [1:38:50<56:32,  2.86s/it] 39%|███▉      | 765/1950 [1:38:52<53:59,  2.73s/it]                                                    {'loss': 0.0026, 'learning_rate': 3.3373640339470745e-05, 'epoch': 19.37}
 39%|███▉      | 765/1950 [1:38:52<53:59,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 11:35:08,772 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:35:08,772 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:35:08,772 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2247314453125, 'eval_runtime': 3.294, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 19.37}
 39%|███▉      | 765/1950 [1:38:56<53:59,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 39%|███▉      | 766/1950 [1:38:58<1:11:44,  3.64s/it] 39%|███▉      | 767/1950 [1:39:01<1:05:46,  3.34s/it] 39%|███▉      | 768/1950 [1:39:03<1:01:28,  3.12s/it] 39%|███▉      | 769/1950 [1:39:06<56:32,  2.87s/it]   39%|███▉      | 770/1950 [1:39:08<56:18,  2.86s/it]                                                    {'loss': 0.0049, 'learning_rate': 3.318361902954692e-05, 'epoch': 19.49}
 39%|███▉      | 770/1950 [1:39:08<56:18,  2.86s/it][INFO|trainer.py:3242] 2024-02-05 11:35:24,904 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:35:24,904 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:35:24,905 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.224609375, 'eval_runtime': 3.2933, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 19.49}
 39%|███▉      | 770/1950 [1:39:12<56:18,  2.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 40%|███▉      | 771/1950 [1:39:14<1:12:39,  3.70s/it] 40%|███▉      | 772/1950 [1:39:17<1:08:03,  3.47s/it] 40%|███▉      | 773/1950 [1:39:19<1:01:12,  3.12s/it] 40%|███▉      | 774/1950 [1:39:22<58:53,  3.00s/it]   40%|███▉      | 775/1950 [1:39:25<55:16,  2.82s/it]                                                    {'loss': 0.0026, 'learning_rate': 3.2993066696311845e-05, 'epoch': 19.62}
 40%|███▉      | 775/1950 [1:39:25<55:16,  2.82s/it][INFO|trainer.py:3242] 2024-02-05 11:35:40,921 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:35:40,921 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:35:40,921 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.24365234375, 'eval_runtime': 3.2945, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 19.62}
 40%|███▉      | 775/1950 [1:39:28<55:16,  2.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 40%|███▉      | 776/1950 [1:39:30<1:13:01,  3.73s/it] 40%|███▉      | 777/1950 [1:39:33<1:04:26,  3.30s/it] 40%|███▉      | 778/1950 [1:39:35<59:20,  3.04s/it]   40%|███▉      | 779/1950 [1:39:37<55:15,  2.83s/it] 40%|████      | 780/1950 [1:39:40<52:45,  2.71s/it]                                                    {'loss': 0.0034, 'learning_rate': 3.280199570443337e-05, 'epoch': 19.75}
 40%|████      | 780/1950 [1:39:40<52:45,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 11:35:56,251 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:35:56,251 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:35:56,251 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.241455078125, 'eval_runtime': 3.2926, 'eval_samples_per_second': 21.26, 'eval_steps_per_second': 2.733, 'epoch': 19.75}
 40%|████      | 780/1950 [1:39:43<52:45,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 40%|████      | 781/1950 [1:39:45<1:09:49,  3.58s/it] 40%|████      | 782/1950 [1:39:48<1:02:17,  3.20s/it] 40%|████      | 783/1950 [1:39:51<59:57,  3.08s/it]   40%|████      | 784/1950 [1:39:53<56:13,  2.89s/it] 40%|████      | 785/1950 [1:39:55<52:36,  2.71s/it]                                                    {'loss': 0.0045, 'learning_rate': 3.261041845223432e-05, 'epoch': 19.87}
 40%|████      | 785/1950 [1:39:55<52:36,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 11:36:11,728 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:36:11,729 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:36:11,729 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2252197265625, 'eval_runtime': 3.2886, 'eval_samples_per_second': 21.286, 'eval_steps_per_second': 2.737, 'epoch': 19.87}
 40%|████      | 785/1950 [1:39:59<52:36,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 40%|████      | 786/1950 [1:40:01<1:09:25,  3.58s/it] 40%|████      | 787/1950 [1:40:03<1:03:16,  3.26s/it] 40%|████      | 788/1950 [1:40:06<58:12,  3.01s/it]   40%|████      | 789/1950 [1:40:08<54:44,  2.83s/it] 41%|████      | 790/1950 [1:40:11<51:56,  2.69s/it]                                                    {'loss': 0.0017, 'learning_rate': 3.241834737088804e-05, 'epoch': 20.0}
 41%|████      | 790/1950 [1:40:11<51:56,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 11:36:27,040 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:36:27,040 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:36:27,040 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2310791015625, 'eval_runtime': 3.2964, 'eval_samples_per_second': 21.235, 'eval_steps_per_second': 2.73, 'epoch': 20.0}
 41%|████      | 790/1950 [1:40:14<51:56,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 41%|████      | 791/1950 [1:40:16<1:08:50,  3.56s/it] 41%|████      | 792/1950 [1:40:19<1:01:31,  3.19s/it] 41%|████      | 793/1950 [1:40:21<55:52,  2.90s/it]   41%|████      | 794/1950 [1:40:23<53:45,  2.79s/it] 41%|████      | 795/1950 [1:40:26<51:33,  2.68s/it]                                                    {'loss': 0.0014, 'learning_rate': 3.222579492361179e-05, 'epoch': 20.13}
 41%|████      | 795/1950 [1:40:26<51:33,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 11:36:42,138 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:36:42,138 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:36:42,138 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.2379150390625, 'eval_runtime': 3.2884, 'eval_samples_per_second': 21.287, 'eval_steps_per_second': 2.737, 'epoch': 20.13}
 41%|████      | 795/1950 [1:40:29<51:33,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 41%|████      | 796/1950 [1:40:31<1:07:57,  3.53s/it] 41%|████      | 797/1950 [1:40:34<1:01:52,  3.22s/it] 41%|████      | 798/1950 [1:40:36<57:50,  3.01s/it]   41%|████      | 799/1950 [1:40:38<52:57,  2.76s/it] 41%|████      | 800/1950 [1:40:41<50:37,  2.64s/it]                                                    {'loss': 0.003, 'learning_rate': 3.2032773604857915e-05, 'epoch': 20.25}
 41%|████      | 800/1950 [1:40:41<50:37,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 11:36:57,217 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:36:57,217 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:36:57,217 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.23193359375, 'eval_runtime': 3.2934, 'eval_samples_per_second': 21.254, 'eval_steps_per_second': 2.733, 'epoch': 20.25}
 41%|████      | 800/1950 [1:40:44<50:37,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 11:37:14,930 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 11:37:15,076 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 11:37:15,077 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/special_tokens_map.json
[2024-02-05 11:37:16,156] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step800 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 11:37:30,050] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/mp_rank_00_model_states.pt
[2024-02-05 11:37:30,051] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/mp_rank_00_model_states.pt...
[2024-02-05 11:45:28,360] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/mp_rank_00_model_states.pt.
[2024-02-05 11:45:29,355] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 11:45:30,051] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 11:45:30,056] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-800/global_step800/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 11:45:30,056] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step800 is ready now!
 41%|████      | 801/1950 [1:49:16<49:56:33, 156.48s/it] 41%|████      | 802/1950 [1:49:19<35:10:10, 110.29s/it] 41%|████      | 803/1950 [1:49:21<24:49:17, 77.91s/it]  41%|████      | 804/1950 [1:49:23<17:34:24, 55.20s/it] 41%|████▏     | 805/1950 [1:49:26<12:31:20, 39.37s/it]                                                       {'loss': 0.0024, 'learning_rate': 3.183929593950317e-05, 'epoch': 20.38}
 41%|████▏     | 805/1950 [1:49:26<12:31:20, 39.37s/it][INFO|trainer.py:3242] 2024-02-05 11:45:42,185 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:45:42,186 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:45:42,186 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.98it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.19it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                       
                                             [A{'eval_loss': 0.2303466796875, 'eval_runtime': 3.188, 'eval_samples_per_second': 21.958, 'eval_steps_per_second': 2.823, 'epoch': 20.38}
 41%|████▏     | 805/1950 [1:49:29<12:31:20, 39.37s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 41%|████▏     | 806/1950 [1:49:31<9:17:07, 29.22s/it]  41%|████▏     | 807/1950 [1:49:34<6:43:56, 21.20s/it] 41%|████▏     | 808/1950 [1:49:36<4:56:22, 15.57s/it] 41%|████▏     | 809/1950 [1:49:39<3:41:07, 11.63s/it] 42%|████▏     | 810/1950 [1:49:41<2:49:12,  8.91s/it]                                                      {'loss': 0.0027, 'learning_rate': 3.164537448203601e-05, 'epoch': 20.51}
 42%|████▏     | 810/1950 [1:49:41<2:49:12,  8.91s/it][INFO|trainer.py:3242] 2024-02-05 11:45:57,611 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:45:57,611 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:45:57,611 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.97it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                      
                                             [A{'eval_loss': 0.229248046875, 'eval_runtime': 3.2009, 'eval_samples_per_second': 21.869, 'eval_steps_per_second': 2.812, 'epoch': 20.51}
 42%|████▏     | 810/1950 [1:49:44<2:49:12,  8.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 42%|████▏     | 811/1950 [1:49:47<2:29:35,  7.88s/it] 42%|████▏     | 812/1950 [1:49:50<2:01:13,  6.39s/it] 42%|████▏     | 813/1950 [1:49:52<1:37:39,  5.15s/it] 42%|████▏     | 814/1950 [1:49:55<1:24:00,  4.44s/it] 42%|████▏     | 815/1950 [1:49:57<1:12:10,  3.82s/it]                                                      {'loss': 0.0013, 'learning_rate': 3.14510218157419e-05, 'epoch': 20.63}
 42%|████▏     | 815/1950 [1:49:57<1:12:10,  3.82s/it][INFO|trainer.py:3242] 2024-02-05 11:46:13,413 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:46:13,413 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:46:13,413 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                      
                                             [A{'eval_loss': 0.2489013671875, 'eval_runtime': 3.2194, 'eval_samples_per_second': 21.743, 'eval_steps_per_second': 2.796, 'epoch': 20.63}
 42%|████▏     | 815/1950 [1:50:00<1:12:10,  3.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 42%|████▏     | 816/1950 [1:50:03<1:22:36,  4.37s/it] 42%|████▏     | 817/1950 [1:50:05<1:11:02,  3.76s/it] 42%|████▏     | 818/1950 [1:50:07<1:02:58,  3.34s/it] 42%|████▏     | 819/1950 [1:50:10<57:49,  3.07s/it]   42%|████▏     | 820/1950 [1:50:12<54:29,  2.89s/it]                                                    {'loss': 0.0032, 'learning_rate': 3.125625055188684e-05, 'epoch': 20.76}
 42%|████▏     | 820/1950 [1:50:12<54:29,  2.89s/it][INFO|trainer.py:3242] 2024-02-05 11:46:28,692 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:46:28,693 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:46:28,693 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.53it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                    
                                             [A{'eval_loss': 0.2384033203125, 'eval_runtime': 3.2369, 'eval_samples_per_second': 21.626, 'eval_steps_per_second': 2.78, 'epoch': 20.76}
 42%|████▏     | 820/1950 [1:50:16<54:29,  2.89s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 42%|████▏     | 821/1950 [1:50:18<1:09:31,  3.69s/it] 42%|████▏     | 822/1950 [1:50:20<1:02:13,  3.31s/it] 42%|████▏     | 823/1950 [1:50:23<58:04,  3.09s/it]   42%|████▏     | 824/1950 [1:50:25<53:48,  2.87s/it] 42%|████▏     | 825/1950 [1:50:28<51:12,  2.73s/it]                                                    {'loss': 0.0027, 'learning_rate': 3.1061073328899023e-05, 'epoch': 20.89}
 42%|████▏     | 825/1950 [1:50:28<51:12,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 11:46:44,009 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:46:44,009 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:46:44,009 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.2333984375, 'eval_runtime': 3.2459, 'eval_samples_per_second': 21.566, 'eval_steps_per_second': 2.773, 'epoch': 20.89}
 42%|████▏     | 825/1950 [1:50:31<51:12,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 42%|████▏     | 826/1950 [1:50:33<1:06:52,  3.57s/it] 42%|████▏     | 827/1950 [1:50:35<59:36,  3.18s/it]   42%|████▏     | 828/1950 [1:50:38<55:02,  2.94s/it] 43%|████▎     | 829/1950 [1:50:40<52:18,  2.80s/it] 43%|████▎     | 830/1950 [1:50:43<49:44,  2.66s/it]                                                    {'loss': 0.002, 'learning_rate': 3.0865502811548755e-05, 'epoch': 21.01}
 43%|████▎     | 830/1950 [1:50:43<49:44,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 11:46:59,016 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:46:59,016 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:46:59,017 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.232421875, 'eval_runtime': 3.2683, 'eval_samples_per_second': 21.418, 'eval_steps_per_second': 2.754, 'epoch': 21.01}
 43%|████▎     | 830/1950 [1:50:46<49:44,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 43%|████▎     | 831/1950 [1:50:48<1:05:46,  3.53s/it] 43%|████▎     | 832/1950 [1:50:51<59:21,  3.19s/it]   43%|████▎     | 833/1950 [1:50:53<55:09,  2.96s/it] 43%|████▎     | 834/1950 [1:50:55<52:36,  2.83s/it] 43%|████▎     | 835/1950 [1:50:58<49:43,  2.68s/it]                                                    {'loss': 0.0013, 'learning_rate': 3.066955169012664e-05, 'epoch': 21.14}
 43%|████▎     | 835/1950 [1:50:58<49:43,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 11:47:14,236 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:47:14,236 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:47:14,236 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.2396240234375, 'eval_runtime': 3.2763, 'eval_samples_per_second': 21.366, 'eval_steps_per_second': 2.747, 'epoch': 21.14}
 43%|████▎     | 835/1950 [1:51:01<49:43,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 43%|████▎     | 836/1950 [1:51:04<1:06:51,  3.60s/it] 43%|████▎     | 837/1950 [1:51:06<1:01:45,  3.33s/it] 43%|████▎     | 838/1950 [1:51:09<56:12,  3.03s/it]   43%|████▎     | 839/1950 [1:51:11<52:10,  2.82s/it] 43%|████▎     | 840/1950 [1:51:13<49:37,  2.68s/it]                                                    {'loss': 0.0023, 'learning_rate': 3.0473232679620127e-05, 'epoch': 21.27}
 43%|████▎     | 840/1950 [1:51:13<49:37,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 11:47:29,700 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:47:29,700 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:47:29,700 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.23095703125, 'eval_runtime': 3.282, 'eval_samples_per_second': 21.329, 'eval_steps_per_second': 2.742, 'epoch': 21.27}
 43%|████▎     | 840/1950 [1:51:17<49:37,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 43%|████▎     | 841/1950 [1:51:19<1:07:24,  3.65s/it] 43%|████▎     | 842/1950 [1:51:22<1:00:19,  3.27s/it] 43%|████▎     | 843/1950 [1:51:24<56:24,  3.06s/it]   43%|████▎     | 844/1950 [1:51:27<52:46,  2.86s/it] 43%|████▎     | 845/1950 [1:51:29<50:46,  2.76s/it]                                                    {'loss': 0.0015, 'learning_rate': 3.0276558518888493e-05, 'epoch': 21.39}
 43%|████▎     | 845/1950 [1:51:29<50:46,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 11:47:45,466 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:47:45,467 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:47:45,467 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.2265625, 'eval_runtime': 3.2897, 'eval_samples_per_second': 21.279, 'eval_steps_per_second': 2.736, 'epoch': 21.39}
 43%|████▎     | 845/1950 [1:51:32<50:46,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 43%|████▎     | 846/1950 [1:51:35<1:07:58,  3.69s/it] 43%|████▎     | 847/1950 [1:51:37<1:01:21,  3.34s/it] 43%|████▎     | 848/1950 [1:51:40<55:11,  3.01s/it]   44%|████▎     | 849/1950 [1:51:43<54:22,  2.96s/it] 44%|████▎     | 850/1950 [1:51:45<50:48,  2.77s/it]                                                    {'loss': 0.0016, 'learning_rate': 3.007954196983616e-05, 'epoch': 21.52}
 44%|████▎     | 850/1950 [1:51:45<50:48,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 11:48:01,269 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:48:01,269 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:48:01,270 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2274169921875, 'eval_runtime': 3.2919, 'eval_samples_per_second': 21.265, 'eval_steps_per_second': 2.734, 'epoch': 21.52}
 44%|████▎     | 850/1950 [1:51:48<50:48,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 44%|████▎     | 851/1950 [1:51:51<1:09:34,  3.80s/it] 44%|████▎     | 852/1950 [1:51:53<1:01:20,  3.35s/it] 44%|████▎     | 853/1950 [1:51:56<57:54,  3.17s/it]   44%|████▍     | 854/1950 [1:51:58<53:23,  2.92s/it] 44%|████▍     | 855/1950 [1:52:01<51:00,  2.79s/it]                                                    {'loss': 0.0019, 'learning_rate': 2.988219581658468e-05, 'epoch': 21.65}
 44%|████▍     | 855/1950 [1:52:01<51:00,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 11:48:17,368 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:48:17,368 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:48:17,368 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.44it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A                                                    
                                             [A{'eval_loss': 0.2275390625, 'eval_runtime': 3.3057, 'eval_samples_per_second': 21.176, 'eval_steps_per_second': 2.723, 'epoch': 21.65}
 44%|████▍     | 855/1950 [1:52:04<51:00,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A
                                             [A 44%|████▍     | 856/1950 [1:52:07<1:06:06,  3.63s/it] 44%|████▍     | 857/1950 [1:52:09<59:30,  3.27s/it]   44%|████▍     | 858/1950 [1:52:11<55:12,  3.03s/it] 44%|████▍     | 859/1950 [1:52:14<52:23,  2.88s/it] 44%|████▍     | 860/1950 [1:52:16<49:36,  2.73s/it]                                                    {'loss': 0.0009, 'learning_rate': 2.9684532864643122e-05, 'epoch': 21.77}
 44%|████▍     | 860/1950 [1:52:16<49:36,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 11:48:32,747 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:48:32,748 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:48:32,748 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2364501953125, 'eval_runtime': 3.2938, 'eval_samples_per_second': 21.252, 'eval_steps_per_second': 2.732, 'epoch': 21.77}
 44%|████▍     | 860/1950 [1:52:20<49:36,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 44%|████▍     | 861/1950 [1:52:22<1:05:48,  3.63s/it] 44%|████▍     | 862/1950 [1:52:25<1:01:05,  3.37s/it] 44%|████▍     | 863/1950 [1:52:27<56:00,  3.09s/it]   44%|████▍     | 864/1950 [1:52:30<51:42,  2.86s/it] 44%|████▍     | 865/1950 [1:52:32<48:23,  2.68s/it]                                                    {'loss': 0.0015, 'learning_rate': 2.9486565940077166e-05, 'epoch': 21.9}
 44%|████▍     | 865/1950 [1:52:32<48:23,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 11:48:48,241 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:48:48,241 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:48:48,241 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2425537109375, 'eval_runtime': 3.2949, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 21.9}
 44%|████▍     | 865/1950 [1:52:35<48:23,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 44%|████▍     | 866/1950 [1:52:38<1:05:06,  3.60s/it] 44%|████▍     | 867/1950 [1:52:40<58:14,  3.23s/it]   45%|████▍     | 868/1950 [1:52:42<53:20,  2.96s/it] 45%|████▍     | 869/1950 [1:52:45<49:50,  2.77s/it] 45%|████▍     | 870/1950 [1:52:47<47:10,  2.62s/it]                                                    {'loss': 0.0013, 'learning_rate': 2.9288307888676863e-05, 'epoch': 22.03}
 45%|████▍     | 870/1950 [1:52:47<47:10,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 11:49:03,286 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:49:03,286 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:49:03,287 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2459716796875, 'eval_runtime': 3.2951, 'eval_samples_per_second': 21.243, 'eval_steps_per_second': 2.731, 'epoch': 22.03}
 45%|████▍     | 870/1950 [1:52:50<47:10,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 45%|████▍     | 871/1950 [1:52:52<1:02:52,  3.50s/it] 45%|████▍     | 872/1950 [1:52:55<55:52,  3.11s/it]   45%|████▍     | 873/1950 [1:52:57<52:35,  2.93s/it] 45%|████▍     | 874/1950 [1:53:00<49:47,  2.78s/it] 45%|████▍     | 875/1950 [1:53:02<46:51,  2.62s/it]                                                    {'loss': 0.0009, 'learning_rate': 2.908977157512305e-05, 'epoch': 22.15}
 45%|████▍     | 875/1950 [1:53:02<46:51,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 11:49:18,202 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:49:18,202 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:49:18,202 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2445068359375, 'eval_runtime': 3.2957, 'eval_samples_per_second': 21.24, 'eval_steps_per_second': 2.731, 'epoch': 22.15}
 45%|████▍     | 875/1950 [1:53:05<46:51,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 45%|████▍     | 876/1950 [1:53:08<1:03:34,  3.55s/it] 45%|████▍     | 877/1950 [1:53:10<57:19,  3.21s/it]   45%|████▌     | 878/1950 [1:53:12<52:11,  2.92s/it] 45%|████▌     | 879/1950 [1:53:15<49:38,  2.78s/it] 45%|████▌     | 880/1950 [1:53:17<47:57,  2.69s/it]                                                    {'loss': 0.001, 'learning_rate': 2.889096988215259e-05, 'epoch': 22.28}
 45%|████▌     | 880/1950 [1:53:17<47:57,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 11:49:33,522 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:49:33,522 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:49:33,522 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2420654296875, 'eval_runtime': 3.2982, 'eval_samples_per_second': 21.224, 'eval_steps_per_second': 2.729, 'epoch': 22.28}
 45%|████▌     | 880/1950 [1:53:20<47:57,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 45%|████▌     | 881/1950 [1:53:23<1:04:29,  3.62s/it] 45%|████▌     | 882/1950 [1:53:25<58:40,  3.30s/it]   45%|████▌     | 883/1950 [1:53:28<53:40,  3.02s/it] 45%|████▌     | 884/1950 [1:53:30<51:09,  2.88s/it] 45%|████▌     | 885/1950 [1:53:33<48:35,  2.74s/it]                                                    {'loss': 0.0009, 'learning_rate': 2.8691915709722466e-05, 'epoch': 22.41}
 45%|████▌     | 885/1950 [1:53:33<48:35,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 11:49:49,188 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:49:49,188 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:49:49,188 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2421875, 'eval_runtime': 3.2906, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 22.41}
 45%|████▌     | 885/1950 [1:53:36<48:35,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 45%|████▌     | 886/1950 [1:53:39<1:05:43,  3.71s/it] 45%|████▌     | 887/1950 [1:53:41<58:45,  3.32s/it]   46%|████▌     | 888/1950 [1:53:44<54:05,  3.06s/it] 46%|████▌     | 889/1950 [1:53:46<52:00,  2.94s/it] 46%|████▌     | 890/1950 [1:53:49<48:48,  2.76s/it]                                                    {'loss': 0.0011, 'learning_rate': 2.849262197417265e-05, 'epoch': 22.53}
 46%|████▌     | 890/1950 [1:53:49<48:48,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 11:50:05,028 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:50:05,028 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:50:05,028 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.236083984375, 'eval_runtime': 3.2875, 'eval_samples_per_second': 21.293, 'eval_steps_per_second': 2.738, 'epoch': 22.53}
 46%|████▌     | 890/1950 [1:53:52<48:48,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 46%|████▌     | 891/1950 [1:53:55<1:06:48,  3.79s/it] 46%|████▌     | 892/1950 [1:53:57<58:41,  3.33s/it]   46%|████▌     | 893/1950 [1:54:00<55:49,  3.17s/it] 46%|████▌     | 894/1950 [1:54:02<51:42,  2.94s/it] 46%|████▌     | 895/1950 [1:54:05<49:34,  2.82s/it]                                                    {'loss': 0.0015, 'learning_rate': 2.8293101607388063e-05, 'epoch': 22.66}
 46%|████▌     | 895/1950 [1:54:05<49:34,  2.82s/it][INFO|trainer.py:3242] 2024-02-05 11:50:21,198 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:50:21,199 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:50:21,199 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2320556640625, 'eval_runtime': 3.2957, 'eval_samples_per_second': 21.24, 'eval_steps_per_second': 2.731, 'epoch': 22.66}
 46%|████▌     | 895/1950 [1:54:08<49:34,  2.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 46%|████▌     | 896/1950 [1:54:10<1:04:43,  3.68s/it] 46%|████▌     | 897/1950 [1:54:13<57:50,  3.30s/it]   46%|████▌     | 898/1950 [1:54:15<53:20,  3.04s/it] 46%|████▌     | 899/1950 [1:54:18<49:51,  2.85s/it] 46%|████▌     | 900/1950 [1:54:20<47:05,  2.69s/it]                                                    {'loss': 0.001, 'learning_rate': 2.8093367555959366e-05, 'epoch': 22.78}
 46%|████▌     | 900/1950 [1:54:20<47:05,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 11:50:36,458 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:50:36,458 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:50:36,459 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.232421875, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 22.78}
 46%|████▌     | 900/1950 [1:54:23<47:05,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 11:50:54,668 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 11:50:54,818 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 11:50:54,819 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/special_tokens_map.json
[2024-02-05 11:50:55,888] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step900 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 11:51:10,067] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/mp_rank_00_model_states.pt
[2024-02-05 11:51:10,067] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/mp_rank_00_model_states.pt...
[2024-02-05 11:59:06,605] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/mp_rank_00_model_states.pt.
[2024-02-05 11:59:07,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 11:59:08,304] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 11:59:08,306] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-900/global_step900/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 11:59:08,307] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step900 is ready now!
 46%|████▌     | 901/1950 [2:02:54<45:31:05, 156.21s/it] 46%|████▋     | 902/1950 [2:02:57<32:03:36, 110.13s/it] 46%|████▋     | 903/1950 [2:02:59<22:37:24, 77.79s/it]  46%|████▋     | 904/1950 [2:03:02<16:01:19, 55.14s/it] 46%|████▋     | 905/1950 [2:03:04<11:24:30, 39.30s/it]                                                       {'loss': 0.0013, 'learning_rate': 2.7893432780342927e-05, 'epoch': 22.91}
 46%|████▋     | 905/1950 [2:03:04<11:24:30, 39.30s/it][INFO|trainer.py:3242] 2024-02-05 11:59:20,469 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:59:20,469 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:59:20,469 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.98it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.18it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.2376708984375, 'eval_runtime': 3.1787, 'eval_samples_per_second': 22.021, 'eval_steps_per_second': 2.831, 'epoch': 22.91}
 46%|████▋     | 905/1950 [2:03:07<11:24:30, 39.30s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 46%|████▋     | 906/1950 [2:03:09<8:27:06, 29.14s/it]  47%|████▋     | 907/1950 [2:03:12<6:07:16, 21.13s/it] 47%|████▋     | 908/1950 [2:03:14<4:30:14, 15.56s/it] 47%|████▋     | 909/1950 [2:03:17<3:20:30, 11.56s/it] 47%|████▋     | 910/1950 [2:03:19<2:31:23,  8.73s/it]                                                      {'loss': 0.0011, 'learning_rate': 2.7693310254019823e-05, 'epoch': 23.04}
 47%|████▋     | 910/1950 [2:03:19<2:31:23,  8.73s/it][INFO|trainer.py:3242] 2024-02-05 11:59:35,257 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:59:35,258 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:59:35,258 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.18it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                      
                                             [A{'eval_loss': 0.244384765625, 'eval_runtime': 3.1999, 'eval_samples_per_second': 21.876, 'eval_steps_per_second': 2.813, 'epoch': 23.04}
 47%|████▋     | 910/1950 [2:03:22<2:31:23,  8.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 47%|████▋     | 911/1950 [2:03:24<2:14:09,  7.75s/it] 47%|████▋     | 912/1950 [2:03:27<1:45:53,  6.12s/it] 47%|████▋     | 913/1950 [2:03:29<1:26:34,  5.01s/it] 47%|████▋     | 914/1950 [2:03:31<1:12:40,  4.21s/it] 47%|████▋     | 915/1950 [2:03:34<1:03:01,  3.65s/it]                                                      {'loss': 0.0009, 'learning_rate': 2.7493012962653997e-05, 'epoch': 23.16}
 47%|████▋     | 915/1950 [2:03:34<1:03:01,  3.65s/it][INFO|trainer.py:3242] 2024-02-05 11:59:50,142 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 11:59:50,142 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 11:59:50,142 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                      
                                             [A{'eval_loss': 0.249267578125, 'eval_runtime': 3.2172, 'eval_samples_per_second': 21.758, 'eval_steps_per_second': 2.797, 'epoch': 23.16}
 47%|████▋     | 915/1950 [2:03:37<1:03:01,  3.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 47%|████▋     | 916/1950 [2:03:40<1:14:24,  4.32s/it] 47%|████▋     | 917/1950 [2:03:42<1:04:31,  3.75s/it] 47%|████▋     | 918/1950 [2:03:44<56:51,  3.31s/it]   47%|████▋     | 919/1950 [2:03:47<51:46,  3.01s/it] 47%|████▋     | 920/1950 [2:03:49<48:49,  2.84s/it]                                                    {'loss': 0.001, 'learning_rate': 2.7292553903249658e-05, 'epoch': 23.29}
 47%|████▋     | 920/1950 [2:03:49<48:49,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 12:00:05,482 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:00:05,482 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:00:05,482 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.26it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                    
                                             [A{'eval_loss': 0.2431640625, 'eval_runtime': 3.2294, 'eval_samples_per_second': 21.676, 'eval_steps_per_second': 2.787, 'epoch': 23.29}
 47%|████▋     | 920/1950 [2:03:52<48:49,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 47%|████▋     | 921/1950 [2:03:55<1:02:52,  3.67s/it] 47%|████▋     | 922/1950 [2:03:57<57:19,  3.35s/it]   47%|████▋     | 923/1950 [2:04:00<52:05,  3.04s/it] 47%|████▋     | 924/1950 [2:04:02<48:49,  2.86s/it] 47%|████▋     | 925/1950 [2:04:05<47:00,  2.75s/it]                                                    {'loss': 0.0008, 'learning_rate': 2.7091946083307896e-05, 'epoch': 23.42}
 47%|████▋     | 925/1950 [2:04:05<47:00,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 12:00:20,930 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:00:20,930 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:00:20,930 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                    
                                             [A{'eval_loss': 0.2413330078125, 'eval_runtime': 3.2496, 'eval_samples_per_second': 21.541, 'eval_steps_per_second': 2.77, 'epoch': 23.42}
 47%|████▋     | 925/1950 [2:04:08<47:00,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 47%|████▋     | 926/1950 [2:04:10<1:01:58,  3.63s/it] 48%|████▊     | 927/1950 [2:04:12<54:34,  3.20s/it]   48%|████▊     | 928/1950 [2:04:15<52:34,  3.09s/it] 48%|████▊     | 929/1950 [2:04:18<49:55,  2.93s/it] 48%|████▊     | 930/1950 [2:04:21<49:32,  2.91s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.6891202519982657e-05, 'epoch': 23.54}
 48%|████▊     | 930/1950 [2:04:21<49:32,  2.91s/it][INFO|trainer.py:3242] 2024-02-05 12:00:37,075 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:00:37,075 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:00:37,075 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                    
                                             [A{'eval_loss': 0.240478515625, 'eval_runtime': 3.2638, 'eval_samples_per_second': 21.447, 'eval_steps_per_second': 2.758, 'epoch': 23.54}
 48%|████▊     | 930/1950 [2:04:24<49:32,  2.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 48%|████▊     | 931/1950 [2:04:26<1:03:46,  3.76s/it] 48%|████▊     | 932/1950 [2:04:29<58:47,  3.46s/it]   48%|████▊     | 933/1950 [2:04:32<53:19,  3.15s/it] 48%|████▊     | 934/1950 [2:04:34<50:03,  2.96s/it] 48%|████▊     | 935/1950 [2:04:36<46:19,  2.74s/it]                                                    {'loss': 0.001, 'learning_rate': 2.6690336239236097e-05, 'epoch': 23.67}
 48%|████▊     | 935/1950 [2:04:36<46:19,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:00:52,724 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:00:52,725 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:00:52,725 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                    
                                             [A{'eval_loss': 0.2406005859375, 'eval_runtime': 3.2699, 'eval_samples_per_second': 21.407, 'eval_steps_per_second': 2.752, 'epoch': 23.67}
 48%|████▊     | 935/1950 [2:04:40<46:19,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 48%|████▊     | 936/1950 [2:04:42<1:01:29,  3.64s/it] 48%|████▊     | 937/1950 [2:04:44<54:49,  3.25s/it]   48%|████▊     | 938/1950 [2:04:47<50:33,  3.00s/it] 48%|████▊     | 939/1950 [2:04:49<47:21,  2.81s/it] 48%|████▊     | 940/1950 [2:04:51<44:50,  2.66s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.6489360274993314e-05, 'epoch': 23.8}
 48%|████▊     | 940/1950 [2:04:51<44:50,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 12:01:07,909 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:01:07,909 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:01:07,909 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.240966796875, 'eval_runtime': 3.277, 'eval_samples_per_second': 21.361, 'eval_steps_per_second': 2.746, 'epoch': 23.8}
 48%|████▊     | 940/1950 [2:04:55<44:50,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 48%|████▊     | 941/1950 [2:04:58<1:02:53,  3.74s/it] 48%|████▊     | 942/1950 [2:05:00<55:37,  3.31s/it]   48%|████▊     | 943/1950 [2:05:02<50:11,  2.99s/it] 48%|████▊     | 944/1950 [2:05:05<46:50,  2.79s/it] 48%|████▊     | 945/1950 [2:05:07<44:50,  2.68s/it]                                                    {'loss': 0.0007, 'learning_rate': 2.628828766829663e-05, 'epoch': 23.92}
 48%|████▊     | 945/1950 [2:05:07<44:50,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 12:01:23,452 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:01:23,453 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:01:23,453 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2403564453125, 'eval_runtime': 3.2889, 'eval_samples_per_second': 21.284, 'eval_steps_per_second': 2.736, 'epoch': 23.92}
 48%|████▊     | 945/1950 [2:05:10<44:50,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 49%|████▊     | 946/1950 [2:05:13<59:29,  3.55s/it] 49%|████▊     | 947/1950 [2:05:15<53:12,  3.18s/it] 49%|████▊     | 948/1950 [2:05:17<48:50,  2.92s/it] 49%|████▊     | 949/1950 [2:05:20<45:35,  2.73s/it] 49%|████▊     | 950/1950 [2:05:22<42:58,  2.58s/it]                                                    {'loss': 0.001, 'learning_rate': 2.608713146645934e-05, 'epoch': 24.05}
 49%|████▊     | 950/1950 [2:05:22<42:58,  2.58s/it][INFO|trainer.py:3242] 2024-02-05 12:01:38,195 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:01:38,195 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:01:38,195 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.24072265625, 'eval_runtime': 3.3008, 'eval_samples_per_second': 21.207, 'eval_steps_per_second': 2.727, 'epoch': 24.05}
 49%|████▊     | 950/1950 [2:05:25<42:58,  2.58s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 49%|████▉     | 951/1950 [2:05:27<57:36,  3.46s/it] 49%|████▉     | 952/1950 [2:05:30<52:49,  3.18s/it] 49%|████▉     | 953/1950 [2:05:32<49:00,  2.95s/it] 49%|████▉     | 954/1950 [2:05:35<46:05,  2.78s/it] 49%|████▉     | 955/1950 [2:05:37<45:40,  2.75s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.5885904722219105e-05, 'epoch': 24.18}
 49%|████▉     | 955/1950 [2:05:37<45:40,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 12:01:53,722 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:01:53,723 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:01:53,723 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2449951171875, 'eval_runtime': 3.291, 'eval_samples_per_second': 21.27, 'eval_steps_per_second': 2.735, 'epoch': 24.18}
 49%|████▉     | 955/1950 [2:05:41<45:40,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 49%|████▉     | 956/1950 [2:05:43<1:00:34,  3.66s/it] 49%|████▉     | 957/1950 [2:05:45<53:09,  3.21s/it]   49%|████▉     | 958/1950 [2:05:48<49:02,  2.97s/it] 49%|████▉     | 959/1950 [2:05:50<47:02,  2.85s/it] 49%|████▉     | 960/1950 [2:05:53<45:07,  2.73s/it]                                                    {'loss': 0.0007, 'learning_rate': 2.5684620492891002e-05, 'epoch': 24.3}
 49%|████▉     | 960/1950 [2:05:53<45:07,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 12:02:09,092 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:02:09,092 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:02:09,093 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.24462890625, 'eval_runtime': 3.2906, 'eval_samples_per_second': 21.272, 'eval_steps_per_second': 2.735, 'epoch': 24.3}
 49%|████▉     | 960/1950 [2:05:56<45:07,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 49%|████▉     | 961/1950 [2:05:59<1:00:27,  3.67s/it] 49%|████▉     | 962/1950 [2:06:01<54:42,  3.32s/it]   49%|████▉     | 963/1950 [2:06:04<51:07,  3.11s/it] 49%|████▉     | 964/1950 [2:06:06<47:53,  2.91s/it] 49%|████▉     | 965/1950 [2:06:09<47:33,  2.90s/it]                                                    {'loss': 0.0007, 'learning_rate': 2.548329183952021e-05, 'epoch': 24.43}
 49%|████▉     | 965/1950 [2:06:09<47:33,  2.90s/it][INFO|trainer.py:3242] 2024-02-05 12:02:25,380 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:02:25,380 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:02:25,380 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.243896484375, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 24.43}
 49%|████▉     | 965/1950 [2:06:12<47:33,  2.90s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 50%|████▉     | 966/1950 [2:06:15<1:01:21,  3.74s/it] 50%|████▉     | 967/1950 [2:06:17<54:58,  3.36s/it]   50%|████▉     | 968/1950 [2:06:20<51:19,  3.14s/it] 50%|████▉     | 969/1950 [2:06:22<47:33,  2.91s/it] 50%|████▉     | 970/1950 [2:06:25<48:18,  2.96s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.5281931826034537e-05, 'epoch': 24.56}
 50%|████▉     | 970/1950 [2:06:25<48:18,  2.96s/it][INFO|trainer.py:3242] 2024-02-05 12:02:41,620 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:02:41,620 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:02:41,620 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.70it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.24267578125, 'eval_runtime': 3.2996, 'eval_samples_per_second': 21.215, 'eval_steps_per_second': 2.728, 'epoch': 24.56}
 50%|████▉     | 970/1950 [2:06:29<48:18,  2.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 50%|████▉     | 971/1950 [2:06:31<1:00:47,  3.73s/it] 50%|████▉     | 972/1950 [2:06:33<55:54,  3.43s/it]   50%|████▉     | 973/1950 [2:06:36<51:19,  3.15s/it] 50%|████▉     | 974/1950 [2:06:39<48:50,  3.00s/it] 50%|█████     | 975/1950 [2:06:41<45:53,  2.82s/it]                                                    {'loss': 0.0011, 'learning_rate': 2.5080553518396703e-05, 'epoch': 24.68}
 50%|█████     | 975/1950 [2:06:41<45:53,  2.82s/it][INFO|trainer.py:3242] 2024-02-05 12:02:57,445 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:02:57,445 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:02:57,445 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2412109375, 'eval_runtime': 3.2928, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 24.68}
 50%|█████     | 975/1950 [2:06:44<45:53,  2.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 50%|█████     | 976/1950 [2:06:47<1:00:08,  3.71s/it] 50%|█████     | 977/1950 [2:06:49<54:12,  3.34s/it]   50%|█████     | 978/1950 [2:06:52<50:07,  3.09s/it] 50%|█████     | 979/1950 [2:06:54<46:24,  2.87s/it] 50%|█████     | 980/1950 [2:06:57<44:18,  2.74s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.48791699837565e-05, 'epoch': 24.81}
 50%|█████     | 980/1950 [2:06:57<44:18,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:03:13,000 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:03:13,000 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:03:13,000 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.240966796875, 'eval_runtime': 3.291, 'eval_samples_per_second': 21.27, 'eval_steps_per_second': 2.735, 'epoch': 24.81}
 50%|█████     | 980/1950 [2:07:00<44:18,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 50%|█████     | 981/1950 [2:07:02<59:26,  3.68s/it] 50%|█████     | 982/1950 [2:07:05<52:42,  3.27s/it] 50%|█████     | 983/1950 [2:07:07<48:26,  3.01s/it] 50%|█████     | 984/1950 [2:07:09<44:57,  2.79s/it] 51%|█████     | 985/1950 [2:07:12<43:15,  2.69s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.467779428960288e-05, 'epoch': 24.94}
 51%|█████     | 985/1950 [2:07:12<43:15,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:03:28,316 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:03:28,316 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:03:28,316 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.240234375, 'eval_runtime': 3.2862, 'eval_samples_per_second': 21.301, 'eval_steps_per_second': 2.739, 'epoch': 24.94}
 51%|█████     | 985/1950 [2:07:15<43:15,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 51%|█████     | 986/1950 [2:07:18<57:20,  3.57s/it] 51%|█████     | 987/1950 [2:07:20<52:33,  3.27s/it] 51%|█████     | 988/1950 [2:07:22<47:55,  2.99s/it] 51%|█████     | 989/1950 [2:07:25<44:03,  2.75s/it] 51%|█████     | 990/1950 [2:07:27<41:56,  2.62s/it]                                                    {'loss': 0.0004, 'learning_rate': 2.447643950291608e-05, 'epoch': 25.06}
 51%|█████     | 990/1950 [2:07:27<41:56,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 12:03:43,365 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:03:43,365 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:03:43,365 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                    
                                             [A{'eval_loss': 0.240966796875, 'eval_runtime': 3.2874, 'eval_samples_per_second': 21.294, 'eval_steps_per_second': 2.738, 'epoch': 25.06}
 51%|█████     | 990/1950 [2:07:30<41:56,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 51%|█████     | 991/1950 [2:07:33<56:31,  3.54s/it] 51%|█████     | 992/1950 [2:07:35<52:13,  3.27s/it] 51%|█████     | 993/1950 [2:07:38<48:03,  3.01s/it] 51%|█████     | 994/1950 [2:07:40<45:12,  2.84s/it] 51%|█████     | 995/1950 [2:07:43<44:08,  2.77s/it]                                                    {'loss': 0.0005, 'learning_rate': 2.4275118689319637e-05, 'epoch': 25.19}
 51%|█████     | 995/1950 [2:07:43<44:08,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 12:03:59,152 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:03:59,152 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:03:59,152 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                    
                                             [A{'eval_loss': 0.2431640625, 'eval_runtime': 3.2883, 'eval_samples_per_second': 21.288, 'eval_steps_per_second': 2.737, 'epoch': 25.19}
 51%|█████     | 995/1950 [2:07:46<44:08,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 51%|█████     | 996/1950 [2:07:48<57:04,  3.59s/it] 51%|█████     | 997/1950 [2:07:50<50:44,  3.19s/it] 51%|█████     | 998/1950 [2:07:53<46:47,  2.95s/it] 51%|█████     | 999/1950 [2:07:55<44:33,  2.81s/it] 51%|█████▏    | 1000/1950 [2:07:58<42:26,  2.68s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.4073844912232658e-05, 'epoch': 25.32}
 51%|█████▏    | 1000/1950 [2:07:58<42:26,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 12:04:14,160 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:04:14,160 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:04:14,160 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.24365234375, 'eval_runtime': 3.2933, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 25.32}
 51%|█████▏    | 1000/1950 [2:08:01<42:26,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 12:04:31,899 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 12:04:32,043 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 12:04:32,044 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/special_tokens_map.json
[2024-02-05 12:04:33,222] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 12:04:47,071] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/mp_rank_00_model_states.pt
[2024-02-05 12:04:47,071] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/mp_rank_00_model_states.pt...
[2024-02-05 12:12:44,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/mp_rank_00_model_states.pt.
[2024-02-05 12:12:45,727] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 12:12:46,420] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 12:12:46,423] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 12:12:46,423] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 51%|█████▏    | 1001/1950 [2:16:32<41:11:28, 156.26s/it] 51%|█████▏    | 1002/1950 [2:16:35<28:59:09, 110.07s/it] 51%|█████▏    | 1003/1950 [2:16:37<20:27:36, 77.78s/it]  51%|█████▏    | 1004/1950 [2:16:40<14:30:11, 55.19s/it] 52%|█████▏    | 1005/1950 [2:16:42<10:20:25, 39.39s/it]                                                        {'loss': 0.0006, 'learning_rate': 2.3872631232022084e-05, 'epoch': 25.44}
 52%|█████▏    | 1005/1950 [2:16:42<10:20:25, 39.39s/it][INFO|trainer.py:3242] 2024-02-05 12:12:58,529 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:12:58,529 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:12:58,530 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.97it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.19it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                        
                                             [A{'eval_loss': 0.243408203125, 'eval_runtime': 3.189, 'eval_samples_per_second': 21.951, 'eval_steps_per_second': 2.822, 'epoch': 25.44}
 52%|█████▏    | 1005/1950 [2:16:45<10:20:25, 39.39s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 52%|█████▏    | 1006/1950 [2:16:48<7:39:38, 29.21s/it]  52%|█████▏    | 1007/1950 [2:16:51<5:35:32, 21.35s/it] 52%|█████▏    | 1008/1950 [2:16:53<4:06:23, 15.69s/it] 52%|█████▏    | 1009/1950 [2:16:56<3:06:35, 11.90s/it] 52%|█████▏    | 1010/1950 [2:16:58<2:21:34,  9.04s/it]                                                       {'loss': 0.0004, 'learning_rate': 2.3671490705155286e-05, 'epoch': 25.57}
 52%|█████▏    | 1010/1950 [2:16:58<2:21:34,  9.04s/it][INFO|trainer.py:3242] 2024-02-05 12:13:14,877 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:13:14,877 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:13:14,877 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.97it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.99it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                       
                                             [A{'eval_loss': 0.2435302734375, 'eval_runtime': 3.2074, 'eval_samples_per_second': 21.825, 'eval_steps_per_second': 2.806, 'epoch': 25.57}
 52%|█████▏    | 1010/1950 [2:17:02<2:21:34,  9.04s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 52%|█████▏    | 1011/1950 [2:17:04<2:06:59,  8.11s/it] 52%|█████▏    | 1012/1950 [2:17:07<1:39:35,  6.37s/it] 52%|█████▏    | 1013/1950 [2:17:09<1:21:02,  5.19s/it] 52%|█████▏    | 1014/1950 [2:17:11<1:07:14,  4.31s/it] 52%|█████▏    | 1015/1950 [2:17:14<58:23,  3.75s/it]                                                       {'loss': 0.0009, 'learning_rate': 2.34704363833528e-05, 'epoch': 25.7}
 52%|█████▏    | 1015/1950 [2:17:14<58:23,  3.75s/it][INFO|trainer.py:3242] 2024-02-05 12:13:30,265 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:13:30,265 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:13:30,265 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.93it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.09it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                     
                                             [A{'eval_loss': 0.243896484375, 'eval_runtime': 3.2206, 'eval_samples_per_second': 21.735, 'eval_steps_per_second': 2.795, 'epoch': 25.7}
 52%|█████▏    | 1015/1950 [2:17:17<58:23,  3.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 52%|█████▏    | 1016/1950 [2:17:20<1:07:15,  4.32s/it] 52%|█████▏    | 1017/1950 [2:17:22<57:57,  3.73s/it]   52%|█████▏    | 1018/1950 [2:17:24<51:40,  3.33s/it] 52%|█████▏    | 1019/1950 [2:17:27<47:26,  3.06s/it] 52%|█████▏    | 1020/1950 [2:17:30<46:24,  2.99s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.3269481312741453e-05, 'epoch': 25.82}
 52%|█████▏    | 1020/1950 [2:17:30<46:24,  2.99s/it][INFO|trainer.py:3242] 2024-02-05 12:13:45,934 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:13:45,934 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:13:45,934 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                     
                                             [A{'eval_loss': 0.244384765625, 'eval_runtime': 3.2388, 'eval_samples_per_second': 21.613, 'eval_steps_per_second': 2.779, 'epoch': 25.82}
 52%|█████▏    | 1020/1950 [2:17:33<46:24,  2.99s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 52%|█████▏    | 1021/1950 [2:17:35<58:33,  3.78s/it] 52%|█████▏    | 1022/1950 [2:17:37<51:34,  3.33s/it] 52%|█████▏    | 1023/1950 [2:17:40<47:19,  3.06s/it] 53%|█████▎    | 1024/1950 [2:17:42<44:28,  2.88s/it] 53%|█████▎    | 1025/1950 [2:17:45<41:39,  2.70s/it]                                                     {'loss': 0.0005, 'learning_rate': 2.3068638533007786e-05, 'epoch': 25.95}
 53%|█████▎    | 1025/1950 [2:17:45<41:39,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 12:14:01,016 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:14:01,016 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:14:01,016 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.87it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  3.56it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.25it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.09it/s][A
 67%|██████▋   | 6/9 [00:01<00:01,  2.97it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.90it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.2445068359375, 'eval_runtime': 3.3416, 'eval_samples_per_second': 20.948, 'eval_steps_per_second': 2.693, 'epoch': 25.95}
 53%|█████▎    | 1025/1950 [2:17:48<41:39,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 53%|█████▎    | 1026/1950 [2:17:50<55:14,  3.59s/it] 53%|█████▎    | 1027/1950 [2:17:53<49:34,  3.22s/it] 53%|█████▎    | 1028/1950 [2:17:55<45:22,  2.95s/it] 53%|█████▎    | 1029/1950 [2:17:57<42:06,  2.74s/it] 53%|█████▎    | 1030/1950 [2:17:59<39:32,  2.58s/it]                                                     {'loss': 0.0005, 'learning_rate': 2.2867921076551967e-05, 'epoch': 26.08}
 53%|█████▎    | 1030/1950 [2:17:59<39:32,  2.58s/it][INFO|trainer.py:3242] 2024-02-05 12:14:15,812 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:14:15,812 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:14:15,812 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.2459716796875, 'eval_runtime': 3.2695, 'eval_samples_per_second': 21.41, 'eval_steps_per_second': 2.753, 'epoch': 26.08}
 53%|█████▎    | 1030/1950 [2:18:03<39:32,  2.58s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 53%|█████▎    | 1031/1950 [2:18:05<54:05,  3.53s/it] 53%|█████▎    | 1032/1950 [2:18:08<48:49,  3.19s/it] 53%|█████▎    | 1033/1950 [2:18:10<44:19,  2.90s/it] 53%|█████▎    | 1034/1950 [2:18:12<42:09,  2.76s/it] 53%|█████▎    | 1035/1950 [2:18:15<40:43,  2.67s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.2667341967642105e-05, 'epoch': 26.2}
 53%|█████▎    | 1035/1950 [2:18:15<40:43,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 12:14:31,083 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:14:31,083 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:14:31,083 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.247314453125, 'eval_runtime': 3.2783, 'eval_samples_per_second': 21.352, 'eval_steps_per_second': 2.745, 'epoch': 26.2}
 53%|█████▎    | 1035/1950 [2:18:18<40:43,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 53%|█████▎    | 1036/1950 [2:18:20<54:09,  3.56s/it] 53%|█████▎    | 1037/1950 [2:18:23<48:52,  3.21s/it] 53%|█████▎    | 1038/1950 [2:18:25<45:17,  2.98s/it] 53%|█████▎    | 1039/1950 [2:18:28<42:59,  2.83s/it] 53%|█████▎    | 1040/1950 [2:18:30<41:17,  2.72s/it]                                                     {'loss': 0.0005, 'learning_rate': 2.246691422156913e-05, 'epoch': 26.33}
 53%|█████▎    | 1040/1950 [2:18:30<41:17,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:14:46,503 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:14:46,503 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:14:46,503 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.247314453125, 'eval_runtime': 3.2849, 'eval_samples_per_second': 21.31, 'eval_steps_per_second': 2.74, 'epoch': 26.33}
 53%|█████▎    | 1040/1950 [2:18:33<41:17,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 53%|█████▎    | 1041/1950 [2:18:36<54:00,  3.57s/it] 53%|█████▎    | 1042/1950 [2:18:38<48:55,  3.23s/it] 53%|█████▎    | 1043/1950 [2:18:40<45:03,  2.98s/it] 54%|█████▎    | 1044/1950 [2:18:43<43:32,  2.88s/it] 54%|█████▎    | 1045/1950 [2:18:45<41:03,  2.72s/it]                                                     {'loss': 0.0006, 'learning_rate': 2.2266650843802257e-05, 'epoch': 26.46}
 54%|█████▎    | 1045/1950 [2:18:45<41:03,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:15:01,886 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:15:01,886 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:15:01,886 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2459716796875, 'eval_runtime': 3.2964, 'eval_samples_per_second': 21.235, 'eval_steps_per_second': 2.73, 'epoch': 26.46}
 54%|█████▎    | 1045/1950 [2:18:49<41:03,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 54%|█████▎    | 1046/1950 [2:18:51<54:56,  3.65s/it] 54%|█████▎    | 1047/1950 [2:18:54<50:08,  3.33s/it] 54%|█████▎    | 1048/1950 [2:18:56<46:12,  3.07s/it] 54%|█████▍    | 1049/1950 [2:18:59<45:17,  3.02s/it] 54%|█████▍    | 1050/1950 [2:19:02<42:21,  2.82s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.2066564829145097e-05, 'epoch': 26.58}
 54%|█████▍    | 1050/1950 [2:19:02<42:21,  2.82s/it][INFO|trainer.py:3242] 2024-02-05 12:15:18,017 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:15:18,017 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:15:18,017 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.245849609375, 'eval_runtime': 3.296, 'eval_samples_per_second': 21.238, 'eval_steps_per_second': 2.731, 'epoch': 26.58}
 54%|█████▍    | 1050/1950 [2:19:05<42:21,  2.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 54%|█████▍    | 1051/1950 [2:19:08<57:33,  3.84s/it] 54%|█████▍    | 1052/1950 [2:19:10<51:18,  3.43s/it] 54%|█████▍    | 1053/1950 [2:19:13<47:01,  3.15s/it] 54%|█████▍    | 1054/1950 [2:19:15<43:18,  2.90s/it] 54%|█████▍    | 1055/1950 [2:19:17<40:56,  2.74s/it]                                                     {'loss': 0.0009, 'learning_rate': 2.186666916089239e-05, 'epoch': 26.71}
 54%|█████▍    | 1055/1950 [2:19:17<40:56,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:15:33,899 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:15:33,899 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:15:33,900 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2470703125, 'eval_runtime': 3.2984, 'eval_samples_per_second': 21.223, 'eval_steps_per_second': 2.729, 'epoch': 26.71}
 54%|█████▍    | 1055/1950 [2:19:21<40:56,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 54%|█████▍    | 1056/1950 [2:19:23<54:42,  3.67s/it] 54%|█████▍    | 1057/1950 [2:19:26<49:41,  3.34s/it] 54%|█████▍    | 1058/1950 [2:19:28<45:23,  3.05s/it] 54%|█████▍    | 1059/1950 [2:19:31<42:43,  2.88s/it] 54%|█████▍    | 1060/1950 [2:19:33<41:14,  2.78s/it]                                                     {'loss': 0.0005, 'learning_rate': 2.1666976809987604e-05, 'epoch': 26.84}
 54%|█████▍    | 1060/1950 [2:19:33<41:14,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 12:15:49,698 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:15:49,699 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:15:49,699 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.246337890625, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 26.84}
 54%|█████▍    | 1060/1950 [2:19:37<41:14,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 54%|█████▍    | 1061/1950 [2:19:39<53:44,  3.63s/it] 54%|█████▍    | 1062/1950 [2:19:41<48:23,  3.27s/it] 55%|█████▍    | 1063/1950 [2:19:44<44:21,  3.00s/it] 55%|█████▍    | 1064/1950 [2:19:46<41:21,  2.80s/it] 55%|█████▍    | 1065/1950 [2:19:48<39:15,  2.66s/it]                                                     {'loss': 0.0007, 'learning_rate': 2.1467500734181203e-05, 'epoch': 26.96}
 55%|█████▍    | 1065/1950 [2:19:48<39:15,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 12:16:04,781 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:16:04,782 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:16:04,782 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.24609375, 'eval_runtime': 3.2993, 'eval_samples_per_second': 21.216, 'eval_steps_per_second': 2.728, 'epoch': 26.96}
 55%|█████▍    | 1065/1950 [2:19:52<39:15,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 55%|█████▍    | 1066/1950 [2:19:54<52:47,  3.58s/it] 55%|█████▍    | 1067/1950 [2:19:56<46:58,  3.19s/it] 55%|█████▍    | 1068/1950 [2:19:59<42:33,  2.89s/it] 55%|█████▍    | 1069/1950 [2:20:01<39:51,  2.71s/it] 55%|█████▍    | 1070/1950 [2:20:03<38:17,  2.61s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.12682538771899e-05, 'epoch': 27.09}
 55%|█████▍    | 1070/1950 [2:20:03<38:17,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 12:16:19,657 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:16:19,658 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:16:19,658 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2462158203125, 'eval_runtime': 3.2955, 'eval_samples_per_second': 21.241, 'eval_steps_per_second': 2.731, 'epoch': 27.09}
 55%|█████▍    | 1070/1950 [2:20:07<38:17,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 55%|█████▍    | 1071/1950 [2:20:09<51:53,  3.54s/it] 55%|█████▍    | 1072/1950 [2:20:11<46:41,  3.19s/it] 55%|█████▌    | 1073/1950 [2:20:14<43:17,  2.96s/it] 55%|█████▌    | 1074/1950 [2:20:16<42:14,  2.89s/it] 55%|█████▌    | 1075/1950 [2:20:19<39:41,  2.72s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.1069249167856704e-05, 'epoch': 27.22}
 55%|█████▌    | 1075/1950 [2:20:19<39:41,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:16:35,225 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:16:35,225 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:16:35,225 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.2481689453125, 'eval_runtime': 3.2876, 'eval_samples_per_second': 21.292, 'eval_steps_per_second': 2.738, 'epoch': 27.22}
 55%|█████▌    | 1075/1950 [2:20:22<39:41,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 55%|█████▌    | 1076/1950 [2:20:24<52:01,  3.57s/it] 55%|█████▌    | 1077/1950 [2:20:27<46:44,  3.21s/it] 55%|█████▌    | 1078/1950 [2:20:29<43:42,  3.01s/it] 55%|█████▌    | 1079/1950 [2:20:32<41:10,  2.84s/it] 55%|█████▌    | 1080/1950 [2:20:34<39:17,  2.71s/it]                                                     {'loss': 0.0005, 'learning_rate': 2.0870499519312014e-05, 'epoch': 27.34}
 55%|█████▌    | 1080/1950 [2:20:34<39:17,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 12:16:50,538 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:16:50,538 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:16:50,538 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2464599609375, 'eval_runtime': 3.29, 'eval_samples_per_second': 21.276, 'eval_steps_per_second': 2.736, 'epoch': 27.34}
 55%|█████▌    | 1080/1950 [2:20:37<39:17,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 55%|█████▌    | 1081/1950 [2:20:40<52:00,  3.59s/it] 55%|█████▌    | 1082/1950 [2:20:42<46:55,  3.24s/it] 56%|█████▌    | 1083/1950 [2:20:45<44:03,  3.05s/it] 56%|█████▌    | 1084/1950 [2:20:47<41:23,  2.87s/it] 56%|█████▌    | 1085/1950 [2:20:50<38:53,  2.70s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.0672017828135718e-05, 'epoch': 27.47}
 56%|█████▌    | 1085/1950 [2:20:50<38:53,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 12:17:05,957 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:17:05,957 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:17:05,957 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.24609375, 'eval_runtime': 3.2914, 'eval_samples_per_second': 21.268, 'eval_steps_per_second': 2.734, 'epoch': 27.47}
 56%|█████▌    | 1085/1950 [2:20:53<38:53,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 56%|█████▌    | 1086/1950 [2:20:56<53:30,  3.72s/it] 56%|█████▌    | 1087/1950 [2:20:58<47:23,  3.29s/it] 56%|█████▌    | 1088/1950 [2:21:01<45:38,  3.18s/it] 56%|█████▌    | 1089/1950 [2:21:03<42:14,  2.94s/it] 56%|█████▌    | 1090/1950 [2:21:06<41:35,  2.90s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.0473816973520307e-05, 'epoch': 27.59}
 56%|█████▌    | 1090/1950 [2:21:06<41:35,  2.90s/it][INFO|trainer.py:3242] 2024-02-05 12:17:22,467 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:17:22,467 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:17:22,467 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.24609375, 'eval_runtime': 3.2952, 'eval_samples_per_second': 21.243, 'eval_steps_per_second': 2.731, 'epoch': 27.59}
 56%|█████▌    | 1090/1950 [2:21:09<41:35,  2.90s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 56%|█████▌    | 1091/1950 [2:21:12<53:50,  3.76s/it] 56%|█████▌    | 1092/1950 [2:21:14<48:36,  3.40s/it] 56%|█████▌    | 1093/1950 [2:21:17<43:56,  3.08s/it] 56%|█████▌    | 1094/1950 [2:21:19<41:22,  2.90s/it] 56%|█████▌    | 1095/1950 [2:21:22<38:58,  2.73s/it]                                                     {'loss': 0.0008, 'learning_rate': 2.027590981643522e-05, 'epoch': 27.72}
 56%|█████▌    | 1095/1950 [2:21:22<38:58,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 12:17:37,949 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:17:37,949 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:17:37,949 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.24609375, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 27.72}
 56%|█████▌    | 1095/1950 [2:21:25<38:58,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 56%|█████▌    | 1096/1950 [2:21:27<51:57,  3.65s/it] 56%|█████▋    | 1097/1950 [2:21:30<46:25,  3.27s/it] 56%|█████▋    | 1098/1950 [2:21:32<42:15,  2.98s/it] 56%|█████▋    | 1099/1950 [2:21:35<41:22,  2.92s/it] 56%|█████▋    | 1100/1950 [2:21:37<38:49,  2.74s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.007830919879225e-05, 'epoch': 27.85}
 56%|█████▋    | 1100/1950 [2:21:37<38:49,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:17:53,514 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:17:53,515 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:17:53,515 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2464599609375, 'eval_runtime': 3.2929, 'eval_samples_per_second': 21.258, 'eval_steps_per_second': 2.733, 'epoch': 27.85}
 56%|█████▋    | 1100/1950 [2:21:40<38:49,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 12:18:11,195 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 12:18:11,339 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 12:18:11,340 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/special_tokens_map.json
[2024-02-05 12:18:12,449] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1100 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 12:18:26,411] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/mp_rank_00_model_states.pt
[2024-02-05 12:18:26,412] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/mp_rank_00_model_states.pt...
[2024-02-05 12:26:22,422] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/mp_rank_00_model_states.pt.
[2024-02-05 12:26:23,449] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 12:26:24,124] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 12:26:24,138] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1100/global_step1100/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 12:26:24,138] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1100 is ready now!
 56%|█████▋    | 1101/1950 [2:30:10<36:44:39, 155.81s/it] 57%|█████▋    | 1102/1950 [2:30:13<25:51:56, 109.81s/it] 57%|█████▋    | 1103/1950 [2:30:15<18:17:00, 77.71s/it]  57%|█████▋    | 1104/1950 [2:30:18<12:56:45, 55.09s/it] 57%|█████▋    | 1105/1950 [2:30:20<9:12:56, 39.26s/it]                                                        {'loss': 0.0004, 'learning_rate': 1.9881027942612306e-05, 'epoch': 27.97}
 57%|█████▋    | 1105/1950 [2:30:20<9:12:56, 39.26s/it][INFO|trainer.py:3242] 2024-02-05 12:26:36,418 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:26:36,418 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:26:36,418 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.99it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.18it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                       
                                             [A{'eval_loss': 0.2469482421875, 'eval_runtime': 3.1883, 'eval_samples_per_second': 21.955, 'eval_steps_per_second': 2.823, 'epoch': 27.97}
 57%|█████▋    | 1105/1950 [2:30:23<9:12:56, 39.26s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 57%|█████▋    | 1106/1950 [2:30:26<6:49:57, 29.14s/it] 57%|█████▋    | 1107/1950 [2:30:28<4:56:17, 21.09s/it] 57%|█████▋    | 1108/1950 [2:30:30<3:36:44, 15.44s/it] 57%|█████▋    | 1109/1950 [2:30:32<2:41:05, 11.49s/it] 57%|█████▋    | 1110/1950 [2:30:35<2:03:34,  8.83s/it]                                                       {'loss': 0.0005, 'learning_rate': 1.968407884919341e-05, 'epoch': 28.1}
 57%|█████▋    | 1110/1950 [2:30:35<2:03:34,  8.83s/it][INFO|trainer.py:3242] 2024-02-05 12:26:51,388 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:26:51,388 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:26:51,389 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.28it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                       
                                             [A{'eval_loss': 0.2467041015625, 'eval_runtime': 3.2019, 'eval_samples_per_second': 21.862, 'eval_steps_per_second': 2.811, 'epoch': 28.1}
 57%|█████▋    | 1110/1950 [2:30:38<2:03:34,  8.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 57%|█████▋    | 1111/1950 [2:30:41<1:49:50,  7.85s/it] 57%|█████▋    | 1112/1950 [2:30:43<1:26:42,  6.21s/it] 57%|█████▋    | 1113/1950 [2:30:45<1:11:08,  5.10s/it] 57%|█████▋    | 1114/1950 [2:30:48<1:00:06,  4.31s/it] 57%|█████▋    | 1115/1950 [2:30:50<51:31,  3.70s/it]                                                       {'loss': 0.0003, 'learning_rate': 1.9487474698279977e-05, 'epoch': 28.23}
 57%|█████▋    | 1115/1950 [2:30:50<51:31,  3.70s/it][INFO|trainer.py:3242] 2024-02-05 12:27:06,611 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:27:06,611 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:27:06,611 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.94it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                     
                                             [A{'eval_loss': 0.247802734375, 'eval_runtime': 3.2165, 'eval_samples_per_second': 21.762, 'eval_steps_per_second': 2.798, 'epoch': 28.23}
 57%|█████▋    | 1115/1950 [2:30:53<51:31,  3.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 57%|█████▋    | 1116/1950 [2:30:56<59:24,  4.27s/it] 57%|█████▋    | 1117/1950 [2:30:58<51:51,  3.74s/it] 57%|█████▋    | 1118/1950 [2:31:01<46:31,  3.35s/it] 57%|█████▋    | 1119/1950 [2:31:03<42:24,  3.06s/it] 57%|█████▋    | 1120/1950 [2:31:06<39:33,  2.86s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.9291228247233605e-05, 'epoch': 28.35}
 57%|█████▋    | 1120/1950 [2:31:06<39:33,  2.86s/it][INFO|trainer.py:3242] 2024-02-05 12:27:21,933 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:27:21,933 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:27:21,933 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                     
                                             [A{'eval_loss': 0.25, 'eval_runtime': 3.2315, 'eval_samples_per_second': 21.662, 'eval_steps_per_second': 2.785, 'epoch': 28.35}
 57%|█████▋    | 1120/1950 [2:31:09<39:33,  2.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 57%|█████▋    | 1121/1950 [2:31:11<51:09,  3.70s/it] 58%|█████▊    | 1122/1950 [2:31:14<45:40,  3.31s/it] 58%|█████▊    | 1123/1950 [2:31:16<42:45,  3.10s/it] 58%|█████▊    | 1124/1950 [2:31:19<39:45,  2.89s/it] 58%|█████▊    | 1125/1950 [2:31:21<37:46,  2.75s/it]                                                     {'loss': 0.0005, 'learning_rate': 1.9095352230205292e-05, 'epoch': 28.48}
 58%|█████▊    | 1125/1950 [2:31:21<37:46,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 12:27:37,416 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:27:37,416 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:27:37,416 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                     
                                             [A{'eval_loss': 0.2481689453125, 'eval_runtime': 3.2427, 'eval_samples_per_second': 21.587, 'eval_steps_per_second': 2.775, 'epoch': 28.48}
 58%|█████▊    | 1125/1950 [2:31:24<37:46,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 58%|█████▊    | 1126/1950 [2:31:27<50:19,  3.66s/it] 58%|█████▊    | 1127/1950 [2:31:29<45:08,  3.29s/it] 58%|█████▊    | 1128/1950 [2:31:32<43:48,  3.20s/it] 58%|█████▊    | 1129/1950 [2:31:34<39:53,  2.92s/it] 58%|█████▊    | 1130/1950 [2:31:37<39:25,  2.89s/it]                                                     {'loss': 0.0007, 'learning_rate': 1.8899859357309064e-05, 'epoch': 28.61}
 58%|█████▊    | 1130/1950 [2:31:37<39:25,  2.89s/it][INFO|trainer.py:3242] 2024-02-05 12:27:53,694 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:27:53,694 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:27:53,694 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  2.96it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  2.91it/s][A
 67%|██████▋   | 6/9 [00:01<00:01,  2.85it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.82it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.69it/s][A
100%|██████████| 9/9 [00:03<00:00,  2.71it/s][A                                                     
                                             [A{'eval_loss': 0.2471923828125, 'eval_runtime': 3.4047, 'eval_samples_per_second': 20.56, 'eval_steps_per_second': 2.643, 'epoch': 28.61}
 58%|█████▊    | 1130/1950 [2:31:41<39:25,  2.89s/it]
100%|██████████| 9/9 [00:03<00:00,  2.71it/s][A
                                             [A 58%|█████▊    | 1131/1950 [2:31:43<50:59,  3.74s/it] 58%|█████▊    | 1132/1950 [2:31:45<45:27,  3.33s/it] 58%|█████▊    | 1133/1950 [2:31:48<41:17,  3.03s/it] 58%|█████▊    | 1134/1950 [2:31:50<38:07,  2.80s/it] 58%|█████▊    | 1135/1950 [2:31:53<36:54,  2.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.87047623137973e-05, 'epoch': 28.73}
 58%|█████▊    | 1135/1950 [2:31:53<36:54,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:28:08,924 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:28:08,925 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:28:08,925 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.248046875, 'eval_runtime': 3.2746, 'eval_samples_per_second': 21.377, 'eval_steps_per_second': 2.748, 'epoch': 28.73}
 58%|█████▊    | 1135/1950 [2:31:56<36:54,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 58%|█████▊    | 1136/1950 [2:31:58<49:52,  3.68s/it] 58%|█████▊    | 1137/1950 [2:32:01<44:20,  3.27s/it] 58%|█████▊    | 1138/1950 [2:32:03<41:20,  3.06s/it] 58%|█████▊    | 1139/1950 [2:32:06<40:04,  2.96s/it] 58%|█████▊    | 1140/1950 [2:32:08<37:32,  2.78s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.851007375923757e-05, 'epoch': 28.86}
 58%|█████▊    | 1140/1950 [2:32:08<37:32,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 12:28:24,822 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:28:24,822 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:28:24,823 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.2481689453125, 'eval_runtime': 3.2749, 'eval_samples_per_second': 21.375, 'eval_steps_per_second': 2.748, 'epoch': 28.86}
 58%|█████▊    | 1140/1950 [2:32:12<37:32,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 59%|█████▊    | 1141/1950 [2:32:14<49:21,  3.66s/it] 59%|█████▊    | 1142/1950 [2:32:16<43:47,  3.25s/it] 59%|█████▊    | 1143/1950 [2:32:19<39:59,  2.97s/it] 59%|█████▊    | 1144/1950 [2:32:21<37:38,  2.80s/it] 59%|█████▊    | 1145/1950 [2:32:24<36:08,  2.69s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.8315806326691177e-05, 'epoch': 28.99}
 59%|█████▊    | 1145/1950 [2:32:24<36:08,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:28:40,003 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:28:40,003 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:28:40,003 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.248779296875, 'eval_runtime': 3.2981, 'eval_samples_per_second': 21.224, 'eval_steps_per_second': 2.729, 'epoch': 28.99}
 59%|█████▊    | 1145/1950 [2:32:27<36:08,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 59%|█████▉    | 1146/1950 [2:32:29<47:43,  3.56s/it] 59%|█████▉    | 1147/1950 [2:32:31<42:13,  3.15s/it] 59%|█████▉    | 1148/1950 [2:32:34<39:37,  2.96s/it] 59%|█████▉    | 1149/1950 [2:32:36<37:29,  2.81s/it] 59%|█████▉    | 1150/1950 [2:32:39<36:15,  2.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.812197262189342e-05, 'epoch': 29.11}
 59%|█████▉    | 1150/1950 [2:32:39<36:15,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:28:55,270 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:28:55,270 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:28:55,270 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2479248046875, 'eval_runtime': 3.2948, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.732, 'epoch': 29.11}
 59%|█████▉    | 1150/1950 [2:32:42<36:15,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 59%|█████▉    | 1151/1950 [2:32:45<48:11,  3.62s/it] 59%|█████▉    | 1152/1950 [2:32:47<43:07,  3.24s/it] 59%|█████▉    | 1153/1950 [2:32:50<40:36,  3.06s/it] 59%|█████▉    | 1154/1950 [2:32:52<37:05,  2.80s/it] 59%|█████▉    | 1155/1950 [2:32:54<34:51,  2.63s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.7928585222435628e-05, 'epoch': 29.24}
 59%|█████▉    | 1155/1950 [2:32:54<34:51,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 12:29:10,411 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:29:10,411 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:29:10,411 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.75it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.248779296875, 'eval_runtime': 3.3065, 'eval_samples_per_second': 21.17, 'eval_steps_per_second': 2.722, 'epoch': 29.24}
 59%|█████▉    | 1155/1950 [2:32:57<34:51,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 59%|█████▉    | 1156/1950 [2:33:00<46:58,  3.55s/it] 59%|█████▉    | 1157/1950 [2:33:02<42:37,  3.23s/it] 59%|█████▉    | 1158/1950 [2:33:05<39:11,  2.97s/it] 59%|█████▉    | 1159/1950 [2:33:07<36:40,  2.78s/it] 59%|█████▉    | 1160/1950 [2:33:09<35:11,  2.67s/it]                                                     {'loss': 0.0006, 'learning_rate': 1.773565667694903e-05, 'epoch': 29.37}
 59%|█████▉    | 1160/1950 [2:33:09<35:11,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 12:29:25,705 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:29:25,705 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:29:25,705 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25146484375, 'eval_runtime': 3.2947, 'eval_samples_per_second': 21.246, 'eval_steps_per_second': 2.732, 'epoch': 29.37}
 59%|█████▉    | 1160/1950 [2:33:13<35:11,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 60%|█████▉    | 1161/1950 [2:33:15<47:51,  3.64s/it] 60%|█████▉    | 1162/1950 [2:33:18<43:31,  3.31s/it] 60%|█████▉    | 1163/1950 [2:33:20<40:21,  3.08s/it] 60%|█████▉    | 1164/1950 [2:33:22<36:56,  2.82s/it] 60%|█████▉    | 1165/1950 [2:33:25<37:14,  2.85s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.7543199504290442e-05, 'epoch': 29.49}
 60%|█████▉    | 1165/1950 [2:33:25<37:14,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 12:29:41,809 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:29:41,809 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:29:41,809 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.2476806640625, 'eval_runtime': 3.2874, 'eval_samples_per_second': 21.293, 'eval_steps_per_second': 2.738, 'epoch': 29.49}
 60%|█████▉    | 1165/1950 [2:33:29<37:14,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 60%|█████▉    | 1166/1950 [2:33:31<48:34,  3.72s/it] 60%|█████▉    | 1167/1950 [2:33:34<45:40,  3.50s/it] 60%|█████▉    | 1168/1950 [2:33:37<41:37,  3.19s/it] 60%|█████▉    | 1169/1950 [2:33:39<39:48,  3.06s/it] 60%|██████    | 1170/1950 [2:33:42<37:04,  2.85s/it]                                                     {'loss': 0.0006, 'learning_rate': 1.735122619273001e-05, 'epoch': 29.62}
 60%|██████    | 1170/1950 [2:33:42<37:04,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 12:29:58,140 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:29:58,140 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:29:58,140 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2484130859375, 'eval_runtime': 3.2968, 'eval_samples_per_second': 21.233, 'eval_steps_per_second': 2.73, 'epoch': 29.62}
 60%|██████    | 1170/1950 [2:33:45<37:04,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 60%|██████    | 1171/1950 [2:33:48<48:42,  3.75s/it] 60%|██████    | 1172/1950 [2:33:50<43:21,  3.34s/it] 60%|██████    | 1173/1950 [2:33:52<39:55,  3.08s/it] 60%|██████    | 1174/1950 [2:33:55<37:20,  2.89s/it] 60%|██████    | 1175/1950 [2:33:57<35:21,  2.74s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.715974919914082e-05, 'epoch': 29.75}
 60%|██████    | 1175/1950 [2:33:57<35:21,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:30:13,677 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:30:13,678 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:30:13,678 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.249755859375, 'eval_runtime': 3.2991, 'eval_samples_per_second': 21.218, 'eval_steps_per_second': 2.728, 'epoch': 29.75}
 60%|██████    | 1175/1950 [2:34:01<35:21,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 60%|██████    | 1176/1950 [2:34:03<46:23,  3.60s/it] 60%|██████    | 1177/1950 [2:34:05<41:22,  3.21s/it] 60%|██████    | 1178/1950 [2:34:08<40:15,  3.13s/it] 60%|██████    | 1179/1950 [2:34:10<37:07,  2.89s/it] 61%|██████    | 1180/1950 [2:34:13<34:53,  2.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.6968780948190573e-05, 'epoch': 29.87}
 61%|██████    | 1180/1950 [2:34:13<34:53,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:30:29,177 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:30:29,178 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:30:29,178 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2491455078125, 'eval_runtime': 3.2922, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 29.87}
 61%|██████    | 1180/1950 [2:34:16<34:53,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 61%|██████    | 1181/1950 [2:34:18<46:02,  3.59s/it] 61%|██████    | 1182/1950 [2:34:21<41:39,  3.25s/it] 61%|██████    | 1183/1950 [2:34:23<38:30,  3.01s/it] 61%|██████    | 1184/1950 [2:34:26<35:46,  2.80s/it] 61%|██████    | 1185/1950 [2:34:28<34:17,  2.69s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.677833383153542e-05, 'epoch': 30.0}
 61%|██████    | 1185/1950 [2:34:28<34:17,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:30:44,458 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:30:44,458 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:30:44,458 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2493896484375, 'eval_runtime': 3.291, 'eval_samples_per_second': 21.27, 'eval_steps_per_second': 2.735, 'epoch': 30.0}
 61%|██████    | 1185/1950 [2:34:31<34:17,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 61%|██████    | 1186/1950 [2:34:34<45:18,  3.56s/it] 61%|██████    | 1187/1950 [2:34:36<40:27,  3.18s/it] 61%|██████    | 1188/1950 [2:34:38<36:43,  2.89s/it] 61%|██████    | 1189/1950 [2:34:41<35:31,  2.80s/it] 61%|██████    | 1190/1950 [2:34:43<34:00,  2.69s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.6588420207015825e-05, 'epoch': 30.13}
 61%|██████    | 1190/1950 [2:34:43<34:00,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:30:59,565 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:30:59,566 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:30:59,566 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.249267578125, 'eval_runtime': 3.2889, 'eval_samples_per_second': 21.284, 'eval_steps_per_second': 2.736, 'epoch': 30.13}
 61%|██████    | 1190/1950 [2:34:46<34:00,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 61%|██████    | 1191/1950 [2:34:49<44:44,  3.54s/it] 61%|██████    | 1192/1950 [2:34:51<41:29,  3.28s/it] 61%|██████    | 1193/1950 [2:34:54<38:29,  3.05s/it] 61%|██████    | 1194/1950 [2:34:56<35:28,  2.82s/it] 61%|██████▏   | 1195/1950 [2:34:58<33:39,  2.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.6399052397854742e-05, 'epoch': 30.25}
 61%|██████▏   | 1195/1950 [2:34:58<33:39,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 12:31:14,905 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:31:14,905 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:31:14,905 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.249267578125, 'eval_runtime': 3.2885, 'eval_samples_per_second': 21.286, 'eval_steps_per_second': 2.737, 'epoch': 30.25}
 61%|██████▏   | 1195/1950 [2:35:02<33:39,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 61%|██████▏   | 1196/1950 [2:35:04<45:05,  3.59s/it] 61%|██████▏   | 1197/1950 [2:35:07<40:45,  3.25s/it] 61%|██████▏   | 1198/1950 [2:35:09<37:33,  3.00s/it] 61%|██████▏   | 1199/1950 [2:35:11<34:41,  2.77s/it] 62%|██████▏   | 1200/1950 [2:35:14<33:26,  2.68s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.6210242691857925e-05, 'epoch': 30.38}
 62%|██████▏   | 1200/1950 [2:35:14<33:26,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 12:31:30,185 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:31:30,185 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:31:30,186 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.250732421875, 'eval_runtime': 3.299, 'eval_samples_per_second': 21.219, 'eval_steps_per_second': 2.728, 'epoch': 30.38}
 62%|██████▏   | 1200/1950 [2:35:17<33:26,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 12:31:48,909 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 12:31:49,057 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 12:31:49,058 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/special_tokens_map.json
[2024-02-05 12:31:50,118] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1200 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 12:32:05,315] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/mp_rank_00_model_states.pt
[2024-02-05 12:32:05,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/mp_rank_00_model_states.pt...
[2024-02-05 12:40:03,673] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/mp_rank_00_model_states.pt.
[2024-02-05 12:40:04,710] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 12:40:05,403] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 12:40:05,406] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1200/global_step1200/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 12:40:05,406] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1200 is ready now!
 62%|██████▏   | 1201/1950 [2:43:51<32:41:45, 157.15s/it] 62%|██████▏   | 1202/1950 [2:43:54<23:01:10, 110.79s/it] 62%|██████▏   | 1203/1950 [2:43:56<16:14:46, 78.30s/it]  62%|██████▏   | 1204/1950 [2:43:59<11:30:40, 55.55s/it] 62%|██████▏   | 1205/1950 [2:44:02<8:12:45, 39.69s/it]                                                        {'loss': 0.0005, 'learning_rate': 1.6022003340616612e-05, 'epoch': 30.51}
 62%|██████▏   | 1205/1950 [2:44:02<8:12:45, 39.69s/it][INFO|trainer.py:3242] 2024-02-05 12:40:18,023 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:40:18,023 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:40:18,023 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.00it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.251220703125, 'eval_runtime': 3.1796, 'eval_samples_per_second': 22.015, 'eval_steps_per_second': 2.831, 'epoch': 30.51}
 62%|██████▏   | 1205/1950 [2:44:05<8:12:45, 39.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 62%|██████▏   | 1206/1950 [2:44:07<6:05:38, 29.49s/it] 62%|██████▏   | 1207/1950 [2:44:10<4:25:51, 21.47s/it] 62%|██████▏   | 1208/1950 [2:44:12<3:13:49, 15.67s/it] 62%|██████▏   | 1209/1950 [2:44:15<2:25:43, 11.80s/it] 62%|██████▏   | 1210/1950 [2:44:17<1:50:27,  8.96s/it]                                                       {'loss': 0.0006, 'learning_rate': 1.5834346558712562e-05, 'epoch': 30.63}
 62%|██████▏   | 1210/1950 [2:44:17<1:50:27,  8.96s/it][INFO|trainer.py:3242] 2024-02-05 12:40:33,696 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:40:33,696 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:40:33,696 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.17it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.12it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                       
                                             [A{'eval_loss': 0.2498779296875, 'eval_runtime': 3.1973, 'eval_samples_per_second': 21.894, 'eval_steps_per_second': 2.815, 'epoch': 30.63}
 62%|██████▏   | 1210/1950 [2:44:20<1:50:27,  8.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 62%|██████▏   | 1211/1950 [2:44:23<1:38:01,  7.96s/it] 62%|██████▏   | 1212/1950 [2:44:25<1:16:58,  6.26s/it] 62%|██████▏   | 1213/1950 [2:44:27<1:02:15,  5.07s/it] 62%|██████▏   | 1214/1950 [2:44:30<52:16,  4.26s/it]   62%|██████▏   | 1215/1950 [2:44:32<45:31,  3.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.564728452292542e-05, 'epoch': 30.76}
 62%|██████▏   | 1215/1950 [2:44:32<45:31,  3.72s/it][INFO|trainer.py:3242] 2024-02-05 12:40:48,736 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:40:48,736 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:40:48,736 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.09it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                     
                                             [A{'eval_loss': 0.250732421875, 'eval_runtime': 3.2212, 'eval_samples_per_second': 21.731, 'eval_steps_per_second': 2.794, 'epoch': 30.76}
 62%|██████▏   | 1215/1950 [2:44:36<45:31,  3.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 62%|██████▏   | 1216/1950 [2:44:38<52:31,  4.29s/it] 62%|██████▏   | 1217/1950 [2:44:40<45:38,  3.74s/it] 62%|██████▏   | 1218/1950 [2:44:43<41:04,  3.37s/it] 63%|██████▎   | 1219/1950 [2:44:45<36:56,  3.03s/it] 63%|██████▎   | 1220/1950 [2:44:48<34:42,  2.85s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.5460829371442625e-05, 'epoch': 30.89}
 63%|██████▎   | 1220/1950 [2:44:48<34:42,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 12:41:04,000 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:41:04,000 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:41:04,000 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.53it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.79it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                     
                                             [A{'eval_loss': 0.25, 'eval_runtime': 3.237, 'eval_samples_per_second': 21.625, 'eval_steps_per_second': 2.78, 'epoch': 30.89}
 63%|██████▎   | 1220/1950 [2:44:51<34:42,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 63%|██████▎   | 1221/1950 [2:44:53<44:21,  3.65s/it] 63%|██████▎   | 1222/1950 [2:44:55<39:32,  3.26s/it] 63%|██████▎   | 1223/1950 [2:44:58<36:11,  2.99s/it] 63%|██████▎   | 1224/1950 [2:45:00<34:13,  2.83s/it] 63%|██████▎   | 1225/1950 [2:45:03<32:04,  2.65s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.527499320307175e-05, 'epoch': 31.01}
 63%|██████▎   | 1225/1950 [2:45:03<32:04,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 12:41:18,921 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:41:18,921 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:41:18,921 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                     
                                             [A{'eval_loss': 0.250244140625, 'eval_runtime': 3.2495, 'eval_samples_per_second': 21.542, 'eval_steps_per_second': 2.77, 'epoch': 31.01}
 63%|██████▎   | 1225/1950 [2:45:06<32:04,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 63%|██████▎   | 1226/1950 [2:45:08<42:46,  3.54s/it] 63%|██████▎   | 1227/1950 [2:45:10<37:58,  3.15s/it] 63%|██████▎   | 1228/1950 [2:45:13<35:13,  2.93s/it] 63%|██████▎   | 1229/1950 [2:45:15<33:17,  2.77s/it] 63%|██████▎   | 1230/1950 [2:45:18<31:53,  2.66s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.5089788076455441e-05, 'epoch': 31.14}
 63%|██████▎   | 1230/1950 [2:45:18<31:53,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 12:41:33,979 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:41:33,979 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:41:33,979 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.2490234375, 'eval_runtime': 3.2637, 'eval_samples_per_second': 21.448, 'eval_steps_per_second': 2.758, 'epoch': 31.14}
 63%|██████▎   | 1230/1950 [2:45:21<31:53,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 63%|██████▎   | 1231/1950 [2:45:23<42:35,  3.55s/it] 63%|██████▎   | 1232/1950 [2:45:26<39:14,  3.28s/it] 63%|██████▎   | 1233/1950 [2:45:28<35:32,  2.97s/it] 63%|██████▎   | 1234/1950 [2:45:31<33:31,  2.81s/it] 63%|██████▎   | 1235/1950 [2:45:33<31:51,  2.67s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.490522600928898e-05, 'epoch': 31.27}
 63%|██████▎   | 1235/1950 [2:45:33<31:51,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 12:41:49,305 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:41:49,305 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:41:49,305 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.84it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.2498779296875, 'eval_runtime': 3.2747, 'eval_samples_per_second': 21.376, 'eval_steps_per_second': 2.748, 'epoch': 31.27}
 63%|██████▎   | 1235/1950 [2:45:36<31:51,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 63%|██████▎   | 1236/1950 [2:45:39<43:32,  3.66s/it] 63%|██████▎   | 1237/1950 [2:45:41<39:10,  3.30s/it] 63%|██████▎   | 1238/1950 [2:45:44<36:01,  3.04s/it] 64%|██████▎   | 1239/1950 [2:45:46<33:38,  2.84s/it] 64%|██████▎   | 1240/1950 [2:45:49<32:08,  2.72s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.4721318977540394e-05, 'epoch': 31.39}
 64%|██████▎   | 1240/1950 [2:45:49<32:08,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:42:04,953 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:42:04,953 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:42:04,953 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.2509765625, 'eval_runtime': 3.2827, 'eval_samples_per_second': 21.324, 'eval_steps_per_second': 2.742, 'epoch': 31.39}
 64%|██████▎   | 1240/1950 [2:45:52<32:08,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 64%|██████▎   | 1241/1950 [2:45:55<44:27,  3.76s/it] 64%|██████▎   | 1242/1950 [2:45:57<39:42,  3.37s/it] 64%|██████▎   | 1243/1950 [2:45:59<35:34,  3.02s/it] 64%|██████▍   | 1244/1950 [2:46:02<34:37,  2.94s/it] 64%|██████▍   | 1245/1950 [2:46:04<32:19,  2.75s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.4538078914673441e-05, 'epoch': 31.52}
 64%|██████▍   | 1245/1950 [2:46:04<32:19,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 12:42:20,875 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:42:20,876 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:42:20,876 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2906, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 31.52}
 64%|██████▍   | 1245/1950 [2:46:08<32:19,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 64%|██████▍   | 1246/1950 [2:46:11<44:26,  3.79s/it] 64%|██████▍   | 1247/1950 [2:46:13<39:46,  3.39s/it] 64%|██████▍   | 1248/1950 [2:46:16<37:21,  3.19s/it] 64%|██████▍   | 1249/1950 [2:46:18<34:20,  2.94s/it] 64%|██████▍   | 1250/1950 [2:46:21<32:49,  2.81s/it]                                                     {'loss': 0.0007, 'learning_rate': 1.4355517710873184e-05, 'epoch': 31.65}
 64%|██████▍   | 1250/1950 [2:46:21<32:49,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 12:42:37,156 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:42:37,156 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:42:37,157 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25048828125, 'eval_runtime': 3.3001, 'eval_samples_per_second': 21.212, 'eval_steps_per_second': 2.727, 'epoch': 31.65}
 64%|██████▍   | 1250/1950 [2:46:24<32:49,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 64%|██████▍   | 1251/1950 [2:46:26<42:24,  3.64s/it] 64%|██████▍   | 1252/1950 [2:46:29<38:54,  3.34s/it] 64%|██████▍   | 1253/1950 [2:46:31<35:32,  3.06s/it] 64%|██████▍   | 1254/1950 [2:46:34<33:17,  2.87s/it] 64%|██████▍   | 1255/1950 [2:46:36<31:18,  2.70s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.4173647212274538e-05, 'epoch': 31.77}
 64%|██████▍   | 1255/1950 [2:46:36<31:18,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 12:42:52,511 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:42:52,512 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:42:52,512 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2509765625, 'eval_runtime': 3.2987, 'eval_samples_per_second': 21.22, 'eval_steps_per_second': 2.728, 'epoch': 31.77}
 64%|██████▍   | 1255/1950 [2:46:39<31:18,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 64%|██████▍   | 1256/1950 [2:46:42<41:24,  3.58s/it] 64%|██████▍   | 1257/1950 [2:46:45<39:11,  3.39s/it] 65%|██████▍   | 1258/1950 [2:46:47<35:27,  3.07s/it] 65%|██████▍   | 1259/1950 [2:46:49<32:40,  2.84s/it] 65%|██████▍   | 1260/1950 [2:46:52<30:35,  2.66s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.3992479220193522e-05, 'epoch': 31.9}
 65%|██████▍   | 1260/1950 [2:46:52<30:35,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 12:43:07,954 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:43:07,954 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:43:07,955 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.251220703125, 'eval_runtime': 3.2918, 'eval_samples_per_second': 21.265, 'eval_steps_per_second': 2.734, 'epoch': 31.9}
 65%|██████▍   | 1260/1950 [2:46:55<30:35,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 65%|██████▍   | 1261/1950 [2:46:57<41:50,  3.64s/it] 65%|██████▍   | 1262/1950 [2:47:00<37:20,  3.26s/it] 65%|██████▍   | 1263/1950 [2:47:02<34:21,  3.00s/it] 65%|██████▍   | 1264/1950 [2:47:05<31:55,  2.79s/it] 65%|██████▍   | 1265/1950 [2:47:07<30:07,  2.64s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.3812025490361516e-05, 'epoch': 32.03}
 65%|██████▍   | 1265/1950 [2:47:07<30:07,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 12:43:23,236 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:43:23,236 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:43:23,236 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.250732421875, 'eval_runtime': 3.2894, 'eval_samples_per_second': 21.28, 'eval_steps_per_second': 2.736, 'epoch': 32.03}
 65%|██████▍   | 1265/1950 [2:47:10<30:07,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 65%|██████▍   | 1266/1950 [2:47:12<40:01,  3.51s/it] 65%|██████▍   | 1267/1950 [2:47:15<35:45,  3.14s/it] 65%|██████▌   | 1268/1950 [2:47:17<33:36,  2.96s/it] 65%|██████▌   | 1269/1950 [2:47:20<31:43,  2.79s/it] 65%|██████▌   | 1270/1950 [2:47:22<29:46,  2.63s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.3632297732162439e-05, 'epoch': 32.15}
 65%|██████▌   | 1270/1950 [2:47:22<29:46,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 12:43:38,243 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:43:38,243 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:43:38,243 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.251953125, 'eval_runtime': 3.2944, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 32.15}
 65%|██████▌   | 1270/1950 [2:47:25<29:46,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 65%|██████▌   | 1271/1950 [2:47:28<40:30,  3.58s/it] 65%|██████▌   | 1272/1950 [2:47:30<36:46,  3.25s/it] 65%|██████▌   | 1273/1950 [2:47:32<33:38,  2.98s/it] 65%|██████▌   | 1274/1950 [2:47:35<31:31,  2.80s/it] 65%|██████▌   | 1275/1950 [2:47:37<30:31,  2.71s/it]                                                     {'loss': 0.0006, 'learning_rate': 1.3453307607872977e-05, 'epoch': 32.28}
 65%|██████▌   | 1275/1950 [2:47:37<30:31,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 12:43:53,768 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:43:53,768 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:43:53,768 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25146484375, 'eval_runtime': 3.29, 'eval_samples_per_second': 21.277, 'eval_steps_per_second': 2.736, 'epoch': 32.28}
 65%|██████▌   | 1275/1950 [2:47:41<30:31,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 65%|██████▌   | 1276/1950 [2:47:43<40:56,  3.64s/it] 65%|██████▌   | 1277/1950 [2:47:46<37:13,  3.32s/it] 66%|██████▌   | 1278/1950 [2:47:48<33:35,  3.00s/it] 66%|██████▌   | 1279/1950 [2:47:50<31:51,  2.85s/it] 66%|██████▌   | 1280/1950 [2:47:53<30:32,  2.74s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.3275066731905789e-05, 'epoch': 32.41}
 66%|██████▌   | 1280/1950 [2:47:53<30:32,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:44:09,365 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:44:09,365 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:44:09,366 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.75it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253173828125, 'eval_runtime': 3.2983, 'eval_samples_per_second': 21.223, 'eval_steps_per_second': 2.729, 'epoch': 32.41}
 66%|██████▌   | 1280/1950 [2:47:56<30:32,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 66%|██████▌   | 1281/1950 [2:47:59<41:20,  3.71s/it] 66%|██████▌   | 1282/1950 [2:48:01<37:21,  3.36s/it] 66%|██████▌   | 1283/1950 [2:48:04<34:17,  3.09s/it] 66%|██████▌   | 1284/1950 [2:48:07<32:37,  2.94s/it] 66%|██████▌   | 1285/1950 [2:48:09<31:07,  2.81s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.3097586670055884e-05, 'epoch': 32.53}
 66%|██████▌   | 1285/1950 [2:48:09<31:07,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 12:44:25,435 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:44:25,435 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:44:25,435 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.86it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.71it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.72it/s][A                                                     
                                             [A{'eval_loss': 0.25390625, 'eval_runtime': 3.3135, 'eval_samples_per_second': 21.125, 'eval_steps_per_second': 2.716, 'epoch': 32.53}
 66%|██████▌   | 1285/1950 [2:48:12<31:07,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.72it/s][A
                                             [A 66%|██████▌   | 1286/1950 [2:48:15<42:38,  3.85s/it] 66%|██████▌   | 1287/1950 [2:48:18<37:25,  3.39s/it] 66%|██████▌   | 1288/1950 [2:48:20<35:35,  3.23s/it] 66%|██████▌   | 1289/1950 [2:48:23<32:41,  2.97s/it] 66%|██████▌   | 1290/1950 [2:48:25<31:05,  2.83s/it]                                                     {'loss': 0.0008, 'learning_rate': 1.2920878938750122e-05, 'epoch': 32.66}
 66%|██████▌   | 1290/1950 [2:48:25<31:05,  2.83s/it][INFO|trainer.py:3242] 2024-02-05 12:44:41,733 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:44:41,733 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:44:41,733 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25146484375, 'eval_runtime': 3.294, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 32.66}
 66%|██████▌   | 1290/1950 [2:48:29<31:05,  2.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 66%|██████▌   | 1291/1950 [2:48:31<40:22,  3.68s/it] 66%|██████▋   | 1292/1950 [2:48:33<36:11,  3.30s/it] 66%|██████▋   | 1293/1950 [2:48:36<33:13,  3.03s/it] 66%|██████▋   | 1294/1950 [2:48:38<31:03,  2.84s/it] 66%|██████▋   | 1295/1950 [2:48:41<29:35,  2.71s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.2744955004299982e-05, 'epoch': 32.78}
 66%|██████▋   | 1295/1950 [2:48:41<29:35,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 12:44:57,024 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:44:57,024 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:44:57,024 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.252197265625, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 32.78}
 66%|██████▋   | 1295/1950 [2:48:44<29:35,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 66%|██████▋   | 1296/1950 [2:48:46<39:44,  3.65s/it] 67%|██████▋   | 1297/1950 [2:48:49<36:36,  3.36s/it] 67%|██████▋   | 1298/1950 [2:48:51<33:00,  3.04s/it] 67%|██████▋   | 1299/1950 [2:48:54<30:53,  2.85s/it] 67%|██████▋   | 1300/1950 [2:48:56<29:10,  2.69s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.256982628215744e-05, 'epoch': 32.91}
 67%|██████▋   | 1300/1950 [2:48:56<29:10,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:45:12,570 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:45:12,570 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:45:12,570 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2936, 'eval_samples_per_second': 21.254, 'eval_steps_per_second': 2.733, 'epoch': 32.91}
 67%|██████▋   | 1300/1950 [2:48:59<29:10,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 12:45:30,849 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 12:45:30,992 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 12:45:30,993 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/special_tokens_map.json
[2024-02-05 12:45:32,137] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1300 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 12:45:46,925] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/mp_rank_00_model_states.pt
[2024-02-05 12:45:46,925] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/mp_rank_00_model_states.pt...
[2024-02-05 12:53:42,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/mp_rank_00_model_states.pt.
[2024-02-05 12:53:43,650] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 12:53:44,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 12:53:44,347] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1300/global_step1300/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 12:53:44,347] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1300 is ready now!
 67%|██████▋   | 1301/1950 [2:57:30<28:08:49, 156.13s/it] 67%|██████▋   | 1302/1950 [2:57:33<19:48:03, 110.01s/it] 67%|██████▋   | 1303/1950 [2:57:35<13:58:24, 77.75s/it]  67%|██████▋   | 1304/1950 [2:57:37<9:53:07, 55.09s/it]  67%|██████▋   | 1305/1950 [2:57:40<7:01:27, 39.20s/it]                                                       {'loss': 0.0004, 'learning_rate': 1.2395504136174327e-05, 'epoch': 33.04}
 67%|██████▋   | 1305/1950 [2:57:40<7:01:27, 39.20s/it][INFO|trainer.py:3242] 2024-02-05 12:53:55,958 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:53:55,958 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:53:55,959 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.99it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.19it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.30it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A                                                       
                                             [A{'eval_loss': 0.252685546875, 'eval_runtime': 3.1856, 'eval_samples_per_second': 21.974, 'eval_steps_per_second': 2.825, 'epoch': 33.04}
 67%|██████▋   | 1305/1950 [2:57:43<7:01:27, 39.20s/it]
100%|██████████| 9/9 [00:02<00:00,  2.83it/s][A
                                             [A 67%|██████▋   | 1306/1950 [2:57:45<5:12:03, 29.07s/it] 67%|██████▋   | 1307/1950 [2:57:47<3:45:31, 21.04s/it] 67%|██████▋   | 1308/1950 [2:57:50<2:45:25, 15.46s/it] 67%|██████▋   | 1309/1950 [2:57:52<2:03:05, 11.52s/it] 67%|██████▋   | 1310/1950 [2:57:54<1:33:33,  8.77s/it]                                                       {'loss': 0.0003, 'learning_rate': 1.222199987786487e-05, 'epoch': 33.16}
 67%|██████▋   | 1310/1950 [2:57:54<1:33:33,  8.77s/it][INFO|trainer.py:3242] 2024-02-05 12:54:10,806 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:54:10,806 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:54:10,806 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.94it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.55it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                       
                                             [A{'eval_loss': 0.252197265625, 'eval_runtime': 3.2015, 'eval_samples_per_second': 21.864, 'eval_steps_per_second': 2.811, 'epoch': 33.16}
 67%|██████▋   | 1310/1950 [2:57:58<1:33:33,  8.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 67%|██████▋   | 1311/1950 [2:58:00<1:23:45,  7.87s/it] 67%|██████▋   | 1312/1950 [2:58:02<1:05:46,  6.19s/it] 67%|██████▋   | 1313/1950 [2:58:05<53:29,  5.04s/it]   67%|██████▋   | 1314/1950 [2:58:07<44:45,  4.22s/it] 67%|██████▋   | 1315/1950 [2:58:10<39:09,  3.70s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.2049324765671749e-05, 'epoch': 33.29}
 67%|██████▋   | 1315/1950 [2:58:10<39:09,  3.70s/it][INFO|trainer.py:3242] 2024-02-05 12:54:25,982 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:54:25,982 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:54:25,982 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.14it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                     
                                             [A{'eval_loss': 0.25244140625, 'eval_runtime': 3.2174, 'eval_samples_per_second': 21.757, 'eval_steps_per_second': 2.797, 'epoch': 33.29}
 67%|██████▋   | 1315/1950 [2:58:13<39:09,  3.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 67%|██████▋   | 1316/1950 [2:58:15<45:03,  4.26s/it] 68%|██████▊   | 1317/1950 [2:58:17<38:46,  3.67s/it] 68%|██████▊   | 1318/1950 [2:58:20<34:28,  3.27s/it] 68%|██████▊   | 1319/1950 [2:58:22<31:58,  3.04s/it] 68%|██████▊   | 1320/1950 [2:58:25<30:35,  2.91s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.1877490004235536e-05, 'epoch': 33.42}
 68%|██████▊   | 1320/1950 [2:58:25<30:35,  2.91s/it][INFO|trainer.py:3242] 2024-02-05 12:54:41,314 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:54:41,314 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:54:41,314 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.89it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                     
                                             [A{'eval_loss': 0.252197265625, 'eval_runtime': 3.238, 'eval_samples_per_second': 21.618, 'eval_steps_per_second': 2.78, 'epoch': 33.42}
 68%|██████▊   | 1320/1950 [2:58:28<30:35,  2.91s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 68%|██████▊   | 1321/1950 [2:58:31<39:26,  3.76s/it] 68%|██████▊   | 1322/1950 [2:58:33<34:41,  3.31s/it] 68%|██████▊   | 1323/1950 [2:58:36<33:00,  3.16s/it] 68%|██████▊   | 1324/1950 [2:58:38<30:17,  2.90s/it] 68%|██████▊   | 1325/1950 [2:58:41<30:06,  2.89s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.1706506743667667e-05, 'epoch': 33.54}
 68%|██████▊   | 1325/1950 [2:58:41<30:06,  2.89s/it][INFO|trainer.py:3242] 2024-02-05 12:54:57,291 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:54:57,291 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:54:57,291 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                     
                                             [A{'eval_loss': 0.252685546875, 'eval_runtime': 3.2497, 'eval_samples_per_second': 21.54, 'eval_steps_per_second': 2.769, 'epoch': 33.54}
 68%|██████▊   | 1325/1950 [2:58:44<30:06,  2.89s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 68%|██████▊   | 1326/1950 [2:58:47<38:45,  3.73s/it] 68%|██████▊   | 1327/1950 [2:58:49<35:40,  3.44s/it] 68%|██████▊   | 1328/1950 [2:58:52<32:28,  3.13s/it] 68%|██████▊   | 1329/1950 [2:58:54<30:26,  2.94s/it] 68%|██████▊   | 1330/1950 [2:58:56<28:01,  2.71s/it]                                                     {'loss': 0.0006, 'learning_rate': 1.1536386078826884e-05, 'epoch': 33.67}
 68%|██████▊   | 1330/1950 [2:58:56<28:01,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 12:55:12,822 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:55:12,822 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:55:12,822 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.25341796875, 'eval_runtime': 3.2672, 'eval_samples_per_second': 21.425, 'eval_steps_per_second': 2.755, 'epoch': 33.67}
 68%|██████▊   | 1330/1950 [2:59:00<28:01,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 68%|██████▊   | 1331/1950 [2:59:02<37:24,  3.63s/it] 68%|██████▊   | 1332/1950 [2:59:05<33:46,  3.28s/it] 68%|██████▊   | 1333/1950 [2:59:07<31:12,  3.03s/it] 68%|██████▊   | 1334/1950 [2:59:09<29:08,  2.84s/it] 68%|██████▊   | 1335/1950 [2:59:12<27:37,  2.70s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.1367139048599335e-05, 'epoch': 33.8}
 68%|██████▊   | 1335/1950 [2:59:12<27:37,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 12:55:28,253 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:55:28,253 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:55:28,253 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.252685546875, 'eval_runtime': 3.2691, 'eval_samples_per_second': 21.413, 'eval_steps_per_second': 2.753, 'epoch': 33.8}
 68%|██████▊   | 1335/1950 [2:59:15<27:37,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 69%|██████▊   | 1336/1950 [2:59:18<38:02,  3.72s/it] 69%|██████▊   | 1337/1950 [2:59:20<33:53,  3.32s/it] 69%|██████▊   | 1338/1950 [2:59:23<30:41,  3.01s/it] 69%|██████▊   | 1339/1950 [2:59:25<29:00,  2.85s/it] 69%|██████▊   | 1340/1950 [2:59:28<28:10,  2.77s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.1198776635182273e-05, 'epoch': 33.92}
 69%|██████▊   | 1340/1950 [2:59:28<28:10,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 12:55:44,094 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:55:44,095 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:55:44,095 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25244140625, 'eval_runtime': 3.2858, 'eval_samples_per_second': 21.304, 'eval_steps_per_second': 2.739, 'epoch': 33.92}
 69%|██████▊   | 1340/1950 [2:59:31<28:10,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 69%|██████▉   | 1341/1950 [2:59:33<37:07,  3.66s/it] 69%|██████▉   | 1342/1950 [2:59:36<33:07,  3.27s/it] 69%|██████▉   | 1343/1950 [2:59:38<30:20,  3.00s/it] 69%|██████▉   | 1344/1950 [2:59:40<28:20,  2.81s/it] 69%|██████▉   | 1345/1950 [2:59:43<26:37,  2.64s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.103130976337142e-05, 'epoch': 34.05}
 69%|██████▉   | 1345/1950 [2:59:43<26:37,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 12:55:59,162 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:55:59,162 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:55:59,162 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25244140625, 'eval_runtime': 3.2866, 'eval_samples_per_second': 21.298, 'eval_steps_per_second': 2.738, 'epoch': 34.05}
 69%|██████▉   | 1345/1950 [2:59:46<26:37,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 69%|██████▉   | 1346/1950 [2:59:48<35:15,  3.50s/it] 69%|██████▉   | 1347/1950 [2:59:51<32:12,  3.20s/it] 69%|██████▉   | 1348/1950 [2:59:53<29:44,  2.96s/it] 69%|██████▉   | 1349/1950 [2:59:55<27:29,  2.74s/it] 69%|██████▉   | 1350/1950 [2:59:58<26:39,  2.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.0864749299852108e-05, 'epoch': 34.18}
 69%|██████▉   | 1350/1950 [2:59:58<26:39,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 12:56:14,308 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:56:14,308 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:56:14,308 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253173828125, 'eval_runtime': 3.2881, 'eval_samples_per_second': 21.289, 'eval_steps_per_second': 2.737, 'epoch': 34.18}
 69%|██████▉   | 1350/1950 [3:00:01<26:39,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 69%|██████▉   | 1351/1950 [3:00:04<35:52,  3.59s/it] 69%|██████▉   | 1352/1950 [3:00:06<32:07,  3.22s/it] 69%|██████▉   | 1353/1950 [3:00:08<29:38,  2.98s/it] 69%|██████▉   | 1354/1950 [3:00:11<28:10,  2.84s/it] 69%|██████▉   | 1355/1950 [3:00:13<26:54,  2.71s/it]                                                     {'loss': 0.0006, 'learning_rate': 1.0699106052494137e-05, 'epoch': 34.3}
 69%|██████▉   | 1355/1950 [3:00:13<26:54,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 12:56:29,756 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:56:29,756 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:56:29,757 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25146484375, 'eval_runtime': 3.296, 'eval_samples_per_second': 21.238, 'eval_steps_per_second': 2.731, 'epoch': 34.3}
 69%|██████▉   | 1355/1950 [3:00:17<26:54,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 70%|██████▉   | 1356/1950 [3:00:19<36:03,  3.64s/it] 70%|██████▉   | 1357/1950 [3:00:21<31:58,  3.24s/it] 70%|██████▉   | 1358/1950 [3:00:24<29:51,  3.03s/it] 70%|██████▉   | 1359/1950 [3:00:26<28:10,  2.86s/it] 70%|██████▉   | 1360/1950 [3:00:29<27:35,  2.81s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.0534390769650438e-05, 'epoch': 34.43}
 70%|██████▉   | 1360/1950 [3:00:29<27:35,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 12:56:45,543 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:56:45,544 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:56:45,544 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253173828125, 'eval_runtime': 3.2942, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 34.43}
 70%|██████▉   | 1360/1950 [3:00:32<27:35,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 70%|██████▉   | 1361/1950 [3:00:35<35:57,  3.66s/it] 70%|██████▉   | 1362/1950 [3:00:37<32:36,  3.33s/it] 70%|██████▉   | 1363/1950 [3:00:40<30:22,  3.10s/it] 70%|██████▉   | 1364/1950 [3:00:42<28:15,  2.89s/it] 70%|███████   | 1365/1950 [3:00:45<27:55,  2.86s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.0370614139459672e-05, 'epoch': 34.56}
 70%|███████   | 1365/1950 [3:00:45<27:55,  2.86s/it][INFO|trainer.py:3242] 2024-02-05 12:57:01,528 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:57:01,529 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:57:01,529 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2926, 'eval_samples_per_second': 21.26, 'eval_steps_per_second': 2.733, 'epoch': 34.56}
 70%|███████   | 1365/1950 [3:00:48<27:55,  2.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 70%|███████   | 1366/1950 [3:00:51<35:36,  3.66s/it] 70%|███████   | 1367/1950 [3:00:53<32:57,  3.39s/it] 70%|███████   | 1368/1950 [3:00:56<30:15,  3.12s/it] 70%|███████   | 1369/1950 [3:00:58<28:42,  2.96s/it] 70%|███████   | 1370/1950 [3:01:01<27:00,  2.79s/it]                                                     {'loss': 0.0008, 'learning_rate': 1.0207786789152671e-05, 'epoch': 34.68}
 70%|███████   | 1370/1950 [3:01:01<27:00,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 12:57:17,292 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:57:17,292 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:57:17,292 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25244140625, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 34.68}
 70%|███████   | 1370/1950 [3:01:04<27:00,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 70%|███████   | 1371/1950 [3:01:07<35:20,  3.66s/it] 70%|███████   | 1372/1950 [3:01:09<32:21,  3.36s/it] 70%|███████   | 1373/1950 [3:01:12<29:51,  3.10s/it] 70%|███████   | 1374/1950 [3:01:14<27:33,  2.87s/it] 71%|███████   | 1375/1950 [3:01:16<26:16,  2.74s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.0045919284362842e-05, 'epoch': 34.81}
 71%|███████   | 1375/1950 [3:01:16<26:16,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:57:32,913 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:57:32,913 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:57:32,913 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.251708984375, 'eval_runtime': 3.2907, 'eval_samples_per_second': 21.272, 'eval_steps_per_second': 2.735, 'epoch': 34.81}
 71%|███████   | 1375/1950 [3:01:20<26:16,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 71%|███████   | 1376/1950 [3:01:22<35:12,  3.68s/it] 71%|███████   | 1377/1950 [3:01:25<31:08,  3.26s/it] 71%|███████   | 1378/1950 [3:01:27<28:37,  3.00s/it] 71%|███████   | 1379/1950 [3:01:29<26:49,  2.82s/it] 71%|███████   | 1380/1950 [3:01:32<25:31,  2.69s/it]                                                     {'loss': 0.0003, 'learning_rate': 9.88502212844063e-06, 'epoch': 34.94}
 71%|███████   | 1380/1950 [3:01:32<25:31,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 12:57:48,226 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:57:48,226 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:57:48,226 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.251708984375, 'eval_runtime': 3.2945, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 34.94}
 71%|███████   | 1380/1950 [3:01:35<25:31,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 71%|███████   | 1381/1950 [3:01:38<34:10,  3.60s/it] 71%|███████   | 1382/1950 [3:01:40<31:16,  3.30s/it] 71%|███████   | 1383/1950 [3:01:42<28:19,  3.00s/it] 71%|███████   | 1384/1950 [3:01:45<26:00,  2.76s/it] 71%|███████   | 1385/1950 [3:01:47<24:39,  2.62s/it]                                                     {'loss': 0.0002, 'learning_rate': 9.725105761771896e-06, 'epoch': 35.06}
 71%|███████   | 1385/1950 [3:01:47<24:39,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 12:58:03,349 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:58:03,350 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:58:03,350 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253662109375, 'eval_runtime': 3.2922, 'eval_samples_per_second': 21.262, 'eval_steps_per_second': 2.734, 'epoch': 35.06}
 71%|███████   | 1385/1950 [3:01:50<24:39,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 71%|███████   | 1386/1950 [3:01:53<33:40,  3.58s/it] 71%|███████   | 1387/1950 [3:01:55<30:18,  3.23s/it] 71%|███████   | 1388/1950 [3:01:58<27:45,  2.96s/it] 71%|███████   | 1389/1950 [3:02:00<26:14,  2.81s/it] 71%|███████▏  | 1390/1950 [3:02:03<25:36,  2.74s/it]                                                     {'loss': 0.0003, 'learning_rate': 9.566180561100505e-06, 'epoch': 35.19}
 71%|███████▏  | 1390/1950 [3:02:03<25:36,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 12:58:18,968 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:58:18,968 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:58:18,968 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253662109375, 'eval_runtime': 3.2919, 'eval_samples_per_second': 21.264, 'eval_steps_per_second': 2.734, 'epoch': 35.19}
 71%|███████▏  | 1390/1950 [3:02:06<25:36,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 71%|███████▏  | 1391/1950 [3:02:08<34:08,  3.66s/it] 71%|███████▏  | 1392/1950 [3:02:11<30:12,  3.25s/it] 71%|███████▏  | 1393/1950 [3:02:13<27:44,  2.99s/it] 71%|███████▏  | 1394/1950 [3:02:16<26:21,  2.84s/it] 72%|███████▏  | 1395/1950 [3:02:18<25:10,  2.72s/it]                                                     {'loss': 0.0005, 'learning_rate': 9.408256838854967e-06, 'epoch': 35.32}
 72%|███████▏  | 1395/1950 [3:02:18<25:10,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 12:58:34,382 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:58:34,382 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:58:34,382 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2941, 'eval_samples_per_second': 21.25, 'eval_steps_per_second': 2.732, 'epoch': 35.32}
 72%|███████▏  | 1395/1950 [3:02:21<25:10,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 72%|███████▏  | 1396/1950 [3:02:24<33:12,  3.60s/it] 72%|███████▏  | 1397/1950 [3:02:26<29:48,  3.23s/it] 72%|███████▏  | 1398/1950 [3:02:28<27:32,  2.99s/it] 72%|███████▏  | 1399/1950 [3:02:31<26:19,  2.87s/it] 72%|███████▏  | 1400/1950 [3:02:34<25:26,  2.78s/it]                                                     {'loss': 0.0003, 'learning_rate': 9.251344842479331e-06, 'epoch': 35.44}
 72%|███████▏  | 1400/1950 [3:02:34<25:26,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 12:58:49,979 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 12:58:49,980 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 12:58:49,980 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25244140625, 'eval_runtime': 3.2857, 'eval_samples_per_second': 21.304, 'eval_steps_per_second': 2.739, 'epoch': 35.44}
 72%|███████▏  | 1400/1950 [3:02:37<25:26,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 12:59:08,852 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 12:59:08,999 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 12:59:08,999 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/special_tokens_map.json
[2024-02-05 12:59:09,960] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1400 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 12:59:24,660] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/mp_rank_00_model_states.pt
[2024-02-05 12:59:24,660] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/mp_rank_00_model_states.pt...
[2024-02-05 13:07:20,661] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/mp_rank_00_model_states.pt.
[2024-02-05 13:07:21,652] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 13:07:22,323] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 13:07:22,340] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1400/global_step1400/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 13:07:22,340] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1400 is ready now!
 72%|███████▏  | 1401/1950 [3:11:08<23:50:37, 156.35s/it] 72%|███████▏  | 1402/1950 [3:11:11<16:47:12, 110.28s/it] 72%|███████▏  | 1403/1950 [3:11:13<11:50:07, 77.89s/it]  72%|███████▏  | 1404/1950 [3:11:16<8:23:49, 55.37s/it]  72%|███████▏  | 1405/1950 [3:11:19<5:58:38, 39.48s/it]                                                       {'loss': 0.0002, 'learning_rate': 9.095454753768162e-06, 'epoch': 35.57}
 72%|███████▏  | 1405/1950 [3:11:19<5:58:38, 39.48s/it][INFO|trainer.py:3242] 2024-02-05 13:07:35,013 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:07:35,014 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:07:35,014 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.98it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.18it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.58it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.14it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.252685546875, 'eval_runtime': 3.1864, 'eval_samples_per_second': 21.968, 'eval_steps_per_second': 2.824, 'epoch': 35.57}
 72%|███████▏  | 1405/1950 [3:11:22<5:58:38, 39.48s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 72%|███████▏  | 1406/1950 [3:11:24<4:26:31, 29.40s/it] 72%|███████▏  | 1407/1950 [3:11:27<3:12:30, 21.27s/it] 72%|███████▏  | 1408/1950 [3:11:29<2:21:17, 15.64s/it] 72%|███████▏  | 1409/1950 [3:11:32<1:44:54, 11.64s/it] 72%|███████▏  | 1410/1950 [3:11:34<1:19:46,  8.86s/it]                                                       {'loss': 0.0005, 'learning_rate': 8.94059668820591e-06, 'epoch': 35.7}
 72%|███████▏  | 1410/1950 [3:11:34<1:19:46,  8.86s/it][INFO|trainer.py:3242] 2024-02-05 13:07:50,361 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:07:50,362 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:07:50,362 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.97it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                       
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.1999, 'eval_samples_per_second': 21.876, 'eval_steps_per_second': 2.813, 'epoch': 35.7}
 72%|███████▏  | 1410/1950 [3:11:37<1:19:46,  8.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 72%|███████▏  | 1411/1950 [3:11:40<1:10:45,  7.88s/it] 72%|███████▏  | 1412/1950 [3:11:42<55:56,  6.24s/it]   72%|███████▏  | 1413/1950 [3:11:44<45:13,  5.05s/it] 73%|███████▎  | 1414/1950 [3:11:46<37:36,  4.21s/it] 73%|███████▎  | 1415/1950 [3:11:49<34:01,  3.82s/it]                                                     {'loss': 0.0003, 'learning_rate': 8.786780694310551e-06, 'epoch': 35.82}
 73%|███████▎  | 1415/1950 [3:11:49<34:01,  3.82s/it][INFO|trainer.py:3242] 2024-02-05 13:08:05,777 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:08:05,777 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:08:05,777 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                     
                                             [A{'eval_loss': 0.252685546875, 'eval_runtime': 3.2173, 'eval_samples_per_second': 21.757, 'eval_steps_per_second': 2.797, 'epoch': 35.82}
 73%|███████▎  | 1415/1950 [3:11:53<34:01,  3.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 73%|███████▎  | 1416/1950 [3:11:55<38:21,  4.31s/it] 73%|███████▎  | 1417/1950 [3:11:57<32:39,  3.68s/it] 73%|███████▎  | 1418/1950 [3:11:59<28:43,  3.24s/it] 73%|███████▎  | 1419/1950 [3:12:02<26:31,  3.00s/it] 73%|███████▎  | 1420/1950 [3:12:04<25:00,  2.83s/it]                                                     {'loss': 0.0004, 'learning_rate': 8.634016752981486e-06, 'epoch': 35.95}
 73%|███████▎  | 1420/1950 [3:12:04<25:00,  2.83s/it][INFO|trainer.py:3242] 2024-02-05 13:08:20,535 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:08:20,535 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:08:20,535 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                     
                                             [A{'eval_loss': 0.253173828125, 'eval_runtime': 3.2377, 'eval_samples_per_second': 21.62, 'eval_steps_per_second': 2.78, 'epoch': 35.95}
 73%|███████▎  | 1420/1950 [3:12:07<25:00,  2.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 73%|███████▎  | 1421/1950 [3:12:10<32:25,  3.68s/it] 73%|███████▎  | 1422/1950 [3:12:12<29:04,  3.30s/it] 73%|███████▎  | 1423/1950 [3:12:14<26:14,  2.99s/it] 73%|███████▎  | 1424/1950 [3:12:17<24:19,  2.77s/it] 73%|███████▎  | 1425/1950 [3:12:19<22:42,  2.60s/it]                                                     {'loss': 0.0002, 'learning_rate': 8.482314776851946e-06, 'epoch': 36.08}
 73%|███████▎  | 1425/1950 [3:12:19<22:42,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 13:08:35,325 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:08:35,325 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:08:35,325 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2496, 'eval_samples_per_second': 21.541, 'eval_steps_per_second': 2.77, 'epoch': 36.08}
 73%|███████▎  | 1425/1950 [3:12:22<22:42,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.78it/s][A
                                             [A 73%|███████▎  | 1426/1950 [3:12:25<31:03,  3.56s/it] 73%|███████▎  | 1427/1950 [3:12:27<27:58,  3.21s/it] 73%|███████▎  | 1428/1950 [3:12:29<25:21,  2.91s/it] 73%|███████▎  | 1429/1950 [3:12:32<24:13,  2.79s/it] 73%|███████▎  | 1430/1950 [3:12:34<23:15,  2.68s/it]                                                     {'loss': 0.0003, 'learning_rate': 8.331684609645779e-06, 'epoch': 36.2}
 73%|███████▎  | 1430/1950 [3:12:34<23:15,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 13:08:50,687 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:08:50,688 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:08:50,688 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2579, 'eval_samples_per_second': 21.486, 'eval_steps_per_second': 2.763, 'epoch': 36.2}
 73%|███████▎  | 1430/1950 [3:12:38<23:15,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 73%|███████▎  | 1431/1950 [3:12:40<30:20,  3.51s/it] 73%|███████▎  | 1432/1950 [3:12:42<27:16,  3.16s/it] 73%|███████▎  | 1433/1950 [3:12:45<25:25,  2.95s/it] 74%|███████▎  | 1434/1950 [3:12:47<24:48,  2.89s/it] 74%|███████▎  | 1435/1950 [3:12:50<23:59,  2.79s/it]                                                     {'loss': 0.0003, 'learning_rate': 8.182136025538668e-06, 'epoch': 36.33}
 74%|███████▎  | 1435/1950 [3:12:50<23:59,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 13:09:06,242 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:09:06,242 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:09:06,242 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.04it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  3.86it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.36it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.15it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.253173828125, 'eval_runtime': 3.3184, 'eval_samples_per_second': 21.094, 'eval_steps_per_second': 2.712, 'epoch': 36.33}
 74%|███████▎  | 1435/1950 [3:12:53<23:59,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 74%|███████▎  | 1436/1950 [3:12:56<31:31,  3.68s/it] 74%|███████▎  | 1437/1950 [3:12:58<28:35,  3.34s/it] 74%|███████▎  | 1438/1950 [3:13:01<26:05,  3.06s/it] 74%|███████▍  | 1439/1950 [3:13:03<25:02,  2.94s/it] 74%|███████▍  | 1440/1950 [3:13:06<23:39,  2.78s/it]                                                     {'loss': 0.0003, 'learning_rate': 8.03367872852392e-06, 'epoch': 36.46}
 74%|███████▍  | 1440/1950 [3:13:06<23:39,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 13:09:22,021 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:09:22,022 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:09:22,022 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.2529296875, 'eval_runtime': 3.2802, 'eval_samples_per_second': 21.34, 'eval_steps_per_second': 2.744, 'epoch': 36.46}
 74%|███████▍  | 1440/1950 [3:13:09<23:39,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 74%|███████▍  | 1441/1950 [3:13:11<31:11,  3.68s/it] 74%|███████▍  | 1442/1950 [3:13:14<28:31,  3.37s/it] 74%|███████▍  | 1443/1950 [3:13:16<26:03,  3.08s/it] 74%|███████▍  | 1444/1950 [3:13:19<25:23,  3.01s/it] 74%|███████▍  | 1445/1950 [3:13:21<23:18,  2.77s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.886322351782783e-06, 'epoch': 36.58}
 74%|███████▍  | 1445/1950 [3:13:21<23:18,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 13:09:37,897 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:09:37,897 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:09:37,897 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2872, 'eval_samples_per_second': 21.295, 'eval_steps_per_second': 2.738, 'epoch': 36.58}
 74%|███████▍  | 1445/1950 [3:13:25<23:18,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 74%|███████▍  | 1446/1950 [3:13:28<31:31,  3.75s/it] 74%|███████▍  | 1447/1950 [3:13:30<28:13,  3.37s/it] 74%|███████▍  | 1448/1950 [3:13:33<26:16,  3.14s/it] 74%|███████▍  | 1449/1950 [3:13:35<24:11,  2.90s/it] 74%|███████▍  | 1450/1950 [3:13:37<22:47,  2.73s/it]                                                     {'loss': 0.0005, 'learning_rate': 7.740076457059392e-06, 'epoch': 36.71}
 74%|███████▍  | 1450/1950 [3:13:37<22:47,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 13:09:53,711 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:09:53,711 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:09:53,711 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2925, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 36.71}
 74%|███████▍  | 1450/1950 [3:13:41<22:47,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 74%|███████▍  | 1451/1950 [3:13:43<30:17,  3.64s/it] 74%|███████▍  | 1452/1950 [3:13:46<27:26,  3.31s/it] 75%|███████▍  | 1453/1950 [3:13:48<25:01,  3.02s/it] 75%|███████▍  | 1454/1950 [3:13:50<23:40,  2.86s/it] 75%|███████▍  | 1455/1950 [3:13:53<22:44,  2.76s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.594950534040268e-06, 'epoch': 36.84}
 75%|███████▍  | 1455/1950 [3:13:53<22:44,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 13:10:09,354 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:10:09,354 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:10:09,354 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2962, 'eval_samples_per_second': 21.237, 'eval_steps_per_second': 2.73, 'epoch': 36.84}
 75%|███████▍  | 1455/1950 [3:13:56<22:44,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 75%|███████▍  | 1456/1950 [3:13:59<29:40,  3.60s/it] 75%|███████▍  | 1457/1950 [3:14:01<26:42,  3.25s/it] 75%|███████▍  | 1458/1950 [3:14:03<24:12,  2.95s/it] 75%|███████▍  | 1459/1950 [3:14:06<22:37,  2.77s/it] 75%|███████▍  | 1460/1950 [3:14:08<21:35,  2.64s/it]                                                     {'loss': 0.0003, 'learning_rate': 7.450953999738583e-06, 'epoch': 36.96}
 75%|███████▍  | 1460/1950 [3:14:08<21:35,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 13:10:24,310 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:10:24,310 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:10:24,310 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253662109375, 'eval_runtime': 3.2976, 'eval_samples_per_second': 21.228, 'eval_steps_per_second': 2.729, 'epoch': 36.96}
 75%|███████▍  | 1460/1950 [3:14:11<21:35,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 75%|███████▍  | 1461/1950 [3:14:14<29:20,  3.60s/it] 75%|███████▍  | 1462/1950 [3:14:16<26:03,  3.20s/it] 75%|███████▌  | 1463/1950 [3:14:18<23:33,  2.90s/it] 75%|███████▌  | 1464/1950 [3:14:21<22:04,  2.73s/it] 75%|███████▌  | 1465/1950 [3:14:23<21:07,  2.61s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.308096197883094e-06, 'epoch': 37.09}
 75%|███████▌  | 1465/1950 [3:14:23<21:07,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 13:10:39,284 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:10:39,284 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:10:39,284 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253662109375, 'eval_runtime': 3.2952, 'eval_samples_per_second': 21.243, 'eval_steps_per_second': 2.731, 'epoch': 37.09}
 75%|███████▌  | 1465/1950 [3:14:26<21:07,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 75%|███████▌  | 1466/1950 [3:14:29<28:39,  3.55s/it] 75%|███████▌  | 1467/1950 [3:14:31<25:44,  3.20s/it] 75%|███████▌  | 1468/1950 [3:14:33<23:51,  2.97s/it] 75%|███████▌  | 1469/1950 [3:14:36<22:52,  2.85s/it] 75%|███████▌  | 1470/1950 [3:14:38<21:24,  2.68s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.166386398311828e-06, 'epoch': 37.22}
 75%|███████▌  | 1470/1950 [3:14:38<21:24,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 13:10:54,681 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:10:54,681 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:10:54,681 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25390625, 'eval_runtime': 3.2949, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 37.22}
 75%|███████▌  | 1470/1950 [3:14:42<21:24,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 75%|███████▌  | 1471/1950 [3:14:44<28:25,  3.56s/it] 75%|███████▌  | 1472/1950 [3:14:46<25:43,  3.23s/it] 76%|███████▌  | 1473/1950 [3:14:49<23:57,  3.01s/it] 76%|███████▌  | 1474/1950 [3:14:51<22:34,  2.85s/it] 76%|███████▌  | 1475/1950 [3:14:54<21:28,  2.71s/it]                                                     {'loss': 0.0003, 'learning_rate': 7.025833796370615e-06, 'epoch': 37.34}
 76%|███████▌  | 1475/1950 [3:14:54<21:28,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 13:11:10,129 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:11:10,129 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:11:10,129 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2915, 'eval_samples_per_second': 21.267, 'eval_steps_per_second': 2.734, 'epoch': 37.34}
 76%|███████▌  | 1475/1950 [3:14:57<21:28,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 76%|███████▌  | 1476/1950 [3:14:59<28:36,  3.62s/it] 76%|███████▌  | 1477/1950 [3:15:02<25:54,  3.29s/it] 76%|███████▌  | 1478/1950 [3:15:05<24:10,  3.07s/it] 76%|███████▌  | 1479/1950 [3:15:07<22:53,  2.92s/it] 76%|███████▌  | 1480/1950 [3:15:09<21:20,  2.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 6.886447512316377e-06, 'epoch': 37.47}
 76%|███████▌  | 1480/1950 [3:15:09<21:20,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 13:11:25,774 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:11:25,774 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:11:25,775 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.253662109375, 'eval_runtime': 3.2918, 'eval_samples_per_second': 21.265, 'eval_steps_per_second': 2.734, 'epoch': 37.47}
 76%|███████▌  | 1480/1950 [3:15:13<21:20,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 76%|███████▌  | 1481/1950 [3:15:15<29:04,  3.72s/it] 76%|███████▌  | 1482/1950 [3:15:18<25:40,  3.29s/it] 76%|███████▌  | 1483/1950 [3:15:21<24:42,  3.17s/it] 76%|███████▌  | 1484/1950 [3:15:23<23:00,  2.96s/it] 76%|███████▌  | 1485/1950 [3:15:26<22:28,  2.90s/it]                                                     {'loss': 0.0002, 'learning_rate': 6.748236590725335e-06, 'epoch': 37.59}
 76%|███████▌  | 1485/1950 [3:15:26<22:28,  2.90s/it][INFO|trainer.py:3242] 2024-02-05 13:11:42,230 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:11:42,230 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:11:42,230 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25390625, 'eval_runtime': 3.2944, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 37.59}
 76%|███████▌  | 1485/1950 [3:15:29<22:28,  2.90s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 76%|███████▌  | 1486/1950 [3:15:31<28:44,  3.72s/it] 76%|███████▋  | 1487/1950 [3:15:34<26:14,  3.40s/it] 76%|███████▋  | 1488/1950 [3:15:36<23:37,  3.07s/it] 76%|███████▋  | 1489/1950 [3:15:39<22:15,  2.90s/it] 76%|███████▋  | 1490/1950 [3:15:41<21:02,  2.74s/it]                                                     {'loss': 0.0005, 'learning_rate': 6.6112099999061235e-06, 'epoch': 37.72}
 76%|███████▋  | 1490/1950 [3:15:41<21:02,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 13:11:57,694 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:11:57,694 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:11:57,694 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25390625, 'eval_runtime': 3.2932, 'eval_samples_per_second': 21.256, 'eval_steps_per_second': 2.733, 'epoch': 37.72}
 76%|███████▋  | 1490/1950 [3:15:45<21:02,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 76%|███████▋  | 1491/1950 [3:15:47<27:47,  3.63s/it] 77%|███████▋  | 1492/1950 [3:15:49<24:59,  3.27s/it] 77%|███████▋  | 1493/1950 [3:15:52<22:48,  3.00s/it] 77%|███████▋  | 1494/1950 [3:15:55<22:12,  2.92s/it] 77%|███████▋  | 1495/1950 [3:15:57<20:50,  2.75s/it]                                                     {'loss': 0.0002, 'learning_rate': 6.475376631317856e-06, 'epoch': 37.85}
 77%|███████▋  | 1495/1950 [3:15:57<20:50,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 13:12:13,278 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:12:13,278 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:12:13,279 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2944, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 37.85}
 77%|███████▋  | 1495/1950 [3:16:00<20:50,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 77%|███████▋  | 1496/1950 [3:16:02<27:16,  3.61s/it] 77%|███████▋  | 1497/1950 [3:16:05<24:08,  3.20s/it] 77%|███████▋  | 1498/1950 [3:16:07<22:32,  2.99s/it] 77%|███████▋  | 1499/1950 [3:16:10<21:01,  2.80s/it] 77%|███████▋  | 1500/1950 [3:16:12<19:55,  2.66s/it]                                                     {'loss': 0.0003, 'learning_rate': 6.340745298993156e-06, 'epoch': 37.97}
 77%|███████▋  | 1500/1950 [3:16:12<19:55,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 13:12:28,317 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:12:28,318 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:12:28,318 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2927, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 37.97}
 77%|███████▋  | 1500/1950 [3:16:15<19:55,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 13:12:46,339 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 13:12:46,480 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 13:12:46,481 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/special_tokens_map.json
[2024-02-05 13:12:47,557] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 13:13:01,403] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/mp_rank_00_model_states.pt
[2024-02-05 13:13:01,403] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/mp_rank_00_model_states.pt...
[2024-02-05 13:20:59,040] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/mp_rank_00_model_states.pt.
[2024-02-05 13:20:59,982] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 13:21:00,669] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 13:21:00,673] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 13:21:00,673] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 77%|███████▋  | 1501/1950 [3:24:47<19:29:18, 156.25s/it] 77%|███████▋  | 1502/1950 [3:24:49<13:41:39, 110.04s/it] 77%|███████▋  | 1503/1950 [3:24:51<9:38:44, 77.68s/it]   77%|███████▋  | 1504/1950 [3:24:53<6:49:04, 55.03s/it] 77%|███████▋  | 1505/1950 [3:24:56<4:51:16, 39.27s/it]                                                       {'loss': 0.0002, 'learning_rate': 6.207324738966255e-06, 'epoch': 38.1}
 77%|███████▋  | 1505/1950 [3:24:56<4:51:16, 39.27s/it][INFO|trainer.py:3242] 2024-02-05 13:21:12,050 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:21:12,051 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:21:12,051 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.99it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.84it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.1823, 'eval_samples_per_second': 21.997, 'eval_steps_per_second': 2.828, 'epoch': 38.1}
 77%|███████▋  | 1505/1950 [3:24:59<4:51:16, 39.27s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 77%|███████▋  | 1506/1950 [3:25:01<3:35:46, 29.16s/it] 77%|███████▋  | 1507/1950 [3:25:03<2:35:40, 21.09s/it] 77%|███████▋  | 1508/1950 [3:25:06<1:54:18, 15.52s/it] 77%|███████▋  | 1509/1950 [3:25:08<1:25:09, 11.59s/it] 77%|███████▋  | 1510/1950 [3:25:11<1:04:30,  8.80s/it]                                                       {'loss': 0.0002, 'learning_rate': 6.075123608706093e-06, 'epoch': 38.23}
 77%|███████▋  | 1510/1950 [3:25:11<1:04:30,  8.80s/it][INFO|trainer.py:3242] 2024-02-05 13:21:27,073 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:21:27,073 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:21:27,074 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.16it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.11it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                       
                                             [A{'eval_loss': 0.25390625, 'eval_runtime': 3.1985, 'eval_samples_per_second': 21.885, 'eval_steps_per_second': 2.814, 'epoch': 38.23}
 77%|███████▋  | 1510/1950 [3:25:14<1:04:30,  8.80s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 77%|███████▋  | 1511/1950 [3:25:16<57:17,  7.83s/it]   78%|███████▊  | 1512/1950 [3:25:19<45:26,  6.22s/it] 78%|███████▊  | 1513/1950 [3:25:21<37:16,  5.12s/it] 78%|███████▊  | 1514/1950 [3:25:24<31:24,  4.32s/it] 78%|███████▊  | 1515/1950 [3:25:26<27:05,  3.74s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.944150486554556e-06, 'epoch': 38.35}
 78%|███████▊  | 1515/1950 [3:25:26<27:05,  3.74s/it][INFO|trainer.py:3242] 2024-02-05 13:21:42,496 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:21:42,496 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:21:42,497 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.10it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2166, 'eval_samples_per_second': 21.762, 'eval_steps_per_second': 2.798, 'epoch': 38.35}
 78%|███████▊  | 1515/1950 [3:25:29<27:05,  3.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.81it/s][A
                                             [A 78%|███████▊  | 1516/1950 [3:25:32<31:49,  4.40s/it] 78%|███████▊  | 1517/1950 [3:25:35<27:36,  3.83s/it] 78%|███████▊  | 1518/1950 [3:25:37<24:50,  3.45s/it] 78%|███████▊  | 1519/1950 [3:25:40<22:53,  3.19s/it] 78%|███████▊  | 1520/1950 [3:25:42<21:10,  2.96s/it]                                                     {'loss': 0.0003, 'learning_rate': 5.8144138711698434e-06, 'epoch': 38.48}
 78%|███████▊  | 1520/1950 [3:25:42<21:10,  2.96s/it][INFO|trainer.py:3242] 2024-02-05 13:21:58,493 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:21:58,494 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:21:58,494 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2325, 'eval_samples_per_second': 21.655, 'eval_steps_per_second': 2.784, 'epoch': 38.48}
 78%|███████▊  | 1520/1950 [3:25:45<21:10,  2.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 78%|███████▊  | 1521/1950 [3:25:48<27:18,  3.82s/it] 78%|███████▊  | 1522/1950 [3:25:50<24:10,  3.39s/it] 78%|███████▊  | 1523/1950 [3:25:53<22:55,  3.22s/it] 78%|███████▊  | 1524/1950 [3:25:55<20:38,  2.91s/it] 78%|███████▊  | 1525/1950 [3:25:58<20:13,  2.85s/it]                                                     {'loss': 0.0004, 'learning_rate': 5.685922180975023e-06, 'epoch': 38.61}
 78%|███████▊  | 1525/1950 [3:25:58<20:13,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 13:22:14,450 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:22:14,450 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:22:14,450 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.10it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.51it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.24it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.06it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.96it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2534, 'eval_samples_per_second': 21.516, 'eval_steps_per_second': 2.766, 'epoch': 38.61}
 78%|███████▊  | 1525/1950 [3:26:01<20:13,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 78%|███████▊  | 1526/1950 [3:26:04<26:05,  3.69s/it] 78%|███████▊  | 1527/1950 [3:26:06<23:34,  3.34s/it] 78%|███████▊  | 1528/1950 [3:26:09<21:19,  3.03s/it] 78%|███████▊  | 1529/1950 [3:26:11<19:49,  2.83s/it] 78%|███████▊  | 1530/1950 [3:26:13<19:04,  2.73s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.558683753611727e-06, 'epoch': 38.73}
 78%|███████▊  | 1530/1950 [3:26:13<19:04,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 13:22:29,770 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:22:29,770 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:22:29,770 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.86it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.09it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2616, 'eval_samples_per_second': 21.462, 'eval_steps_per_second': 2.759, 'epoch': 38.73}
 78%|███████▊  | 1530/1950 [3:26:17<19:04,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 79%|███████▊  | 1531/1950 [3:26:19<25:17,  3.62s/it] 79%|███████▊  | 1532/1950 [3:26:22<22:46,  3.27s/it] 79%|███████▊  | 1533/1950 [3:26:24<20:57,  3.02s/it] 79%|███████▊  | 1534/1950 [3:26:27<19:59,  2.88s/it] 79%|███████▊  | 1535/1950 [3:26:29<18:45,  2.71s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.432706845399161e-06, 'epoch': 38.86}
 79%|███████▊  | 1535/1950 [3:26:29<18:45,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 13:22:45,240 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:22:45,240 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:22:45,240 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2709, 'eval_samples_per_second': 21.401, 'eval_steps_per_second': 2.752, 'epoch': 38.86}
 79%|███████▊  | 1535/1950 [3:26:32<18:45,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 79%|███████▉  | 1536/1950 [3:26:34<24:44,  3.59s/it] 79%|███████▉  | 1537/1950 [3:26:37<21:54,  3.18s/it] 79%|███████▉  | 1538/1950 [3:26:39<20:08,  2.93s/it] 79%|███████▉  | 1539/1950 [3:26:41<18:50,  2.75s/it] 79%|███████▉  | 1540/1950 [3:26:44<18:14,  2.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 5.30799963079838e-06, 'epoch': 38.99}
 79%|███████▉  | 1540/1950 [3:26:44<18:14,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 13:23:00,264 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:23:00,264 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:23:00,264 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.83it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2806, 'eval_samples_per_second': 21.338, 'eval_steps_per_second': 2.743, 'epoch': 38.99}
 79%|███████▉  | 1540/1950 [3:26:47<18:14,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 79%|███████▉  | 1541/1950 [3:26:49<24:06,  3.54s/it] 79%|███████▉  | 1542/1950 [3:26:52<21:18,  3.13s/it] 79%|███████▉  | 1543/1950 [3:26:54<19:29,  2.87s/it] 79%|███████▉  | 1544/1950 [3:26:56<18:22,  2.71s/it] 79%|███████▉  | 1545/1950 [3:26:59<17:46,  2.63s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.184570201881819e-06, 'epoch': 39.11}
 79%|███████▉  | 1545/1950 [3:26:59<17:46,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 13:23:15,072 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:23:15,072 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:23:15,072 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2913, 'eval_samples_per_second': 21.268, 'eval_steps_per_second': 2.734, 'epoch': 39.11}
 79%|███████▉  | 1545/1950 [3:27:02<17:46,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 79%|███████▉  | 1546/1950 [3:27:04<23:48,  3.54s/it] 79%|███████▉  | 1547/1950 [3:27:07<21:27,  3.20s/it] 79%|███████▉  | 1548/1950 [3:27:09<20:12,  3.02s/it] 79%|███████▉  | 1549/1950 [3:27:11<18:29,  2.77s/it] 79%|███████▉  | 1550/1950 [3:27:14<17:32,  2.63s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.0624265678082375e-06, 'epoch': 39.24}
 79%|███████▉  | 1550/1950 [3:27:14<17:32,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 13:23:30,210 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:23:30,210 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:23:30,210 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2548828125, 'eval_runtime': 3.2956, 'eval_samples_per_second': 21.241, 'eval_steps_per_second': 2.731, 'epoch': 39.24}
 79%|███████▉  | 1550/1950 [3:27:17<17:32,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 80%|███████▉  | 1551/1950 [3:27:19<23:33,  3.54s/it] 80%|███████▉  | 1552/1950 [3:27:22<21:27,  3.24s/it] 80%|███████▉  | 1553/1950 [3:27:24<19:43,  2.98s/it] 80%|███████▉  | 1554/1950 [3:27:27<18:26,  2.79s/it] 80%|███████▉  | 1555/1950 [3:27:29<17:44,  2.70s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.941576654303018e-06, 'epoch': 39.37}
 80%|███████▉  | 1555/1950 [3:27:29<17:44,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 13:23:45,610 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:23:45,610 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:23:45,610 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.2548828125, 'eval_runtime': 3.2937, 'eval_samples_per_second': 21.253, 'eval_steps_per_second': 2.732, 'epoch': 39.37}
 80%|███████▉  | 1555/1950 [3:27:32<17:44,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 80%|███████▉  | 1556/1950 [3:27:35<23:47,  3.62s/it] 80%|███████▉  | 1557/1950 [3:27:38<21:46,  3.32s/it] 80%|███████▉  | 1558/1950 [3:27:40<20:09,  3.09s/it] 80%|███████▉  | 1559/1950 [3:27:42<18:25,  2.83s/it] 80%|████████  | 1560/1950 [3:27:45<18:28,  2.84s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.822028303143863e-06, 'epoch': 39.49}
 80%|████████  | 1560/1950 [3:27:45<18:28,  2.84s/it][INFO|trainer.py:3242] 2024-02-05 13:24:01,654 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:24:01,654 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:24:01,654 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.254638671875, 'eval_runtime': 3.2913, 'eval_samples_per_second': 21.268, 'eval_steps_per_second': 2.734, 'epoch': 39.49}
 80%|████████  | 1560/1950 [3:27:49<18:28,  2.84s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 80%|████████  | 1561/1950 [3:27:51<23:46,  3.67s/it] 80%|████████  | 1562/1950 [3:27:54<22:22,  3.46s/it] 80%|████████  | 1563/1950 [3:27:56<20:22,  3.16s/it] 80%|████████  | 1564/1950 [3:27:59<19:29,  3.03s/it] 80%|████████  | 1565/1950 [3:28:01<18:03,  2.81s/it]                                                     {'loss': 0.0004, 'learning_rate': 4.7037892716519565e-06, 'epoch': 39.62}
 80%|████████  | 1565/1950 [3:28:01<18:03,  2.81s/it][INFO|trainer.py:3242] 2024-02-05 13:24:17,724 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:24:17,724 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:24:17,724 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.254638671875, 'eval_runtime': 3.297, 'eval_samples_per_second': 21.232, 'eval_steps_per_second': 2.73, 'epoch': 39.62}
 80%|████████  | 1565/1950 [3:28:05<18:03,  2.81s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 80%|████████  | 1566/1950 [3:28:07<23:50,  3.73s/it] 80%|████████  | 1567/1950 [3:28:09<20:49,  3.26s/it] 80%|████████  | 1568/1950 [3:28:12<19:13,  3.02s/it] 80%|████████  | 1569/1950 [3:28:14<17:58,  2.83s/it] 81%|████████  | 1570/1950 [3:28:17<17:07,  2.70s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.586867232188602e-06, 'epoch': 39.75}
 81%|████████  | 1570/1950 [3:28:17<17:07,  2.70s/it][INFO|trainer.py:3242] 2024-02-05 13:24:33,003 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:24:33,003 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:24:33,003 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.254638671875, 'eval_runtime': 3.2934, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 39.75}
 81%|████████  | 1570/1950 [3:28:20<17:07,  2.70s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 81%|████████  | 1571/1950 [3:28:22<22:36,  3.58s/it] 81%|████████  | 1572/1950 [3:28:25<20:10,  3.20s/it] 81%|████████  | 1573/1950 [3:28:27<19:13,  3.06s/it] 81%|████████  | 1574/1950 [3:28:30<17:44,  2.83s/it] 81%|████████  | 1575/1950 [3:28:32<16:34,  2.65s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.4712697716574e-06, 'epoch': 39.87}
 81%|████████  | 1575/1950 [3:28:32<16:34,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 13:24:48,210 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:24:48,210 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:24:48,211 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2934, 'eval_samples_per_second': 21.255, 'eval_steps_per_second': 2.733, 'epoch': 39.87}
 81%|████████  | 1575/1950 [3:28:35<16:34,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 81%|████████  | 1576/1950 [3:28:37<22:01,  3.53s/it] 81%|████████  | 1577/1950 [3:28:40<20:42,  3.33s/it] 81%|████████  | 1578/1950 [3:28:43<18:43,  3.02s/it] 81%|████████  | 1579/1950 [3:28:45<17:32,  2.84s/it] 81%|████████  | 1580/1950 [3:28:47<16:30,  2.68s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.357004391011899e-06, 'epoch': 40.0}
 81%|████████  | 1580/1950 [3:28:47<16:30,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 13:25:03,663 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:25:03,663 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:25:03,663 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.254638671875, 'eval_runtime': 3.2888, 'eval_samples_per_second': 21.284, 'eval_steps_per_second': 2.737, 'epoch': 40.0}
 81%|████████  | 1580/1950 [3:28:51<16:30,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 81%|████████  | 1581/1950 [3:28:53<21:51,  3.55s/it] 81%|████████  | 1582/1950 [3:28:55<19:28,  3.17s/it] 81%|████████  | 1583/1950 [3:28:57<17:44,  2.90s/it] 81%|████████  | 1584/1950 [3:29:00<17:17,  2.83s/it] 81%|████████▏ | 1585/1950 [3:29:02<16:29,  2.71s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.244078504768897e-06, 'epoch': 40.13}
 81%|████████▏ | 1585/1950 [3:29:02<16:29,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 13:25:18,917 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:25:18,917 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:25:18,918 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2889, 'eval_samples_per_second': 21.284, 'eval_steps_per_second': 2.736, 'epoch': 40.13}
 81%|████████▏ | 1585/1950 [3:29:06<16:29,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 81%|████████▏ | 1586/1950 [3:29:08<21:34,  3.56s/it] 81%|████████▏ | 1587/1950 [3:29:11<19:34,  3.23s/it] 81%|████████▏ | 1588/1950 [3:29:13<18:11,  3.01s/it] 81%|████████▏ | 1589/1950 [3:29:15<16:44,  2.78s/it] 82%|████████▏ | 1590/1950 [3:29:18<15:55,  2.66s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.132499440527329e-06, 'epoch': 40.25}
 82%|████████▏ | 1590/1950 [3:29:18<15:55,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 13:25:34,030 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:25:34,030 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:25:34,030 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2949, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 40.25}
 82%|████████▏ | 1590/1950 [3:29:21<15:55,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 82%|████████▏ | 1591/1950 [3:29:23<21:32,  3.60s/it] 82%|████████▏ | 1592/1950 [3:29:26<19:21,  3.24s/it] 82%|████████▏ | 1593/1950 [3:29:28<17:51,  3.00s/it] 82%|████████▏ | 1594/1950 [3:29:31<16:45,  2.82s/it] 82%|████████▏ | 1595/1950 [3:29:33<16:19,  2.76s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.022274438492765e-06, 'epoch': 40.38}
 82%|████████▏ | 1595/1950 [3:29:33<16:19,  2.76s/it][INFO|trainer.py:3242] 2024-02-05 13:25:49,701 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:25:49,701 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:25:49,701 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2928, 'eval_samples_per_second': 21.259, 'eval_steps_per_second': 2.733, 'epoch': 40.38}
 82%|████████▏ | 1595/1950 [3:29:37<16:19,  2.76s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 82%|████████▏ | 1596/1950 [3:29:39<21:38,  3.67s/it] 82%|████████▏ | 1597/1950 [3:29:42<19:40,  3.34s/it] 82%|████████▏ | 1598/1950 [3:29:44<17:59,  3.07s/it] 82%|████████▏ | 1599/1950 [3:29:47<16:57,  2.90s/it] 82%|████████▏ | 1600/1950 [3:29:49<16:37,  2.85s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.913410651007637e-06, 'epoch': 40.51}
 82%|████████▏ | 1600/1950 [3:29:49<16:37,  2.85s/it][INFO|trainer.py:3242] 2024-02-05 13:26:05,736 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:26:05,736 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:26:05,736 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2919, 'eval_samples_per_second': 21.264, 'eval_steps_per_second': 2.734, 'epoch': 40.51}
 82%|████████▏ | 1600/1950 [3:29:53<16:37,  2.85s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 13:26:23,413 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 13:26:23,554 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 13:26:23,555 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/special_tokens_map.json
[2024-02-05 13:26:24,674] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1600 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 13:26:38,641] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/mp_rank_00_model_states.pt
[2024-02-05 13:26:38,641] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/mp_rank_00_model_states.pt...
[2024-02-05 13:34:34,446] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/mp_rank_00_model_states.pt.
[2024-02-05 13:34:35,399] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 13:34:36,088] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 13:34:36,092] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1600/global_step1600/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 13:34:36,092] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1600 is ready now!
 82%|████████▏ | 1601/1950 [3:38:22<15:06:32, 155.85s/it] 82%|████████▏ | 1602/1950 [3:38:25<10:37:40, 109.95s/it] 82%|████████▏ | 1603/1950 [3:38:27<7:28:57, 77.63s/it]   82%|████████▏ | 1604/1950 [3:38:30<5:18:04, 55.16s/it] 82%|████████▏ | 1605/1950 [3:38:32<3:46:13, 39.34s/it]                                                       {'loss': 0.0004, 'learning_rate': 3.8059151420871105e-06, 'epoch': 40.63}
 82%|████████▏ | 1605/1950 [3:38:32<3:46:13, 39.34s/it][INFO|trainer.py:3242] 2024-02-05 13:34:48,823 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:34:48,823 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:34:48,823 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  6.00it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.20it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.59it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.31it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.13it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.02it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.85it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A                                                       
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.1792, 'eval_samples_per_second': 22.018, 'eval_steps_per_second': 2.831, 'epoch': 40.63}
 82%|████████▏ | 1605/1950 [3:38:36<3:46:13, 39.34s/it]
100%|██████████| 9/9 [00:02<00:00,  2.84it/s][A
                                             [A 82%|████████▏ | 1606/1950 [3:38:38<2:47:35, 29.23s/it] 82%|████████▏ | 1607/1950 [3:38:40<2:00:52, 21.14s/it] 82%|████████▏ | 1608/1950 [3:38:43<1:28:13, 15.48s/it] 83%|████████▎ | 1609/1950 [3:38:45<1:05:37, 11.55s/it] 83%|████████▎ | 1610/1950 [3:38:47<49:48,  8.79s/it]                                                       {'loss': 0.0003, 'learning_rate': 3.6997948869607056e-06, 'epoch': 40.76}
 83%|████████▎ | 1610/1950 [3:38:47<49:48,  8.79s/it][INFO|trainer.py:3242] 2024-02-05 13:35:03,709 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:35:03,709 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:35:03,709 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.95it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.57it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.12it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  3.00it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.82it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A                                                     
                                             [A{'eval_loss': 0.254150390625, 'eval_runtime': 3.2001, 'eval_samples_per_second': 21.874, 'eval_steps_per_second': 2.812, 'epoch': 40.76}
 83%|████████▎ | 1610/1950 [3:38:50<49:48,  8.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.82it/s][A
                                             [A 83%|████████▎ | 1611/1950 [3:38:53<44:10,  7.82s/it] 83%|████████▎ | 1612/1950 [3:38:55<35:00,  6.21s/it] 83%|████████▎ | 1613/1950 [3:38:58<28:30,  5.07s/it] 83%|████████▎ | 1614/1950 [3:39:00<24:06,  4.30s/it] 83%|████████▎ | 1615/1950 [3:39:03<20:49,  3.73s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.595056771619704e-06, 'epoch': 40.89}
 83%|████████▎ | 1615/1950 [3:39:03<20:49,  3.73s/it][INFO|trainer.py:3242] 2024-02-05 13:35:19,046 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:35:19,046 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:35:19,046 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.54it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.27it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.09it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.98it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.81it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2193, 'eval_samples_per_second': 21.744, 'eval_steps_per_second': 2.796, 'epoch': 40.89}
 83%|████████▎ | 1615/1950 [3:39:06<20:49,  3.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 83%|████████▎ | 1616/1950 [3:39:08<23:43,  4.26s/it] 83%|████████▎ | 1617/1950 [3:39:10<20:22,  3.67s/it] 83%|████████▎ | 1618/1950 [3:39:13<18:10,  3.29s/it] 83%|████████▎ | 1619/1950 [3:39:15<16:41,  3.03s/it] 83%|████████▎ | 1620/1950 [3:39:17<15:21,  2.79s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.491707592370308e-06, 'epoch': 41.01}
 83%|████████▎ | 1620/1950 [3:39:17<15:21,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 13:35:33,898 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:35:33,898 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:35:33,898 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.88it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.11it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2338, 'eval_samples_per_second': 21.646, 'eval_steps_per_second': 2.783, 'epoch': 41.01}
 83%|████████▎ | 1620/1950 [3:39:21<15:21,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.80it/s][A
                                             [A 83%|████████▎ | 1621/1950 [3:39:23<19:37,  3.58s/it] 83%|████████▎ | 1622/1950 [3:39:25<17:19,  3.17s/it] 83%|████████▎ | 1623/1950 [3:39:27<15:55,  2.92s/it] 83%|████████▎ | 1624/1950 [3:39:30<15:05,  2.78s/it] 83%|████████▎ | 1625/1950 [3:39:32<14:15,  2.63s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.389754055392666e-06, 'epoch': 41.14}
 83%|████████▎ | 1625/1950 [3:39:32<14:15,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 13:35:48,606 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:35:48,607 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:35:48,607 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.85it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.21it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2675, 'eval_samples_per_second': 21.423, 'eval_steps_per_second': 2.754, 'epoch': 41.14}
 83%|████████▎ | 1625/1950 [3:39:35<14:15,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 83%|████████▎ | 1626/1950 [3:39:38<19:08,  3.54s/it] 83%|████████▎ | 1627/1950 [3:39:40<17:31,  3.26s/it] 83%|████████▎ | 1628/1950 [3:39:43<15:53,  2.96s/it] 84%|████████▎ | 1629/1950 [3:39:45<14:43,  2.75s/it] 84%|████████▎ | 1630/1950 [3:39:47<14:03,  2.64s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.2892027763056803e-06, 'epoch': 41.27}
 84%|████████▎ | 1630/1950 [3:39:47<14:03,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 13:36:03,771 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:36:03,771 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:36:03,771 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2983, 'eval_samples_per_second': 21.223, 'eval_steps_per_second': 2.729, 'epoch': 41.27}
 84%|████████▎ | 1630/1950 [3:39:51<14:03,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 84%|████████▎ | 1631/1950 [3:39:53<19:10,  3.61s/it] 84%|████████▎ | 1632/1950 [3:39:56<17:21,  3.28s/it] 84%|████████▎ | 1633/1950 [3:39:58<15:50,  3.00s/it] 84%|████████▍ | 1634/1950 [3:40:00<14:48,  2.81s/it] 84%|████████▍ | 1635/1950 [3:40:03<14:08,  2.69s/it]                                                     {'loss': 0.0003, 'learning_rate': 3.1900602797377528e-06, 'epoch': 41.39}
 84%|████████▍ | 1635/1950 [3:40:03<14:08,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 13:36:19,291 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:36:19,291 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:36:19,291 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2999, 'eval_samples_per_second': 21.213, 'eval_steps_per_second': 2.727, 'epoch': 41.39}
 84%|████████▍ | 1635/1950 [3:40:06<14:08,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 84%|████████▍ | 1636/1950 [3:40:09<19:13,  3.67s/it] 84%|████████▍ | 1637/1950 [3:40:11<17:21,  3.33s/it] 84%|████████▍ | 1638/1950 [3:40:14<15:42,  3.02s/it] 84%|████████▍ | 1639/1950 [3:40:16<15:14,  2.94s/it] 84%|████████▍ | 1640/1950 [3:40:19<14:18,  2.77s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.092332998903416e-06, 'epoch': 41.52}
 84%|████████▍ | 1640/1950 [3:40:19<14:18,  2.77s/it][INFO|trainer.py:3242] 2024-02-05 13:36:35,199 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:36:35,199 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:36:35,200 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2975, 'eval_samples_per_second': 21.228, 'eval_steps_per_second': 2.729, 'epoch': 41.52}
 84%|████████▍ | 1640/1950 [3:40:22<14:18,  2.77s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 84%|████████▍ | 1641/1950 [3:40:25<19:33,  3.80s/it] 84%|████████▍ | 1642/1950 [3:40:27<17:12,  3.35s/it] 84%|████████▍ | 1643/1950 [3:40:30<16:11,  3.16s/it] 84%|████████▍ | 1644/1950 [3:40:32<14:52,  2.92s/it] 84%|████████▍ | 1645/1950 [3:40:35<14:10,  2.79s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.9960272751858616e-06, 'epoch': 41.65}
 84%|████████▍ | 1645/1950 [3:40:35<14:10,  2.79s/it][INFO|trainer.py:3242] 2024-02-05 13:36:51,258 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:36:51,259 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:36:51,259 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2939, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 41.65}
 84%|████████▍ | 1645/1950 [3:40:38<14:10,  2.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 84%|████████▍ | 1646/1950 [3:40:40<18:15,  3.60s/it] 84%|████████▍ | 1647/1950 [3:40:43<16:26,  3.26s/it] 85%|████████▍ | 1648/1950 [3:40:45<14:57,  2.97s/it] 85%|████████▍ | 1649/1950 [3:40:48<14:05,  2.81s/it] 85%|████████▍ | 1650/1950 [3:40:50<13:21,  2.67s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.9011493577255077e-06, 'epoch': 41.77}
 85%|████████▍ | 1650/1950 [3:40:50<13:21,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 13:37:06,302 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:37:06,303 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:37:06,303 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.294, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 41.77}
 85%|████████▍ | 1650/1950 [3:40:53<13:21,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 85%|████████▍ | 1651/1950 [3:40:55<17:41,  3.55s/it] 85%|████████▍ | 1652/1950 [3:40:58<16:28,  3.32s/it] 85%|████████▍ | 1653/1950 [3:41:01<15:01,  3.03s/it] 85%|████████▍ | 1654/1950 [3:41:03<13:47,  2.80s/it] 85%|████████▍ | 1655/1950 [3:41:05<12:56,  2.63s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.8077054030144377e-06, 'epoch': 41.9}
 85%|████████▍ | 1655/1950 [3:41:05<12:56,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 13:37:21,539 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:37:21,540 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:37:21,540 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2945, 'eval_samples_per_second': 21.247, 'eval_steps_per_second': 2.732, 'epoch': 41.9}
 85%|████████▍ | 1655/1950 [3:41:08<12:56,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 85%|████████▍ | 1656/1950 [3:41:11<17:26,  3.56s/it] 85%|████████▍ | 1657/1950 [3:41:13<15:37,  3.20s/it] 85%|████████▌ | 1658/1950 [3:41:16<14:24,  2.96s/it] 85%|████████▌ | 1659/1950 [3:41:18<13:24,  2.77s/it] 85%|████████▌ | 1660/1950 [3:41:20<12:40,  2.62s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.7157014744969734e-06, 'epoch': 42.03}
 85%|████████▌ | 1660/1950 [3:41:20<12:40,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 13:37:36,622 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:37:36,622 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:37:36,622 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2905, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 42.03}
 85%|████████▌ | 1660/1950 [3:41:23<12:40,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 85%|████████▌ | 1661/1950 [3:41:26<16:50,  3.50s/it] 85%|████████▌ | 1662/1950 [3:41:28<14:58,  3.12s/it] 85%|████████▌ | 1663/1950 [3:41:30<13:58,  2.92s/it] 85%|████████▌ | 1664/1950 [3:41:33<13:12,  2.77s/it] 85%|████████▌ | 1665/1950 [3:41:35<12:23,  2.61s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.6251435421761865e-06, 'epoch': 42.15}
 85%|████████▌ | 1665/1950 [3:41:35<12:23,  2.61s/it][INFO|trainer.py:3242] 2024-02-05 13:37:51,503 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:37:51,503 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:37:51,503 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2922, 'eval_samples_per_second': 21.262, 'eval_steps_per_second': 2.734, 'epoch': 42.15}
 85%|████████▌ | 1665/1950 [3:41:38<12:23,  2.61s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 85%|████████▌ | 1666/1950 [3:41:41<16:50,  3.56s/it] 85%|████████▌ | 1667/1950 [3:41:43<15:08,  3.21s/it] 86%|████████▌ | 1668/1950 [3:41:45<13:36,  2.90s/it] 86%|████████▌ | 1669/1950 [3:41:48<12:48,  2.74s/it] 86%|████████▌ | 1670/1950 [3:41:50<12:20,  2.65s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.5360374822265277e-06, 'epoch': 42.28}
 86%|████████▌ | 1670/1950 [3:41:50<12:20,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 13:38:06,641 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:38:06,641 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:38:06,641 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2911, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 42.28}
 86%|████████▌ | 1670/1950 [3:41:54<12:20,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 86%|████████▌ | 1671/1950 [3:41:56<16:35,  3.57s/it] 86%|████████▌ | 1672/1950 [3:41:58<14:55,  3.22s/it] 86%|████████▌ | 1673/1950 [3:42:01<13:30,  2.93s/it] 86%|████████▌ | 1674/1950 [3:42:03<12:49,  2.79s/it] 86%|████████▌ | 1675/1950 [3:42:05<12:13,  2.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 2.4483890766125314e-06, 'epoch': 42.41}
 86%|████████▌ | 1675/1950 [3:42:05<12:13,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 13:38:21,854 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:38:21,854 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:38:21,854 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2911, 'eval_samples_per_second': 21.27, 'eval_steps_per_second': 2.735, 'epoch': 42.41}
 86%|████████▌ | 1675/1950 [3:42:09<12:13,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 86%|████████▌ | 1676/1950 [3:42:11<16:33,  3.63s/it] 86%|████████▌ | 1677/1950 [3:42:14<14:44,  3.24s/it] 86%|████████▌ | 1678/1950 [3:42:16<13:36,  3.00s/it] 86%|████████▌ | 1679/1950 [3:42:19<12:59,  2.87s/it] 86%|████████▌ | 1680/1950 [3:42:21<12:14,  2.72s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.36220401271364e-06, 'epoch': 42.53}
 86%|████████▌ | 1680/1950 [3:42:21<12:14,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 13:38:37,448 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:38:37,448 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:38:37,448 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2836, 'eval_samples_per_second': 21.318, 'eval_steps_per_second': 2.741, 'epoch': 42.53}
 86%|████████▌ | 1680/1950 [3:42:24<12:14,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 86%|████████▌ | 1681/1950 [3:42:27<16:44,  3.74s/it] 86%|████████▋ | 1682/1950 [3:42:29<14:37,  3.27s/it] 86%|████████▋ | 1683/1950 [3:42:32<13:52,  3.12s/it] 86%|████████▋ | 1684/1950 [3:42:34<12:46,  2.88s/it] 86%|████████▋ | 1685/1950 [3:42:37<12:08,  2.75s/it]                                                     {'loss': 0.0004, 'learning_rate': 2.27748788295514e-06, 'epoch': 42.66}
 86%|████████▋ | 1685/1950 [3:42:37<12:08,  2.75s/it][INFO|trainer.py:3242] 2024-02-05 13:38:53,268 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:38:53,268 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:38:53,268 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2947, 'eval_samples_per_second': 21.246, 'eval_steps_per_second': 2.732, 'epoch': 42.66}
 86%|████████▋ | 1685/1950 [3:42:40<12:08,  2.75s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 86%|████████▋ | 1686/1950 [3:42:43<15:55,  3.62s/it] 87%|████████▋ | 1687/1950 [3:42:45<14:08,  3.23s/it] 87%|████████▋ | 1688/1950 [3:42:47<13:02,  2.99s/it] 87%|████████▋ | 1689/1950 [3:42:50<12:11,  2.80s/it] 87%|████████▋ | 1690/1950 [3:42:52<11:28,  2.65s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.194246184445284e-06, 'epoch': 42.78}
 87%|████████▋ | 1690/1950 [3:42:52<11:28,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 13:39:08,323 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:39:08,324 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:39:08,324 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.299, 'eval_samples_per_second': 21.218, 'eval_steps_per_second': 2.728, 'epoch': 42.78}
 87%|████████▋ | 1690/1950 [3:42:55<11:28,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 87%|████████▋ | 1691/1950 [3:42:58<15:27,  3.58s/it] 87%|████████▋ | 1692/1950 [3:43:00<13:58,  3.25s/it] 87%|████████▋ | 1693/1950 [3:43:02<12:42,  2.97s/it] 87%|████████▋ | 1694/1950 [3:43:05<11:49,  2.77s/it] 87%|████████▋ | 1695/1950 [3:43:07<11:04,  2.60s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.112484318618599e-06, 'epoch': 42.91}
 87%|████████▋ | 1695/1950 [3:43:07<11:04,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 13:39:23,395 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:39:23,395 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:39:23,395 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.2939, 'eval_samples_per_second': 21.252, 'eval_steps_per_second': 2.732, 'epoch': 42.91}
 87%|████████▋ | 1695/1950 [3:43:10<11:04,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 87%|████████▋ | 1696/1950 [3:43:13<14:51,  3.51s/it] 87%|████████▋ | 1697/1950 [3:43:15<13:17,  3.15s/it] 87%|████████▋ | 1698/1950 [3:43:17<12:20,  2.94s/it] 87%|████████▋ | 1699/1950 [3:43:20<11:28,  2.74s/it] 87%|████████▋ | 1700/1950 [3:43:22<10:44,  2.58s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.0322075908853934e-06, 'epoch': 43.04}
 87%|████████▋ | 1700/1950 [3:43:22<10:44,  2.58s/it][INFO|trainer.py:3242] 2024-02-05 13:39:38,260 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:39:38,260 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:39:38,260 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 43.04}
 87%|████████▋ | 1700/1950 [3:43:25<10:44,  2.58s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 13:39:55,565 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 13:39:55,711 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 13:39:55,711 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/special_tokens_map.json
[2024-02-05 13:39:58,949] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1700 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 13:40:12,810] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/mp_rank_00_model_states.pt
[2024-02-05 13:40:12,810] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/mp_rank_00_model_states.pt...
[2024-02-05 13:48:18,011] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/mp_rank_00_model_states.pt.
[2024-02-05 13:48:19,085] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 13:48:19,781] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 13:48:19,786] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1700/global_step1700/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 13:48:19,786] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1700 is ready now!
 87%|████████▋ | 1701/1950 [3:52:06<10:59:34, 158.93s/it] 87%|████████▋ | 1702/1950 [3:52:08<7:42:44, 111.95s/it]  87%|████████▋ | 1703/1950 [3:52:10<5:25:33, 79.08s/it]  87%|████████▋ | 1704/1950 [3:52:13<3:49:49, 56.06s/it] 87%|████████▋ | 1705/1950 [3:52:15<2:43:12, 39.97s/it]                                                       {'loss': 0.0002, 'learning_rate': 1.95342121028749e-06, 'epoch': 43.16}
 87%|████████▋ | 1705/1950 [3:52:15<2:43:12, 39.97s/it][INFO|trainer.py:3242] 2024-02-05 13:48:31,511 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:48:31,512 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:48:31,512 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.92it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                       
                                             [A{'eval_loss': 0.2548828125, 'eval_runtime': 3.2344, 'eval_samples_per_second': 21.642, 'eval_steps_per_second': 2.783, 'epoch': 43.16}
 87%|████████▋ | 1705/1950 [3:52:18<2:43:12, 39.97s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 87%|████████▋ | 1706/1950 [3:52:21<2:00:51, 29.72s/it] 88%|████████▊ | 1707/1950 [3:52:23<1:26:55, 21.46s/it] 88%|████████▊ | 1708/1950 [3:52:25<1:03:15, 15.69s/it] 88%|████████▊ | 1709/1950 [3:52:28<46:56, 11.68s/it]   88%|████████▊ | 1710/1950 [3:52:30<35:44,  8.94s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.8761302891602133e-06, 'epoch': 43.29}
 88%|████████▊ | 1710/1950 [3:52:30<35:44,  8.94s/it][INFO|trainer.py:3242] 2024-02-05 13:48:46,577 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:48:46,577 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:48:46,578 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.48it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.04it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2749, 'eval_samples_per_second': 21.375, 'eval_steps_per_second': 2.748, 'epoch': 43.29}
 88%|████████▊ | 1710/1950 [3:52:33<35:44,  8.94s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 88%|████████▊ | 1711/1950 [3:52:36<31:40,  7.95s/it] 88%|████████▊ | 1712/1950 [3:52:38<24:51,  6.27s/it] 88%|████████▊ | 1713/1950 [3:52:41<20:09,  5.10s/it] 88%|████████▊ | 1714/1950 [3:52:43<16:56,  4.31s/it] 88%|████████▊ | 1715/1950 [3:52:46<14:51,  3.79s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.8003398428006747e-06, 'epoch': 43.42}
 88%|████████▊ | 1715/1950 [3:52:46<14:51,  3.79s/it][INFO|trainer.py:3242] 2024-02-05 13:49:01,994 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:49:01,994 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:49:01,995 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.44it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.3051, 'eval_samples_per_second': 21.179, 'eval_steps_per_second': 2.723, 'epoch': 43.42}
 88%|████████▊ | 1715/1950 [3:52:49<14:51,  3.79s/it]
100%|██████████| 9/9 [00:02<00:00,  2.73it/s][A
                                             [A 88%|████████▊ | 1716/1950 [3:52:51<17:07,  4.39s/it] 88%|████████▊ | 1717/1950 [3:52:54<14:31,  3.74s/it] 88%|████████▊ | 1718/1950 [3:52:56<13:21,  3.45s/it] 88%|████████▊ | 1719/1950 [3:52:59<11:59,  3.11s/it] 88%|████████▊ | 1720/1950 [3:53:02<11:42,  3.05s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.7260547891423313e-06, 'epoch': 43.54}
 88%|████████▊ | 1720/1950 [3:53:02<11:42,  3.05s/it][INFO|trainer.py:3242] 2024-02-05 13:49:18,027 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:49:18,027 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:49:18,027 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.3, 'eval_samples_per_second': 21.212, 'eval_steps_per_second': 2.727, 'epoch': 43.54}
 88%|████████▊ | 1720/1950 [3:53:05<11:42,  3.05s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 88%|████████▊ | 1721/1950 [3:53:07<14:34,  3.82s/it] 88%|████████▊ | 1722/1950 [3:53:10<13:16,  3.49s/it] 88%|████████▊ | 1723/1950 [3:53:12<11:57,  3.16s/it] 88%|████████▊ | 1724/1950 [3:53:15<11:08,  2.96s/it] 88%|████████▊ | 1725/1950 [3:53:17<10:12,  2.72s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.653279948435857e-06, 'epoch': 43.67}
 88%|████████▊ | 1725/1950 [3:53:17<10:12,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 13:49:33,399 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:49:33,399 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:49:33,399 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25439453125, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 43.67}
 88%|████████▊ | 1725/1950 [3:53:20<10:12,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 89%|████████▊ | 1726/1950 [3:53:23<13:31,  3.62s/it] 89%|████████▊ | 1727/1950 [3:53:25<12:07,  3.26s/it] 89%|████████▊ | 1728/1950 [3:53:28<11:08,  3.01s/it] 89%|████████▊ | 1729/1950 [3:53:30<10:19,  2.81s/it] 89%|████████▊ | 1730/1950 [3:53:32<09:44,  2.66s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.5820200429363775e-06, 'epoch': 43.8}
 89%|████████▊ | 1730/1950 [3:53:32<09:44,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 13:49:48,603 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:49:48,603 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:49:48,603 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.292, 'eval_samples_per_second': 21.264, 'eval_steps_per_second': 2.734, 'epoch': 43.8}
 89%|████████▊ | 1730/1950 [3:53:35<09:44,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 89%|████████▉ | 1731/1950 [3:53:38<13:25,  3.68s/it] 89%|████████▉ | 1732/1950 [3:53:41<11:52,  3.27s/it] 89%|████████▉ | 1733/1950 [3:53:43<10:46,  2.98s/it] 89%|████████▉ | 1734/1950 [3:53:45<09:55,  2.76s/it] 89%|████████▉ | 1735/1950 [3:53:48<09:33,  2.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.512279696597038e-06, 'epoch': 43.92}
 89%|████████▉ | 1735/1950 [3:53:48<09:33,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 13:50:03,988 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:50:03,988 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:50:03,988 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2921, 'eval_samples_per_second': 21.263, 'eval_steps_per_second': 2.734, 'epoch': 43.92}
 89%|████████▉ | 1735/1950 [3:53:51<09:33,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 89%|████████▉ | 1736/1950 [3:53:53<12:41,  3.56s/it] 89%|████████▉ | 1737/1950 [3:53:56<11:19,  3.19s/it] 89%|████████▉ | 1738/1950 [3:53:58<10:21,  2.93s/it] 89%|████████▉ | 1739/1950 [3:54:00<09:37,  2.74s/it] 89%|████████▉ | 1740/1950 [3:54:02<09:05,  2.60s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.4440634347689719e-06, 'epoch': 44.05}
 89%|████████▉ | 1740/1950 [3:54:02<09:05,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 13:50:18,830 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:50:18,830 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:50:18,830 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.299, 'eval_samples_per_second': 21.218, 'eval_steps_per_second': 2.728, 'epoch': 44.05}
 89%|████████▉ | 1740/1950 [3:54:06<09:05,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 89%|████████▉ | 1741/1950 [3:54:08<12:05,  3.47s/it] 89%|████████▉ | 1742/1950 [3:54:11<11:11,  3.23s/it] 89%|████████▉ | 1743/1950 [3:54:13<10:17,  2.98s/it] 89%|████████▉ | 1744/1950 [3:54:15<09:32,  2.78s/it] 89%|████████▉ | 1745/1950 [3:54:18<09:11,  2.69s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.3773756839076501e-06, 'epoch': 44.18}
 89%|████████▉ | 1745/1950 [3:54:18<09:11,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 13:50:34,193 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:50:34,193 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:50:34,193 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.2944, 'eval_samples_per_second': 21.248, 'eval_steps_per_second': 2.732, 'epoch': 44.18}
 89%|████████▉ | 1745/1950 [3:54:21<09:11,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 90%|████████▉ | 1746/1950 [3:54:23<12:12,  3.59s/it] 90%|████████▉ | 1747/1950 [3:54:26<10:49,  3.20s/it] 90%|████████▉ | 1748/1950 [3:54:28<09:55,  2.95s/it] 90%|████████▉ | 1749/1950 [3:54:31<09:25,  2.81s/it] 90%|████████▉ | 1750/1950 [3:54:33<08:57,  2.69s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.3122207712856633e-06, 'epoch': 44.3}
 90%|████████▉ | 1750/1950 [3:54:33<08:57,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 13:50:49,428 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:50:49,428 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:50:49,428 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2943, 'eval_samples_per_second': 21.249, 'eval_steps_per_second': 2.732, 'epoch': 44.3}
 90%|████████▉ | 1750/1950 [3:54:36<08:57,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 90%|████████▉ | 1751/1950 [3:54:39<11:55,  3.59s/it] 90%|████████▉ | 1752/1950 [3:54:41<10:29,  3.18s/it] 90%|████████▉ | 1753/1950 [3:54:43<09:43,  2.96s/it] 90%|████████▉ | 1754/1950 [3:54:46<09:06,  2.79s/it] 90%|█████████ | 1755/1950 [3:54:48<08:50,  2.72s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.2486029247119168e-06, 'epoch': 44.43}
 90%|█████████ | 1755/1950 [3:54:48<08:50,  2.72s/it][INFO|trainer.py:3242] 2024-02-05 13:51:04,742 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:51:04,742 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:51:04,743 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.294, 'eval_samples_per_second': 21.251, 'eval_steps_per_second': 2.732, 'epoch': 44.43}
 90%|█████████ | 1755/1950 [3:54:52<08:50,  2.72s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 90%|█████████ | 1756/1950 [3:54:54<11:37,  3.59s/it] 90%|█████████ | 1757/1950 [3:54:56<10:27,  3.25s/it] 90%|█████████ | 1758/1950 [3:54:59<09:45,  3.05s/it] 90%|█████████ | 1759/1950 [3:55:01<09:01,  2.83s/it] 90%|█████████ | 1760/1950 [3:55:04<09:03,  2.86s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.1865262722573072e-06, 'epoch': 44.56}
 90%|█████████ | 1760/1950 [3:55:04<09:03,  2.86s/it][INFO|trainer.py:3242] 2024-02-05 13:51:20,663 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:51:20,663 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:51:20,664 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.292, 'eval_samples_per_second': 21.264, 'eval_steps_per_second': 2.734, 'epoch': 44.56}
 90%|█████████ | 1760/1950 [3:55:08<09:03,  2.86s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 90%|█████████ | 1761/1950 [3:55:10<11:30,  3.65s/it] 90%|█████████ | 1762/1950 [3:55:13<10:37,  3.39s/it] 90%|█████████ | 1763/1950 [3:55:15<09:38,  3.09s/it] 90%|█████████ | 1764/1950 [3:55:17<09:00,  2.91s/it] 91%|█████████ | 1765/1950 [3:55:20<08:26,  2.74s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.125994841986855e-06, 'epoch': 44.68}
 91%|█████████ | 1765/1950 [3:55:20<08:26,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 13:51:36,165 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:51:36,165 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:51:36,165 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256591796875, 'eval_runtime': 3.2948, 'eval_samples_per_second': 21.246, 'eval_steps_per_second': 2.732, 'epoch': 44.68}
 91%|█████████ | 1765/1950 [3:55:23<08:26,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 91%|█████████ | 1766/1950 [3:55:25<11:02,  3.60s/it] 91%|█████████ | 1767/1950 [3:55:28<09:53,  3.24s/it] 91%|█████████ | 1768/1950 [3:55:30<09:02,  2.98s/it] 91%|█████████ | 1769/1950 [3:55:32<08:22,  2.77s/it] 91%|█████████ | 1770/1950 [3:55:35<08:01,  2.67s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.067012561698319e-06, 'epoch': 44.81}
 91%|█████████ | 1770/1950 [3:55:35<08:01,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 13:51:51,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:51:51,279 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:51:51,280 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2882, 'eval_samples_per_second': 21.288, 'eval_steps_per_second': 2.737, 'epoch': 44.81}
 91%|█████████ | 1770/1950 [3:55:38<08:01,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 91%|█████████ | 1771/1950 [3:55:41<10:45,  3.60s/it] 91%|█████████ | 1772/1950 [3:55:43<09:31,  3.21s/it] 91%|█████████ | 1773/1950 [3:55:45<08:40,  2.94s/it] 91%|█████████ | 1774/1950 [3:55:47<07:59,  2.72s/it] 91%|█████████ | 1775/1950 [3:55:50<07:34,  2.60s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.0095832586673515e-06, 'epoch': 44.94}
 91%|█████████ | 1775/1950 [3:55:50<07:34,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 13:52:06,168 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:52:06,169 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:52:06,169 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2843, 'eval_samples_per_second': 21.314, 'eval_steps_per_second': 2.74, 'epoch': 44.94}
 91%|█████████ | 1775/1950 [3:55:53<07:34,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 91%|█████████ | 1776/1950 [3:55:55<10:13,  3.53s/it] 91%|█████████ | 1777/1950 [3:55:58<09:14,  3.21s/it] 91%|█████████ | 1778/1950 [3:56:00<08:23,  2.93s/it] 91%|█████████ | 1779/1950 [3:56:02<07:43,  2.71s/it] 91%|█████████▏| 1780/1950 [3:56:05<07:15,  2.56s/it]                                                     {'loss': 0.0002, 'learning_rate': 9.537106593991207e-07, 'epoch': 45.06}
 91%|█████████▏| 1780/1950 [3:56:05<07:15,  2.56s/it][INFO|trainer.py:3242] 2024-02-05 13:52:21,015 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:52:21,015 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:52:21,015 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2955, 'eval_samples_per_second': 21.241, 'eval_steps_per_second': 2.731, 'epoch': 45.06}
 91%|█████████▏| 1780/1950 [3:56:08<07:15,  2.56s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 91%|█████████▏| 1781/1950 [3:56:10<09:49,  3.49s/it] 91%|█████████▏| 1782/1950 [3:56:13<08:53,  3.18s/it] 91%|█████████▏| 1783/1950 [3:56:15<08:08,  2.93s/it] 91%|█████████▏| 1784/1950 [3:56:17<07:39,  2.77s/it] 92%|█████████▏| 1785/1950 [3:56:20<07:31,  2.73s/it]                                                     {'loss': 0.0002, 'learning_rate': 8.993983893865271e-07, 'epoch': 45.19}
 92%|█████████▏| 1785/1950 [3:56:20<07:31,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 13:52:36,519 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:52:36,519 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:52:36,519 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2915, 'eval_samples_per_second': 21.267, 'eval_steps_per_second': 2.734, 'epoch': 45.19}
 92%|█████████▏| 1785/1950 [3:56:23<07:31,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 92%|█████████▏| 1786/1950 [3:56:26<09:46,  3.58s/it] 92%|█████████▏| 1787/1950 [3:56:28<08:38,  3.18s/it] 92%|█████████▏| 1788/1950 [3:56:30<07:56,  2.94s/it] 92%|█████████▏| 1789/1950 [3:56:33<07:33,  2.81s/it] 92%|█████████▏| 1790/1950 [3:56:35<07:09,  2.68s/it]                                                     {'loss': 0.0002, 'learning_rate': 8.466499728749411e-07, 'epoch': 45.32}
 92%|█████████▏| 1790/1950 [3:56:35<07:09,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 13:52:51,606 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:52:51,606 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:52:51,606 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2974, 'eval_samples_per_second': 21.229, 'eval_steps_per_second': 2.729, 'epoch': 45.32}
 92%|█████████▏| 1790/1950 [3:56:38<07:09,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 92%|█████████▏| 1791/1950 [3:56:41<09:28,  3.57s/it] 92%|█████████▏| 1792/1950 [3:56:43<08:29,  3.22s/it] 92%|█████████▏| 1793/1950 [3:56:46<07:48,  2.99s/it] 92%|█████████▏| 1794/1950 [3:56:48<07:24,  2.85s/it] 92%|█████████▏| 1795/1950 [3:56:51<07:03,  2.73s/it]                                                     {'loss': 0.0003, 'learning_rate': 7.954688326335141e-07, 'epoch': 45.44}
 92%|█████████▏| 1795/1950 [3:56:51<07:03,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 13:53:07,088 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:53:07,088 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:53:07,088 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.2893, 'eval_samples_per_second': 21.281, 'eval_steps_per_second': 2.736, 'epoch': 45.44}
 92%|█████████▏| 1795/1950 [3:56:54<07:03,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 92%|█████████▏| 1796/1950 [3:56:56<09:09,  3.57s/it] 92%|█████████▏| 1797/1950 [3:56:59<08:28,  3.33s/it] 92%|█████████▏| 1798/1950 [3:57:01<07:41,  3.04s/it] 92%|█████████▏| 1799/1950 [3:57:05<07:56,  3.15s/it] 92%|█████████▏| 1800/1950 [3:57:07<07:23,  2.96s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.458582897330923e-07, 'epoch': 45.57}
 92%|█████████▏| 1800/1950 [3:57:07<07:23,  2.96s/it][INFO|trainer.py:3242] 2024-02-05 13:53:23,665 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 13:53:23,665 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 13:53:23,665 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2876, 'eval_samples_per_second': 21.292, 'eval_steps_per_second': 2.738, 'epoch': 45.57}
 92%|█████████▏| 1800/1950 [3:57:11<07:23,  2.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 13:53:43,366 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 13:53:43,515 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 13:53:43,516 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/special_tokens_map.json
[2024-02-05 13:53:44,597] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1800 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 13:54:00,760] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/mp_rank_00_model_states.pt
[2024-02-05 13:54:00,760] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/mp_rank_00_model_states.pt...
[2024-02-05 14:01:59,739] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/mp_rank_00_model_states.pt.
[2024-02-05 14:02:00,904] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 14:02:01,590] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 14:02:01,592] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1800/global_step1800/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 14:02:01,592] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1800 is ready now!
 92%|█████████▏| 1801/1950 [4:05:48<6:33:04, 158.29s/it] 92%|█████████▏| 1802/1950 [4:05:50<4:34:59, 111.48s/it] 92%|█████████▏| 1803/1950 [4:05:53<3:13:05, 78.82s/it]  93%|█████████▎| 1804/1950 [4:05:55<2:15:48, 55.81s/it] 93%|█████████▎| 1805/1950 [4:05:57<1:36:07, 39.78s/it]                                                       {'loss': 0.0004, 'learning_rate': 6.978215633307139e-07, 'epoch': 45.7}
 93%|█████████▎| 1805/1950 [4:05:57<1:36:07, 39.78s/it][INFO|trainer.py:3242] 2024-02-05 14:02:13,751 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:02:13,752 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:02:13,752 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.90it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.12it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.52it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.25it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.08it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                       
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.2344, 'eval_samples_per_second': 21.642, 'eval_steps_per_second': 2.783, 'epoch': 45.7}
 93%|█████████▎| 1805/1950 [4:06:01<1:36:07, 39.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 93%|█████████▎| 1806/1950 [4:06:03<1:10:50, 29.52s/it] 93%|█████████▎| 1807/1950 [4:06:05<50:55, 21.37s/it]   93%|█████████▎| 1808/1950 [4:06:08<37:00, 15.64s/it] 93%|█████████▎| 1809/1950 [4:06:10<27:21, 11.64s/it] 93%|█████████▎| 1810/1950 [4:06:13<20:54,  8.96s/it]                                                     {'loss': 0.0002, 'learning_rate': 6.513617704607094e-07, 'epoch': 45.82}
 93%|█████████▎| 1810/1950 [4:06:13<20:54,  8.96s/it][INFO|trainer.py:3242] 2024-02-05 14:02:28,972 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:02:28,973 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:02:28,973 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.82it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.08it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.50it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.23it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.95it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.78it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2606, 'eval_samples_per_second': 21.469, 'eval_steps_per_second': 2.76, 'epoch': 45.82}
 93%|█████████▎| 1810/1950 [4:06:16<20:54,  8.96s/it]
100%|██████████| 9/9 [00:02<00:00,  2.77it/s][A
                                             [A 93%|█████████▎| 1811/1950 [4:06:18<18:26,  7.96s/it] 93%|█████████▎| 1812/1950 [4:06:20<14:22,  6.25s/it] 93%|█████████▎| 1813/1950 [4:06:23<11:30,  5.04s/it] 93%|█████████▎| 1814/1950 [4:06:25<09:38,  4.25s/it] 93%|█████████▎| 1815/1950 [4:06:27<08:15,  3.67s/it]                                                     {'loss': 0.0003, 'learning_rate': 6.064819258324639e-07, 'epoch': 45.95}
 93%|█████████▎| 1815/1950 [4:06:27<08:15,  3.67s/it][INFO|trainer.py:3242] 2024-02-05 14:02:43,792 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:02:43,792 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:02:43,792 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2897, 'eval_samples_per_second': 21.279, 'eval_steps_per_second': 2.736, 'epoch': 45.95}
 93%|█████████▎| 1815/1950 [4:06:31<08:15,  3.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 93%|█████████▎| 1816/1950 [4:06:33<09:31,  4.26s/it] 93%|█████████▎| 1817/1950 [4:06:35<08:09,  3.68s/it] 93%|█████████▎| 1818/1950 [4:06:38<07:10,  3.26s/it] 93%|█████████▎| 1819/1950 [4:06:40<06:26,  2.95s/it] 93%|█████████▎| 1820/1950 [4:06:42<05:55,  2.73s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.631849416347757e-07, 'epoch': 46.08}
 93%|█████████▎| 1820/1950 [4:06:42<05:55,  2.73s/it][INFO|trainer.py:3242] 2024-02-05 14:02:58,494 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:02:58,494 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:02:58,494 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.3023, 'eval_samples_per_second': 21.197, 'eval_steps_per_second': 2.725, 'epoch': 46.08}
 93%|█████████▎| 1820/1950 [4:06:45<05:55,  2.73s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 93%|█████████▎| 1821/1950 [4:06:48<07:49,  3.64s/it] 93%|█████████▎| 1822/1950 [4:06:50<06:59,  3.27s/it] 93%|█████████▎| 1823/1950 [4:06:52<06:16,  2.97s/it] 94%|█████████▎| 1824/1950 [4:06:55<05:54,  2.81s/it] 94%|█████████▎| 1825/1950 [4:06:57<05:36,  2.69s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.214736273469079e-07, 'epoch': 46.2}
 94%|█████████▎| 1825/1950 [4:06:57<05:36,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 14:03:13,788 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:03:13,788 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:03:13,788 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2954, 'eval_samples_per_second': 21.242, 'eval_steps_per_second': 2.731, 'epoch': 46.2}
 94%|█████████▎| 1825/1950 [4:07:01<05:36,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 94%|█████████▎| 1826/1950 [4:07:03<07:17,  3.53s/it] 94%|█████████▎| 1827/1950 [4:07:05<06:30,  3.18s/it] 94%|█████████▎| 1828/1950 [4:07:08<05:59,  2.95s/it] 94%|█████████▍| 1829/1950 [4:07:10<05:37,  2.79s/it] 94%|█████████▍| 1830/1950 [4:07:12<05:20,  2.67s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.813506895562648e-07, 'epoch': 46.33}
 94%|█████████▍| 1830/1950 [4:07:12<05:20,  2.67s/it][INFO|trainer.py:3242] 2024-02-05 14:03:28,858 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:03:28,858 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:03:28,858 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2884, 'eval_samples_per_second': 21.287, 'eval_steps_per_second': 2.737, 'epoch': 46.33}
 94%|█████████▍| 1830/1950 [4:07:16<05:20,  2.67s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 94%|█████████▍| 1831/1950 [4:07:18<06:59,  3.53s/it] 94%|█████████▍| 1832/1950 [4:07:20<06:20,  3.23s/it] 94%|█████████▍| 1833/1950 [4:07:23<05:48,  2.98s/it] 94%|█████████▍| 1834/1950 [4:07:26<05:45,  2.98s/it] 94%|█████████▍| 1835/1950 [4:07:28<05:20,  2.78s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.4281873178278475e-07, 'epoch': 46.46}
 94%|█████████▍| 1835/1950 [4:07:28<05:20,  2.78s/it][INFO|trainer.py:3242] 2024-02-05 14:03:44,609 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:03:44,609 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:03:44,609 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.2869, 'eval_samples_per_second': 21.297, 'eval_steps_per_second': 2.738, 'epoch': 46.46}
 94%|█████████▍| 1835/1950 [4:07:31<05:20,  2.78s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 94%|█████████▍| 1836/1950 [4:07:34<06:58,  3.68s/it] 94%|█████████▍| 1837/1950 [4:07:37<06:17,  3.35s/it] 94%|█████████▍| 1838/1950 [4:07:39<05:41,  3.05s/it] 94%|█████████▍| 1839/1950 [4:07:42<05:29,  2.97s/it] 94%|█████████▍| 1840/1950 [4:07:44<05:01,  2.74s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.058802543099843e-07, 'epoch': 46.58}
 94%|█████████▍| 1840/1950 [4:07:44<05:01,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 14:04:00,279 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:04:00,280 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:04:00,280 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2991, 'eval_samples_per_second': 21.218, 'eval_steps_per_second': 2.728, 'epoch': 46.58}
 94%|█████████▍| 1840/1950 [4:07:47<05:01,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 94%|█████████▍| 1841/1950 [4:07:50<06:47,  3.74s/it] 94%|█████████▍| 1842/1950 [4:07:52<05:58,  3.32s/it] 95%|█████████▍| 1843/1950 [4:07:55<05:26,  3.05s/it] 95%|█████████▍| 1844/1950 [4:07:57<05:01,  2.84s/it] 95%|█████████▍| 1845/1950 [4:07:59<04:41,  2.68s/it]                                                     {'loss': 0.0004, 'learning_rate': 3.705376540227373e-07, 'epoch': 46.71}
 95%|█████████▍| 1845/1950 [4:07:59<04:41,  2.68s/it][INFO|trainer.py:3242] 2024-02-05 14:04:15,773 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:04:15,773 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:04:15,773 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.2975, 'eval_samples_per_second': 21.228, 'eval_steps_per_second': 2.729, 'epoch': 46.71}
 95%|█████████▍| 1845/1950 [4:08:03<04:41,  2.68s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 95%|█████████▍| 1846/1950 [4:08:05<06:13,  3.60s/it] 95%|█████████▍| 1847/1950 [4:08:08<05:37,  3.28s/it] 95%|█████████▍| 1848/1950 [4:08:10<05:05,  2.99s/it] 95%|█████████▍| 1849/1950 [4:08:12<04:45,  2.83s/it] 95%|█████████▍| 1850/1950 [4:08:15<04:33,  2.74s/it]                                                     {'loss': 0.0002, 'learning_rate': 3.367932242517247e-07, 'epoch': 46.84}
 95%|█████████▍| 1850/1950 [4:08:15<04:33,  2.74s/it][INFO|trainer.py:3242] 2024-02-05 14:04:31,325 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:04:31,325 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:04:31,325 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.93it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.289, 'eval_samples_per_second': 21.283, 'eval_steps_per_second': 2.736, 'epoch': 46.84}
 95%|█████████▍| 1850/1950 [4:08:18<04:33,  2.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 95%|█████████▍| 1851/1950 [4:08:20<05:55,  3.59s/it] 95%|█████████▍| 1852/1950 [4:08:23<05:19,  3.26s/it] 95%|█████████▌| 1853/1950 [4:08:25<04:46,  2.95s/it] 95%|█████████▌| 1854/1950 [4:08:28<04:25,  2.76s/it] 95%|█████████▌| 1855/1950 [4:08:30<04:10,  2.64s/it]                                                     {'loss': 0.0003, 'learning_rate': 3.0464915462464214e-07, 'epoch': 46.96}
 95%|█████████▌| 1855/1950 [4:08:30<04:10,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 14:04:46,296 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:04:46,296 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:04:46,296 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.2912, 'eval_samples_per_second': 21.269, 'eval_steps_per_second': 2.735, 'epoch': 46.96}
 95%|█████████▌| 1855/1950 [4:08:33<04:10,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 95%|█████████▌| 1856/1950 [4:08:36<05:34,  3.56s/it] 95%|█████████▌| 1857/1950 [4:08:38<04:55,  3.18s/it] 95%|█████████▌| 1858/1950 [4:08:40<04:25,  2.88s/it] 95%|█████████▌| 1859/1950 [4:08:42<04:06,  2.71s/it] 95%|█████████▌| 1860/1950 [4:08:45<03:53,  2.60s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.741075309240976e-07, 'epoch': 47.09}
 95%|█████████▌| 1860/1950 [4:08:45<03:53,  2.60s/it][INFO|trainer.py:3242] 2024-02-05 14:05:01,117 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:05:01,117 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:05:01,118 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.76it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2898, 'eval_samples_per_second': 21.278, 'eval_steps_per_second': 2.736, 'epoch': 47.09}
 95%|█████████▌| 1860/1950 [4:08:48<03:53,  2.60s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 95%|█████████▌| 1861/1950 [4:08:50<05:13,  3.53s/it] 95%|█████████▌| 1862/1950 [4:08:53<04:38,  3.17s/it] 96%|█████████▌| 1863/1950 [4:08:55<04:14,  2.92s/it] 96%|█████████▌| 1864/1950 [4:08:58<04:02,  2.82s/it] 96%|█████████▌| 1865/1950 [4:09:00<03:42,  2.62s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.451703349522855e-07, 'epoch': 47.22}
 96%|█████████▌| 1865/1950 [4:09:00<03:42,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 14:05:16,231 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:05:16,231 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:05:16,231 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.2905, 'eval_samples_per_second': 21.273, 'eval_steps_per_second': 2.735, 'epoch': 47.22}
 96%|█████████▌| 1865/1950 [4:09:03<03:42,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 96%|█████████▌| 1866/1950 [4:09:05<04:53,  3.49s/it] 96%|█████████▌| 1867/1950 [4:09:08<04:21,  3.16s/it] 96%|█████████▌| 1868/1950 [4:09:10<04:00,  2.94s/it] 96%|█████████▌| 1869/1950 [4:09:13<03:44,  2.77s/it] 96%|█████████▌| 1870/1950 [4:09:15<03:30,  2.64s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.1783944440238736e-07, 'epoch': 47.34}
 96%|█████████▌| 1870/1950 [4:09:15<03:30,  2.64s/it][INFO|trainer.py:3242] 2024-02-05 14:05:31,261 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:05:31,261 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:05:31,261 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256591796875, 'eval_runtime': 3.2946, 'eval_samples_per_second': 21.247, 'eval_steps_per_second': 2.732, 'epoch': 47.34}
 96%|█████████▌| 1870/1950 [4:09:18<03:30,  2.64s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 96%|█████████▌| 1871/1950 [4:09:20<04:39,  3.54s/it] 96%|█████████▌| 1872/1950 [4:09:23<04:09,  3.20s/it] 96%|█████████▌| 1873/1950 [4:09:25<03:51,  3.00s/it] 96%|█████████▌| 1874/1950 [4:09:28<03:35,  2.84s/it] 96%|█████████▌| 1875/1950 [4:09:30<03:18,  2.65s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.9211663273672188e-07, 'epoch': 47.47}
 96%|█████████▌| 1875/1950 [4:09:30<03:18,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 14:05:46,522 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:05:46,522 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:05:46,523 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.76it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.295, 'eval_samples_per_second': 21.245, 'eval_steps_per_second': 2.731, 'epoch': 47.47}
 96%|█████████▌| 1875/1950 [4:09:33<03:18,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 96%|█████████▌| 1876/1950 [4:09:36<04:31,  3.67s/it] 96%|█████████▋| 1877/1950 [4:09:38<03:57,  3.25s/it] 96%|█████████▋| 1878/1950 [4:09:41<03:44,  3.12s/it] 96%|█████████▋| 1879/1950 [4:09:44<03:23,  2.87s/it] 96%|█████████▋| 1880/1950 [4:09:46<03:17,  2.83s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.680035690716758e-07, 'epoch': 47.59}
 96%|█████████▋| 1880/1950 [4:09:46<03:17,  2.83s/it][INFO|trainer.py:3242] 2024-02-05 14:06:02,674 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:06:02,674 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:06:02,674 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255126953125, 'eval_runtime': 3.2951, 'eval_samples_per_second': 21.244, 'eval_steps_per_second': 2.731, 'epoch': 47.59}
 96%|█████████▋| 1880/1950 [4:09:50<03:17,  2.83s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 96%|█████████▋| 1881/1950 [4:09:52<04:13,  3.67s/it] 97%|█████████▋| 1882/1950 [4:09:54<03:44,  3.31s/it] 97%|█████████▋| 1883/1950 [4:09:57<03:18,  2.97s/it] 97%|█████████▋| 1884/1950 [4:09:59<03:04,  2.80s/it] 97%|█████████▋| 1885/1950 [4:10:01<02:52,  2.66s/it]                                                     {'loss': 0.0004, 'learning_rate': 1.4550181806939622e-07, 'epoch': 47.72}
 97%|█████████▋| 1885/1950 [4:10:01<02:52,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 14:06:17,684 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:06:17,684 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:06:17,684 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.3017, 'eval_samples_per_second': 21.201, 'eval_steps_per_second': 2.726, 'epoch': 47.72}
 97%|█████████▋| 1885/1950 [4:10:05<02:52,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 97%|█████████▋| 1886/1950 [4:10:07<03:48,  3.57s/it] 97%|█████████▋| 1887/1950 [4:10:09<03:20,  3.19s/it] 97%|█████████▋| 1888/1950 [4:10:12<03:01,  2.92s/it] 97%|█████████▋| 1889/1950 [4:10:14<02:54,  2.86s/it] 97%|█████████▋| 1890/1950 [4:10:17<02:41,  2.69s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.246128398362606e-07, 'epoch': 47.85}
 97%|█████████▋| 1890/1950 [4:10:17<02:41,  2.69s/it][INFO|trainer.py:3242] 2024-02-05 14:06:32,979 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:06:32,979 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:06:32,979 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2898, 'eval_samples_per_second': 21.278, 'eval_steps_per_second': 2.736, 'epoch': 47.85}
 97%|█████████▋| 1890/1950 [4:10:20<02:41,  2.69s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 97%|█████████▋| 1891/1950 [4:10:22<03:28,  3.54s/it] 97%|█████████▋| 1892/1950 [4:10:24<03:02,  3.15s/it] 97%|█████████▋| 1893/1950 [4:10:27<02:47,  2.93s/it] 97%|█████████▋| 1894/1950 [4:10:29<02:34,  2.75s/it] 97%|█████████▋| 1895/1950 [4:10:31<02:24,  2.62s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.0533798982812482e-07, 'epoch': 47.97}
 97%|█████████▋| 1895/1950 [4:10:31<02:24,  2.62s/it][INFO|trainer.py:3242] 2024-02-05 14:06:47,821 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:06:47,821 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:06:47,821 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2884, 'eval_samples_per_second': 21.287, 'eval_steps_per_second': 2.737, 'epoch': 47.97}
 97%|█████████▋| 1895/1950 [4:10:35<02:24,  2.62s/it]
100%|██████████| 9/9 [00:02<00:00,  2.75it/s][A
                                             [A 97%|█████████▋| 1896/1950 [4:10:37<03:09,  3.52s/it] 97%|█████████▋| 1897/1950 [4:10:39<02:46,  3.15s/it] 97%|█████████▋| 1898/1950 [4:10:41<02:28,  2.86s/it] 97%|█████████▋| 1899/1950 [4:10:44<02:17,  2.70s/it] 97%|█████████▋| 1900/1950 [4:10:46<02:11,  2.63s/it]                                                     {'loss': 0.0002, 'learning_rate': 8.767851876239074e-08, 'epoch': 48.1}
 97%|█████████▋| 1900/1950 [4:10:46<02:11,  2.63s/it][INFO|trainer.py:3242] 2024-02-05 14:07:02,695 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:07:02,695 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:07:02,695 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.80it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2895, 'eval_samples_per_second': 21.28, 'eval_steps_per_second': 2.736, 'epoch': 48.1}
 97%|█████████▋| 1900/1950 [4:10:50<02:11,  2.63s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:2936] 2024-02-05 14:07:20,702 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 14:07:20,850 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 14:07:20,851 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/special_tokens_map.json
[2024-02-05 14:07:22,367] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step1900 is about to be saved!
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-02-05 14:07:35,792] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/mp_rank_00_model_states.pt
[2024-02-05 14:07:35,792] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/mp_rank_00_model_states.pt...
[2024-02-05 14:15:36,664] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/mp_rank_00_model_states.pt.
[2024-02-05 14:15:37,896] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 14:15:38,583] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 14:15:38,586] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tmp-checkpoint-1900/global_step1900/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-02-05 14:15:38,587] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1900 is ready now!
 97%|█████████▋| 1901/1950 [4:19:25<2:08:29, 157.33s/it] 98%|█████████▊| 1902/1950 [4:19:27<1:28:39, 110.82s/it] 98%|█████████▊| 1903/1950 [4:19:29<1:01:20, 78.30s/it]  98%|█████████▊| 1904/1950 [4:19:32<42:34, 55.53s/it]   98%|█████████▊| 1905/1950 [4:19:34<29:37, 39.51s/it]                                                     {'loss': 0.0002, 'learning_rate': 7.163557253682673e-08, 'epoch': 48.23}
 98%|█████████▊| 1905/1950 [4:19:34<29:37, 39.51s/it][INFO|trainer.py:3242] 2024-02-05 14:15:50,259 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:15:50,259 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:15:50,259 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.91it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.13it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.53it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.26it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.07it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.97it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.80it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.2347, 'eval_samples_per_second': 21.64, 'eval_steps_per_second': 2.782, 'epoch': 48.23}
 98%|█████████▊| 1905/1950 [4:19:37<29:37, 39.51s/it]
100%|██████████| 9/9 [00:02<00:00,  2.79it/s][A
                                             [A 98%|█████████▊| 1906/1950 [4:19:40<21:34, 29.41s/it] 98%|█████████▊| 1907/1950 [4:19:42<15:17, 21.33s/it] 98%|█████████▊| 1908/1950 [4:19:45<10:57, 15.65s/it] 98%|█████████▊| 1909/1950 [4:19:47<07:58, 11.66s/it] 98%|█████████▊| 1910/1950 [4:19:49<05:52,  8.82s/it]                                                     {'loss': 0.0002, 'learning_rate': 5.7210192155224276e-08, 'epoch': 48.35}
 98%|█████████▊| 1910/1950 [4:19:49<05:52,  8.82s/it][INFO|trainer.py:3242] 2024-02-05 14:16:05,521 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:16:05,521 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:16:05,521 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.81it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.07it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.49it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.22it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.05it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.94it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.77it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2694, 'eval_samples_per_second': 21.41, 'eval_steps_per_second': 2.753, 'epoch': 48.35}
 98%|█████████▊| 1910/1950 [4:19:52<05:52,  8.82s/it]
100%|██████████| 9/9 [00:02<00:00,  2.76it/s][A
                                             [A 98%|█████████▊| 1911/1950 [4:19:55<05:08,  7.91s/it] 98%|█████████▊| 1912/1950 [4:19:57<03:57,  6.25s/it] 98%|█████████▊| 1913/1950 [4:20:00<03:10,  5.14s/it] 98%|█████████▊| 1914/1950 [4:20:02<02:34,  4.30s/it] 98%|█████████▊| 1915/1950 [4:20:05<02:11,  3.74s/it]                                                     {'loss': 0.0003, 'learning_rate': 4.4403313659843736e-08, 'epoch': 48.48}
 98%|█████████▊| 1915/1950 [4:20:05<02:11,  3.74s/it][INFO|trainer.py:3242] 2024-02-05 14:16:21,013 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:16:21,013 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:16:21,013 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.77it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.01it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.62it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.65it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.3544, 'eval_samples_per_second': 20.868, 'eval_steps_per_second': 2.683, 'epoch': 48.48}
 98%|█████████▊| 1915/1950 [4:20:08<02:11,  3.74s/it]
100%|██████████| 9/9 [00:02<00:00,  2.65it/s][A
                                             [A 98%|█████████▊| 1916/1950 [4:20:11<02:29,  4.40s/it] 98%|█████████▊| 1917/1950 [4:20:13<02:04,  3.78s/it] 98%|█████████▊| 1918/1950 [4:20:16<01:51,  3.48s/it] 98%|█████████▊| 1919/1950 [4:20:18<01:36,  3.10s/it] 98%|█████████▊| 1920/1950 [4:20:21<01:29,  2.99s/it]                                                     {'loss': 0.0004, 'learning_rate': 3.321576807067406e-08, 'epoch': 48.61}
 98%|█████████▊| 1920/1950 [4:20:21<01:29,  2.99s/it][INFO|trainer.py:3242] 2024-02-05 14:16:37,013 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:16:37,013 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:16:37,013 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.45it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.18it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.256103515625, 'eval_runtime': 3.3005, 'eval_samples_per_second': 21.209, 'eval_steps_per_second': 2.727, 'epoch': 48.61}
 98%|█████████▊| 1920/1950 [4:20:24<01:29,  2.99s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 99%|█████████▊| 1921/1950 [4:20:26<01:49,  3.78s/it] 99%|█████████▊| 1922/1950 [4:20:29<01:34,  3.37s/it] 99%|█████████▊| 1923/1950 [4:20:31<01:22,  3.06s/it] 99%|█████████▊| 1924/1950 [4:20:33<01:13,  2.84s/it] 99%|█████████▊| 1925/1950 [4:20:36<01:07,  2.71s/it]                                                     {'loss': 0.0002, 'learning_rate': 2.3648281331520306e-08, 'epoch': 48.73}
 99%|█████████▊| 1925/1950 [4:20:36<01:07,  2.71s/it][INFO|trainer.py:3242] 2024-02-05 14:16:52,138 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:16:52,139 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:16:52,139 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.03it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.91it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.74it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.2987, 'eval_samples_per_second': 21.221, 'eval_steps_per_second': 2.728, 'epoch': 48.73}
 99%|█████████▊| 1925/1950 [4:20:39<01:07,  2.71s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 99%|█████████▉| 1926/1950 [4:20:41<01:26,  3.60s/it] 99%|█████████▉| 1927/1950 [4:20:44<01:13,  3.21s/it] 99%|█████████▉| 1928/1950 [4:20:46<01:05,  2.98s/it] 99%|█████████▉| 1929/1950 [4:20:49<00:59,  2.83s/it] 99%|█████████▉| 1930/1950 [4:20:51<00:53,  2.66s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.5701474262883043e-08, 'epoch': 48.86}
 99%|█████████▉| 1930/1950 [4:20:51<00:53,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 14:17:07,294 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:17:07,294 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:17:07,295 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25634765625, 'eval_runtime': 3.2943, 'eval_samples_per_second': 21.249, 'eval_steps_per_second': 2.732, 'epoch': 48.86}
 99%|█████████▉| 1930/1950 [4:20:54<00:53,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A 99%|█████████▉| 1931/1950 [4:20:56<01:07,  3.55s/it] 99%|█████████▉| 1932/1950 [4:20:59<00:56,  3.17s/it] 99%|█████████▉| 1933/1950 [4:21:01<00:49,  2.91s/it] 99%|█████████▉| 1934/1950 [4:21:03<00:44,  2.75s/it] 99%|█████████▉| 1935/1950 [4:21:06<00:39,  2.65s/it]                                                     {'loss': 0.0003, 'learning_rate': 9.375862521687762e-09, 'epoch': 48.99}
 99%|█████████▉| 1935/1950 [4:21:06<00:39,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 14:17:22,297 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:17:22,297 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:17:22,297 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.78it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.05it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.02it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.25537109375, 'eval_runtime': 3.4206, 'eval_samples_per_second': 20.464, 'eval_steps_per_second': 2.631, 'epoch': 48.99}
 99%|█████████▉| 1935/1950 [4:21:09<00:39,  2.65s/it]
100%|██████████| 9/9 [00:03<00:00,  2.74it/s][A
                                             [A 99%|█████████▉| 1936/1950 [4:21:12<00:50,  3.59s/it] 99%|█████████▉| 1937/1950 [4:21:14<00:41,  3.17s/it] 99%|█████████▉| 1938/1950 [4:21:16<00:34,  2.91s/it] 99%|█████████▉| 1939/1950 [4:21:19<00:30,  2.76s/it] 99%|█████████▉| 1940/1950 [4:21:21<00:26,  2.66s/it]                                                     {'loss': 0.0002, 'learning_rate': 4.671856567811661e-09, 'epoch': 49.11}
 99%|█████████▉| 1940/1950 [4:21:21<00:26,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 14:17:37,552 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:17:37,552 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:17:37,552 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.06it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.4704, 'eval_samples_per_second': 20.17, 'eval_steps_per_second': 2.593, 'epoch': 49.11}
 99%|█████████▉| 1940/1950 [4:21:25<00:26,  2.66s/it]
100%|██████████| 9/9 [00:03<00:00,  2.74it/s][A
                                             [A100%|█████████▉| 1941/1950 [4:21:27<00:32,  3.65s/it]100%|█████████▉| 1942/1950 [4:21:29<00:26,  3.26s/it]100%|█████████▉| 1943/1950 [4:21:32<00:21,  3.05s/it]100%|█████████▉| 1944/1950 [4:21:34<00:16,  2.81s/it]100%|█████████▉| 1945/1950 [4:21:36<00:13,  2.65s/it]                                                     {'loss': 0.0002, 'learning_rate': 1.5897616374660473e-09, 'epoch': 49.24}
100%|█████████▉| 1945/1950 [4:21:36<00:13,  2.65s/it][INFO|trainer.py:3242] 2024-02-05 14:17:52,796 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:17:52,796 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:17:52,796 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.47it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.20it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255615234375, 'eval_runtime': 3.2908, 'eval_samples_per_second': 21.271, 'eval_steps_per_second': 2.735, 'epoch': 49.24}
100%|█████████▉| 1945/1950 [4:21:40<00:13,  2.65s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A100%|█████████▉| 1946/1950 [4:21:42<00:14,  3.56s/it]100%|█████████▉| 1947/1950 [4:21:45<00:09,  3.23s/it]100%|█████████▉| 1948/1950 [4:21:47<00:05,  2.98s/it]100%|█████████▉| 1949/1950 [4:21:49<00:02,  2.80s/it]100%|██████████| 1950/1950 [4:21:52<00:00,  2.66s/it]                                                     {'loss': 0.0003, 'learning_rate': 1.2977772336775217e-10, 'epoch': 49.37}
100%|██████████| 1950/1950 [4:21:52<00:00,  2.66s/it][INFO|trainer.py:3242] 2024-02-05 14:18:08,053 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:18:08,053 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:18:08,053 >>   Batch size = 4

  0%|          | 0/9 [00:00<?, ?it/s][A
 22%|██▏       | 2/9 [00:00<00:01,  5.79it/s][A
 33%|███▎      | 3/9 [00:00<00:01,  4.04it/s][A
 44%|████▍     | 4/9 [00:01<00:01,  3.46it/s][A
 56%|█████▌    | 5/9 [00:01<00:01,  3.19it/s][A
 67%|██████▋   | 6/9 [00:01<00:00,  3.03it/s][A
 78%|███████▊  | 7/9 [00:02<00:00,  2.92it/s][A
 89%|████████▉ | 8/9 [00:02<00:00,  2.75it/s][A
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A                                                     
                                             [A{'eval_loss': 0.255859375, 'eval_runtime': 3.2924, 'eval_samples_per_second': 21.261, 'eval_steps_per_second': 2.734, 'epoch': 49.37}
100%|██████████| 1950/1950 [4:21:55<00:00,  2.66s/it]
100%|██████████| 9/9 [00:02<00:00,  2.74it/s][A
                                             [A[INFO|trainer.py:1962] 2024-02-05 14:18:11,347 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2160] 2024-02-05 14:18:11,347 >> Loading best model from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200 (score: 0.127685546875).
[INFO|deepspeed.py:400] 2024-02-05 14:18:11,349 >> Attempting to resume from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200
[2024-02-05 14:18:11,351] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/mp_rank_00_model_states.pt...
[2024-02-05 14:27:38,493] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/mp_rank_00_model_states.pt.
[2024-02-05 14:27:40,799] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/mp_rank_00_model_states.pt...
[2024-02-05 14:28:08,760] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/mp_rank_00_model_states.pt.
[2024-02-05 14:28:15,350] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-02-05 14:28:15,704] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/checkpoint-200/global_step200/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-02-05 14:28:15,704] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 2 ZeRO state_dicts for rank 0
[2024-02-05 14:28:15,719] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 2 zero partition checkpoints for rank 0
                                                     {'train_runtime': 16320.7669, 'train_samples_per_second': 1.927, 'train_steps_per_second': 0.119, 'train_loss': 0.04568443293754871, 'epoch': 49.37}
100%|██████████| 1950/1950 [4:32:02<00:00,  2.66s/it]100%|██████████| 1950/1950 [4:32:02<00:00,  8.37s/it]
[INFO|trainer.py:2936] 2024-02-05 14:28:32,324 >> Saving model checkpoint to /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0
/mnt/nas_data/zyj_workspace/zyj_data/conda_env/llama_factory_2/lib/python3.10/site-packages/peft/utils/save_and_load.py:148: UserWarning: Could not find a config file in /mnt/nas_data/zyj_workspace/zyj_data/Baichuan2-13B-Chat - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2433] 2024-02-05 14:28:32,473 >> tokenizer config file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-02-05 14:28:32,474 >> Special tokens file saved in /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/special_tokens_map.json
***** train metrics *****
  epoch                    =      49.37
  train_loss               =     0.0457
  train_runtime            = 4:32:00.76
  train_samples_per_second =      1.927
  train_steps_per_second   =      0.119
Figure saved: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/training_loss.png
Figure saved: /mnt/nas_data/zyj_workspace/zyj_data/sft_output/bachuan2-13B-sft-etc-v5-50e-bs16-codev0.5.0/training_eval_loss.png
[INFO|trainer.py:3242] 2024-02-05 14:28:33,940 >> ***** Running Evaluation *****
[INFO|trainer.py:3244] 2024-02-05 14:28:33,940 >>   Num examples = 70
[INFO|trainer.py:3247] 2024-02-05 14:28:33,941 >>   Batch size = 4
  0%|          | 0/9 [00:00<?, ?it/s] 22%|██▏       | 2/9 [00:00<00:01,  5.96it/s] 33%|███▎      | 3/9 [00:00<00:01,  4.17it/s] 44%|████▍     | 4/9 [00:01<00:01,  3.56it/s] 56%|█████▌    | 5/9 [00:01<00:01,  3.29it/s] 67%|██████▋   | 6/9 [00:01<00:00,  3.12it/s] 78%|███████▊  | 7/9 [00:02<00:00,  3.01it/s] 89%|████████▉ | 8/9 [00:02<00:00,  2.83it/s]100%|██████████| 9/9 [00:02<00:00,  2.83it/s]100%|██████████| 9/9 [00:02<00:00,  3.17it/s]
***** eval metrics *****
  epoch                   =      49.37
  eval_loss               =     0.1277
  eval_runtime            = 0:00:03.18
  eval_samples_per_second =     21.959
  eval_steps_per_second   =      2.823
[INFO|modelcard.py:452] 2024-02-05 14:28:37,133 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[2024-02-05 14:28:38,876] [INFO] [launch.py:347:main] Process 3648077 exits successfully.
[2024-02-05 14:28:40,879] [INFO] [launch.py:347:main] Process 3648076 exits successfully.
